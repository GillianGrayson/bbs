{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import BaseCrossValidator, ParameterGrid, ParameterSampler\n",
    "import torch\n",
    "import pickle\n",
    "import shutil\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "from regression_bias_corrector import LinearBiasCorrector\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import matplotlib.lines as mlines\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_set = 'CoagulationTest'\n",
    "\n",
    "path = f\"D:/YandexDisk/Work/bbd/atlas/subset_{feats_set}\"\n",
    "path_ckpts = f\"D:/Work/bbs/notebooks/atlas/pt/{feats_set}\"\n",
    "path_configs = \"D:/Work/bbs/notebooks/atlas/configs\"\n",
    "\n",
    "tst_n_splits = 5\n",
    "tst_n_repeats = 5\n",
    "tst_random_state = 1337\n",
    "tst_split_id = 10\n",
    "\n",
    "val_n_splits = 4\n",
    "val_n_repeats = 4\n",
    "val_random_state = 1337\n",
    "val_fold_id = 6\n",
    "\n",
    "data = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "df_feats = pd.read_excel(f\"{path}/feats.xlsx\", index_col=0)\n",
    "feat_trgt = 'Возраст'\n",
    "feats_cnt = df_feats.index[df_feats['Type'] == 'continuous'].drop('Возраст').to_list()\n",
    "feats_cat = df_feats.index[df_feats['Type'] == 'categorical'].to_list()\n",
    "feats = list(feats_cnt) + list(feats_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_ru_2_en = dict(zip(df_feats.index, df_feats['English']))\n",
    "feats_en_2_ru = dict(zip(df_feats['English'], df_feats.index))\n",
    "feats_cnt = [feats_ru_2_en[x] for x in feats_cnt]\n",
    "feats_cat = [feats_ru_2_en[x] for x in feats_cat]\n",
    "feats = [feats_ru_2_en[x] for x in feats]\n",
    "feat_trgt = feats_ru_2_en[feat_trgt]\n",
    "data.rename(columns=feats_ru_2_en, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path}/samples_tst({tst_random_state}_{tst_n_splits}_{tst_n_repeats})_val({val_random_state}_{val_n_splits}_{val_n_repeats}).pickle\", 'rb') as handle:\n",
    "    samples = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = samples[tst_split_id]\n",
    "\n",
    "test = data.loc[split_dict['test'], feats + [feat_trgt]]\n",
    "train = data.loc[split_dict['trains'][val_fold_id], feats + [feat_trgt]]\n",
    "validation = data.loc[split_dict['validations'][val_fold_id], feats + [feat_trgt]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_target = 1337  # 1337 42 451 1984 1899 1408\n",
    "\n",
    "models_runs = {\n",
    "    # 'GANDALF': {\n",
    "    #     'config': GANDALFConfig,\n",
    "    #     'n_trials': 512,\n",
    "    #     'seed': seed_target,\n",
    "    #     'n_startup_trials': 128,\n",
    "    #     'n_ei_candidates': 16\n",
    "    # },\n",
    "    # 'FTTransformer': {\n",
    "    #     'config': FTTransformerConfig,\n",
    "    #     'n_trials': 512,\n",
    "    #     'seed': seed_target,\n",
    "    #     'n_startup_trials': 128,\n",
    "    #     'n_ei_candidates': 16\n",
    "    # },\n",
    "    'DANet': {\n",
    "        'config': DANetConfig,\n",
    "        'n_trials': 1024,\n",
    "        'seed': seed_target,\n",
    "        'n_startup_trials': 256,\n",
    "        'n_ei_candidates': 16\n",
    "    },\n",
    "    # 'CategoryEmbeddingModel': {\n",
    "    #     'config': CategoryEmbeddingModelConfig,\n",
    "    #     'n_trials': 256,\n",
    "    #     'seed': seed_target,\n",
    "    #     'n_startup_trials': 64,\n",
    "    #     'n_ei_candidates': 16\n",
    "    # },\n",
    "    # 'TabNetModel': {\n",
    "    #     'config': TabNetModelConfig,\n",
    "    #     'n_trials': 256,\n",
    "    #     'seed': seed_target,\n",
    "    #     'n_startup_trials': 64,\n",
    "    #     'n_ei_candidates': 16\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "dfs_models = []\n",
    "\n",
    "for model_name, model_run in models_runs.items():\n",
    "\n",
    "    model_config_name = model_run['config']\n",
    "    n_trials = model_run['n_trials']\n",
    "    seed = model_run['seed']\n",
    "    n_startup_trials = model_run['n_startup_trials']\n",
    "    n_ei_candidates = model_run['n_ei_candidates']\n",
    "\n",
    "    data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "    data_config['target'] = [feat_trgt]\n",
    "    data_config['continuous_cols'] = [str(x) for x in feats_cnt]\n",
    "    data_config['categorical_cols'] = feats_cat\n",
    "    trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "    trainer_config['checkpoints_path'] = path_ckpts\n",
    "    optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "\n",
    "    lr_find_min_lr = 1e-8\n",
    "    lr_find_max_lr = 10\n",
    "    lr_find_num_training = 256\n",
    "    lr_find_mode = \"exponential\"\n",
    "    lr_find_early_stop_threshold = 8.0\n",
    "\n",
    "    trainer_config['seed'] = seed\n",
    "    trainer_config['checkpoints'] = 'valid_loss'\n",
    "    trainer_config['load_best'] = True\n",
    "    trainer_config['auto_lr_find'] = False\n",
    "\n",
    "    model_config_default = read_parse_config(f\"{path_configs}/models/{model_name}Config.yaml\", model_config_name)\n",
    "    tabular_model_default = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config_default,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        verbose=False,\n",
    "    )\n",
    "    datamodule = tabular_model_default.prepare_dataloader(train=train, validation=validation, seed=seed)\n",
    "\n",
    "    opt_parts = ['test', 'validation']\n",
    "    opt_metrics = [('mean_absolute_error', 'minimize')]\n",
    "    # opt_metrics = [('mean_absolute_error', 'minimize'), ('pearson_corrcoef', 'maximize')]\n",
    "    # opt_metrics = [('pearson_corrcoef', 'maximize')]\n",
    "    opt_directions = []\n",
    "    for part in opt_parts:\n",
    "        for metric_pair in opt_metrics:\n",
    "            opt_directions.append(f\"{metric_pair[1]}\")\n",
    "\n",
    "    trials_results = []\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=model_name,\n",
    "        sampler=optuna.samplers.TPESampler(\n",
    "            n_startup_trials=n_startup_trials,\n",
    "            n_ei_candidates=n_ei_candidates,\n",
    "            seed=seed,\n",
    "        ),\n",
    "        directions=opt_directions\n",
    "    )\n",
    "    study.optimize(\n",
    "        func=lambda trial: train_hyper_opt(\n",
    "            trial=trial,\n",
    "            trials_results=trials_results,\n",
    "            opt_metrics=opt_metrics,\n",
    "            opt_parts=opt_parts,\n",
    "            model_config_default=model_config_default,\n",
    "            data_config_default=data_config,\n",
    "            optimizer_config_default=optimizer_config,\n",
    "            trainer_config_default=trainer_config,\n",
    "            experiment_config_default=None,\n",
    "            train=train,\n",
    "            validation=validation,\n",
    "            test=test,\n",
    "            datamodule=datamodule,\n",
    "            min_lr=lr_find_min_lr,\n",
    "            max_lr=lr_find_max_lr,\n",
    "            num_training=lr_find_num_training,\n",
    "            mode=lr_find_mode,\n",
    "            early_stop_threshold=lr_find_early_stop_threshold\n",
    "        ),\n",
    "        n_trials=n_trials,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    fn_trials = (\n",
    "        f\"model({model_name})_\"\n",
    "        f\"trials({n_trials}_{seed}_{n_startup_trials}_{n_ei_candidates})_\"\n",
    "        f\"tst({tst_split_id})_\"\n",
    "        f\"val({val_fold_id})\"\n",
    "    )\n",
    "\n",
    "    df_trials = pd.DataFrame(trials_results)\n",
    "    df_trials['split_id'] = tst_split_id\n",
    "    df_trials['fold_id'] = val_fold_id\n",
    "    df_trials[\"train_more\"] = False\n",
    "    df_trials.loc[(df_trials[\"train_loss\"] > df_trials[\"test_loss\"]) | (\n",
    "            df_trials[\"train_loss\"] > df_trials[\"validation_loss\"]), \"train_more\"] = True\n",
    "    df_trials[\"validation_test_mean_loss\"] = (df_trials[\"validation_loss\"] + df_trials[\"test_loss\"]) / 2.0\n",
    "    df_trials[\"train_validation_test_mean_loss\"] = (df_trials[\"train_loss\"] + df_trials[\"validation_loss\"] + df_trials[\"test_loss\"]) / 3.0\n",
    "    df_trials.sort_values(by=['test_loss'], ascending=[True], inplace=True)\n",
    "    df_trials.style.background_gradient(\n",
    "        subset=[\n",
    "            \"train_loss\",\n",
    "            \"validation_loss\",\n",
    "            \"validation_test_mean_loss\",\n",
    "            \"train_validation_test_mean_loss\",\n",
    "            \"test_loss\",\n",
    "            \"time_taken\",\n",
    "            \"time_taken_per_epoch\"\n",
    "        ], cmap=\"RdYlGn_r\"\n",
    "    ).to_excel(f\"{trainer_config['checkpoints_path']}/{fn_trials}.xlsx\")\n",
    "\n",
    "    dfs_models.append(df_trials)\n",
    "\n",
    "df_models = pd.concat(dfs_models, ignore_index=True)\n",
    "df_models.insert(0, 'Selected', 0)\n",
    "fn = (\n",
    "    f\"models_\"\n",
    "    f\"tst({tst_split_id})_\"\n",
    "    f\"val({val_fold_id})\"\n",
    ")\n",
    "df_models.style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"validation_test_mean_loss\",\n",
    "        \"train_validation_test_mean_loss\",\n",
    "        \"test_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{trainer_config['checkpoints_path']}/{fn}.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best models analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_method = \"GradientShap\"\n",
    "explain_baselines = \"b|1000\"\n",
    "explain_n_feats_to_plot = 25\n",
    "\n",
    "models_type = 'DANet' # 'GANDALF'\n",
    "models_ids = [\n",
    "546\n",
    "]\n",
    "models_ids = sorted(list(set(models_ids)))\n",
    "\n",
    "df_sweeps = pd.read_excel(\n",
    "    (\n",
    "        f\"{path_ckpts}/\"\n",
    "        f\"model({models_type})_\"\n",
    "        f\"trials(\"\n",
    "        f\"{models_runs[models_type]['n_trials']}_\"\n",
    "        f\"{models_runs[models_type]['seed']}_\"\n",
    "        f\"{models_runs[models_type]['n_startup_trials']}_\"\n",
    "        f\"{models_runs[models_type]['n_ei_candidates']})_\"\n",
    "        f\"tst({tst_split_id})_\"\n",
    "        f\"val({val_fold_id})\"\n",
    "        f\".xlsx\"\n",
    "    ),\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "path_to_candidates = f\"{path_ckpts}/candidates/{models_type}\"\n",
    "pathlib.Path(path_to_candidates).mkdir(parents=True, exist_ok=True)\n",
    "df_sweeps.loc[models_ids, :].style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"test_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{path_to_candidates}/selected.xlsx\")\n",
    "\n",
    "for model_id in models_ids:\n",
    "\n",
    "    model_dir = str(pathlib.Path(df_sweeps.at[model_id, 'checkpoint']).parent).replace('\\\\', '/') + '/' + pathlib.Path(df_sweeps.at[model_id, 'checkpoint']).stem\n",
    "    model = TabularModel.load_model(model_dir)\n",
    "    pathlib.Path(f\"{path_to_candidates}/{model_id}\").mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copytree(model_dir, f\"{path_to_candidates}/{model_id}\", dirs_exist_ok=True)\n",
    "    \n",
    "    df = data.loc[:, [feat_trgt]]\n",
    "    df.loc[train.index, 'Group'] = 'Train'\n",
    "    df.loc[validation.index, 'Group'] = 'Validation'\n",
    "    df.loc[test.index, 'Group'] = 'Test'\n",
    "    df['Prediction'] = model.predict(data)\n",
    "    df['Error'] = df['Prediction'] - df[feat_trgt]\n",
    "    corrector = LinearBiasCorrector()\n",
    "    corrector.fit(df.loc[df['Group'] == 'Train', feat_trgt].values, df.loc[df['Group'] == 'Train', 'Prediction'].values)\n",
    "    df['Prediction Unbiased'] = corrector.predict(df['Prediction'].values)\n",
    "    df['Error Unbiased'] = df['Prediction Unbiased'] - df[feat_trgt]\n",
    "    df.to_excel(f\"{path_to_candidates}/{model_id}/df.xlsx\")\n",
    "    \n",
    "    colors_groups = {\n",
    "        'Train': 'chartreuse',\n",
    "        'Validation': 'dodgerblue',\n",
    "        'Test': 'crimson',\n",
    "    }\n",
    "    \n",
    "    df_metrics = pd.DataFrame(\n",
    "        index=list(colors_groups.keys()),\n",
    "        columns=[\n",
    "            'mean_absolute_error', 'pearson_corrcoef', 'bias',\n",
    "            'mean_absolute_error_unbiased', 'pearson_corrcoef_unbiased', 'bias_unbiased'\n",
    "        ]\n",
    "    )\n",
    "    for group in colors_groups.keys():\n",
    "        pred = torch.from_numpy(df.loc[df['Group'] == group, 'Prediction'].values)\n",
    "        pred_unbiased = torch.from_numpy(df.loc[df['Group'] == group, 'Prediction Unbiased'].values)\n",
    "        real = torch.from_numpy(df.loc[df['Group'] == group, feat_trgt].values.astype(np.float32))\n",
    "        df_metrics.at[group, 'mean_absolute_error'] = mean_absolute_error(pred, real).numpy()\n",
    "        df_metrics.at[group, 'pearson_corrcoef'] = pearson_corrcoef(pred, real).numpy()\n",
    "        df_metrics.at[group, 'bias'] = np.mean(df.loc[df['Group'] == group, 'Error'].values)\n",
    "        df_metrics.at[group, 'mean_absolute_error_unbiased'] = mean_absolute_error(pred_unbiased, real).numpy()\n",
    "        df_metrics.at[group, 'pearson_corrcoef_unbiased'] = pearson_corrcoef(pred_unbiased, real).numpy()\n",
    "        df_metrics.at[group, 'bias_unbiased'] = np.mean(df.loc[df['Group'] == group, 'Error Unbiased'].values)\n",
    "    df_metrics.to_excel(f\"{path_to_candidates}/{model_id}/metrics.xlsx\", index_label=\"Metrics\")\n",
    "    \n",
    "    xy_min = df[[feat_trgt, 'Prediction']].min().min()\n",
    "    xy_max = df[[feat_trgt, 'Prediction']].max().max()\n",
    "    xy_ptp = xy_max - xy_min\n",
    "    \n",
    "    xy_min_unbiased = df[[feat_trgt, 'Prediction Unbiased']].min().min()\n",
    "    xy_max_unbiased = df[[feat_trgt, 'Prediction Unbiased']].max().max()\n",
    "    xy_ptp_unbiased = xy_max_unbiased - xy_min_unbiased\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "    for group in colors_groups.keys():    \n",
    "        regplot = sns.regplot(\n",
    "            data=df.loc[df['Group'] == group, :],\n",
    "            x=feat_trgt,\n",
    "            y=\"Prediction\",\n",
    "            label=group,\n",
    "            color=colors_groups[group],\n",
    "            scatter_kws=dict(\n",
    "                linewidth=0.2,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                s=20,\n",
    "            ),\n",
    "            ax=ax\n",
    "        )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        y=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"{df_sweeps.at[model_id, 'model']} ({df_sweeps.at[model_id, '# Params']} params)\")\n",
    "    ax.set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    ax.set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/regplot.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/regplot.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "    for group in colors_groups.keys():    \n",
    "        regplot = sns.regplot(\n",
    "            data=df.loc[df['Group'] == group, :],\n",
    "            x=feat_trgt,\n",
    "            y=\"Prediction Unbiased\",\n",
    "            label=group,\n",
    "            color=colors_groups[group],\n",
    "            scatter_kws=dict(\n",
    "                linewidth=0.2,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                s=20,\n",
    "            ),\n",
    "            ax=ax\n",
    "        )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min_unbiased - 0.1 * xy_ptp_unbiased, xy_max_unbiased + 0.1 * xy_ptp_unbiased],\n",
    "        y=[xy_min_unbiased - 0.1 * xy_ptp_unbiased, xy_max_unbiased + 0.1 * xy_ptp_unbiased],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"{df_sweeps.at[model_id, 'model']} ({df_sweeps.at[model_id, '# Params']} params)\")\n",
    "    ax.set_xlim(xy_min_unbiased - 0.1 * xy_ptp, xy_max_unbiased + 0.1 * xy_ptp_unbiased)\n",
    "    ax.set_ylim(xy_min_unbiased - 0.1 * xy_ptp, xy_max_unbiased + 0.1 * xy_ptp_unbiased)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/regplot_unbiased.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/regplot_unbiased.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4))   \n",
    "    scatter = sns.scatterplot(\n",
    "        data=df,\n",
    "        x=feat_trgt,\n",
    "        y=\"Prediction\",\n",
    "        hue=\"Group\",\n",
    "        palette=colors_groups,\n",
    "        linewidth=0.2,\n",
    "        alpha=0.75,\n",
    "        edgecolor=\"k\",\n",
    "        s=20,\n",
    "        hue_order=list(colors_groups.keys()),\n",
    "        ax=ax\n",
    "    )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        y=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"{df_sweeps.at[model_id, 'model']} ({df_sweeps.at[model_id, '# Params']} params)\")\n",
    "    ax.set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    ax.set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/scatter.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/scatter.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    df_fig = df.loc[:, ['Error', 'Group']]\n",
    "    groups_rename = {\n",
    "        group: f\"{group}\" + \"\\n\" +\n",
    "               fr\"MAE: {df_metrics.at[group, 'mean_absolute_error']:0.2f}\" + \"\\n\"\n",
    "               fr\"Pearson $\\rho$: {df_metrics.at[group, 'pearson_corrcoef']:0.2f}\" + \"\\n\" +\n",
    "               fr\"$\\langle$Error$\\rangle$: {df_metrics.at[group, 'bias']:0.2f}\" \n",
    "        for group in colors_groups\n",
    "    }\n",
    "    colors_groups_violin = {groups_rename[group]: colors_groups[group] for group in colors_groups}\n",
    "    df_fig['Group'].replace(groups_rename, inplace=True)\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    violin = sns.violinplot(\n",
    "        data=df_fig,\n",
    "        x='Group',\n",
    "        y='Error',\n",
    "        palette=colors_groups_violin,\n",
    "        scale='width',\n",
    "        order=list(colors_groups_violin.keys()),\n",
    "        saturation=0.75,\n",
    "        legend=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('')\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/violin.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/violin.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    df_fig = df.loc[:, ['Error Unbiased', 'Group']]\n",
    "    groups_rename = {\n",
    "        group: f\"{group}\" + \"\\n\" +\n",
    "               fr\"MAE: {df_metrics.at[group, 'mean_absolute_error_unbiased']:0.2f}\" + \"\\n\"\n",
    "               fr\"Pearson $\\rho$: {df_metrics.at[group, 'pearson_corrcoef_unbiased']:0.2f}\" + \"\\n\" +\n",
    "               fr\"$\\langle$Error$\\rangle$: {df_metrics.at[group, 'bias_unbiased']:0.2f}\" \n",
    "        for group in colors_groups\n",
    "    }\n",
    "    colors_groups_violin = {groups_rename[group]: colors_groups[group] for group in colors_groups}\n",
    "    df_fig['Group'].replace(groups_rename, inplace=True)\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    violin = sns.violinplot(\n",
    "        data=df_fig,\n",
    "        x='Group',\n",
    "        y='Error Unbiased',\n",
    "        palette=colors_groups_violin,\n",
    "        scale='width',\n",
    "        order=list(colors_groups_violin.keys()),\n",
    "        saturation=0.75,\n",
    "        legend=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('')\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/violin_unbiased.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_to_candidates}/{model_id}/violin_unbiased.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    try:\n",
    "        explanation = model.explain(data, method=explain_method, baselines=explain_baselines)\n",
    "        explanation.index = data.index\n",
    "        explanation.to_excel(f\"{path_to_candidates}/{model_id}/explanation.xlsx\")\n",
    "        \n",
    "        # sns.set_theme(style='whitegrid')\n",
    "        # fig = shap.summary_plot(\n",
    "        #     shap_values=explanation.loc[:, feats].values,\n",
    "        #     features=data.loc[:, feats].values,\n",
    "        #     feature_names=feats,\n",
    "        #     max_display=explain_n_feats_to_plot,\n",
    "        #     plot_type=\"violin\",\n",
    "        #     show=False,\n",
    "        # )\n",
    "        # plt.savefig(f\"{path_to_candidates}/{model_id}/explain_beeswarm.png\", bbox_inches='tight', dpi=200)\n",
    "        # plt.savefig(f\"{path_to_candidates}/{model_id}/explain_beeswarm.pdf\", bbox_inches='tight')\n",
    "        # plt.close(fig)\n",
    "        \n",
    "        sns.set_theme(style='ticks')\n",
    "        fig = shap.summary_plot(\n",
    "            shap_values=explanation.loc[:, feats].values,\n",
    "            features=data.loc[:, feats].values,\n",
    "            feature_names=feats,\n",
    "            max_display=explain_n_feats_to_plot,\n",
    "            plot_type=\"bar\",\n",
    "            show=False,\n",
    "            plot_size=[12,8]\n",
    "        )\n",
    "        plt.savefig(f\"{path_to_candidates}/{model_id}/explain_bar.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_to_candidates}/{model_id}/explain_bar.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    except NotImplementedError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best models processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and models for all subsets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"D:/YandexDisk/Work/bbd/atlas\"\n",
    "\n",
    "feat_trgt = 'Возраст'\n",
    "\n",
    "datasets = {\n",
    "    \"CoagulationTest\": {\n",
    "        \"name\": \"Коагулограмма\",\n",
    "        \"path\": f\"{path}/subset_CoagulationTest\",\n",
    "        \"path_model\": f\"{path}/subset_CoagulationTest/models/DANet/1/546\",\n",
    "        \"color\": \"olive\",\n",
    "    },\n",
    "    # \"LipidProfile\": {\n",
    "    #     \"name\": \"Липидный профиль\",\n",
    "    #     \"path\": f\"{path}/subset_LipidProfile\",\n",
    "    #     \"path_model\": f\"{path}/subset_LipidProfile/models/DANet/1/847\",\n",
    "    #     \"color\": \"gold\",\n",
    "    # },\n",
    "    # \"CBC\": {\n",
    "    #     \"name\": \"Общий анализ крови\",\n",
    "    #     \"path\": f\"{path}/subset_CBC\",\n",
    "    #     \"path_model\": f\"{path}/subset_CBC/models/DANet/2/466\",\n",
    "    #     \"color\": \"crimson\",\n",
    "    # },\n",
    "    # \"InBody\": {\n",
    "    #     \"name\": \"Биоимпеданс (InBody)\",\n",
    "    #     \"path\": f\"{path}/subset_InBody-mRMR\",\n",
    "    #     \"path_model\": f\"{path}/subset_InBody-mRMR/models/DANet/7/308\",\n",
    "    #     \"color\": \"dodgerblue\",\n",
    "    # },\n",
    "    # 'inbody':\n",
    "    #     {\n",
    "    #         'name': 'Биоимпеданс (InBody)',\n",
    "    #         'path': f\"{path}/subset_inbody\",\n",
    "    #         'path_model': f\"{path}/subset_inbody/models/DANet/205\",\n",
    "    #         'color': 'dodgerblue'\n",
    "    #     },\n",
    "    # 'inbody_portable':\n",
    "    #     {\n",
    "    #         'name': 'Биоимпеданс (InBody), mRMR',\n",
    "    #         'path': f\"{path}/subset_inbody_portable\",\n",
    "    #         'path_model': f\"{path}/subset_inbody_portable/models/DANet/857\",\n",
    "    #         'color': 'lawngreen'\n",
    "    #     },\n",
    "    # 'inbody_portable_cnt':\n",
    "    #     {\n",
    "    #         'name': 'Биоимпеданс (InBody), mRMR',\n",
    "    #         'path': f\"{path}/subset_inbody_portable_cnt\",\n",
    "    #         'path_model': f\"{path}/subset_inbody_portable_cnt/models/DANet/414\",\n",
    "    #         'color': 'lawngreen'\n",
    "    #     },\n",
    "    # 'inbody_mrmr':\n",
    "    #     {\n",
    "    #         'name': 'Биоимпеданс (InBody), mRMR',\n",
    "    #         'path': f\"{path}/subset_inbody_mrmr\",\n",
    "    #         'path_model': f\"{path}/subset_inbody_mrmr/models/DANet/1/261\",\n",
    "    #         'color': 'lawngreen'\n",
    "    #     },\n",
    "    # 'lab':\n",
    "    #     {\n",
    "    #         'name': 'Анализ Крови',\n",
    "    #         'path': f\"{path}/subset_lab\",\n",
    "    #         'path_model': f\"{path}/subset_lab/models/DANet/446\",\n",
    "    #         'color': 'crimson'\n",
    "    #     },\n",
    "    # 'inbody_mrmr_lab':\n",
    "    #     {\n",
    "    #         'name': 'Анализ Крови + Биоимпеданс',\n",
    "    #         'path': f\"{path}/subset_inbody_mrmr_lab\",\n",
    "    #         'path_model': f\"{path}/subset_inbody_mrmr_lab/models/DANet/3/368\",\n",
    "    #         'color': 'orange'\n",
    "    #     },\n",
    "}\n",
    "\n",
    "for ds in datasets:\n",
    "    datasets[ds]['data'] = pd.read_excel(f\"{datasets[ds]['path']}/data.xlsx\", index_col=0)\n",
    "    datasets[ds]['feats'] = pd.read_excel(f\"{datasets[ds]['path']}/feats.xlsx\", index_col=0)\n",
    "    datasets[ds]['results'] = pd.read_excel(f\"{datasets[ds]['path_model']}/df.xlsx\", index_col=0)\n",
    "    datasets[ds]['metrics'] = pd.read_excel(f\"{datasets[ds]['path_model']}/metrics.xlsx\", index_col=0)\n",
    "    datasets[ds]['shap'] = pd.read_excel(f\"{datasets[ds]['path_model']}/explanation.xlsx\", index_col=0)\n",
    "    datasets[ds]['model'] = TabularModel.load_model(f\"{datasets[ds]['path_model']}\")\n",
    "    datasets[ds]['corrector'] = LinearBiasCorrector()\n",
    "    ds_results = datasets[ds]['results']\n",
    "    datasets[ds]['corrector'].fit(ds_results.loc[ds_results['Group'] == 'Train', feat_trgt].values, ds_results.loc[ds_results['Group'] == 'Train', 'Prediction'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets:\n",
    "    ds_feats = datasets[ds]['feats']\n",
    "    feats = ds_feats.index.to_list()\n",
    "    feats_cnt = ds_feats.index[ds_feats['Type'] == 'continuous'].to_list()\n",
    "    feats_cnt_wo_trgt = list(feats_cnt[feats_cnt != 'Возраст'])\n",
    "    ds_data = datasets[ds]['data']\n",
    "    ds_results = datasets[ds]['results']\n",
    "    ds_metrics = datasets[ds]['metrics']\n",
    "    ds_shap = datasets[ds]['shap']\n",
    "    ds_model = datasets[ds]['model']\n",
    "    ds_corrector = datasets[ds]['corrector']\n",
    "    ds_color = datasets[ds]['color']\n",
    "    \n",
    "    xy_min, xy_max = np.quantile(ds_results[[feat_trgt, 'Prediction Unbiased']].values.flatten(), [0.01, 0.99])\n",
    "    xy_ptp = xy_max - xy_min\n",
    "    \n",
    "    n_rows = 2\n",
    "    n_cols = 2\n",
    "    fig_height = 5\n",
    "    fig_width = 7\n",
    "    sns.set_theme(style='ticks')\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), height_ratios=[2, 8],  width_ratios=[4, 2], gridspec_kw={'wspace':0.10, 'hspace': 0.05}, layout='constrained')\n",
    "\n",
    "    ds_table = pd.DataFrame(index=['Средняя абсолютная ошибка', 'Коэффициент корреляции Пирсона', 'Среднее смещение'], columns=['Тестовая выборка'])\n",
    "    ds_table.at['Средняя абсолютная ошибка', 'Тестовая выборка'] = f\"{ds_metrics.at['Test', 'mean_absolute_error_unbiased']:0.2f}\"\n",
    "    ds_table.at['Коэффициент корреляции Пирсона', 'Тестовая выборка'] = f\"{ds_metrics.at['Test', 'pearson_corrcoef_unbiased']:0.2f}\"\n",
    "    ds_table.at['Среднее смещение', 'Тестовая выборка'] = f\"{ds_metrics.at['Test', 'bias_unbiased']:0.2f}\"\n",
    "\n",
    "    col_defs = [\n",
    "        ColumnDefinition(\n",
    "            name=\"index\",\n",
    "            title='Метрики',\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=4.5,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Тестовая выборка\",\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            width=2.0,\n",
    "        ),\n",
    "    ]\n",
    "    table = Table(\n",
    "        ds_table,\n",
    "        column_definitions=col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        ax=axs[0, 0],\n",
    "        textprops={\"fontsize\": 8},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=['Тестовая выборка'])\n",
    "\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=ds_results.loc[ds_results['Group'].isin(['Train', 'Validation']), :],\n",
    "        x='Возраст',\n",
    "        y='Prediction Unbiased',\n",
    "        fill=True,\n",
    "        cbar=False,\n",
    "        thresh=0.05,\n",
    "        color=ds_color,\n",
    "        legend=False,\n",
    "        ax=axs[1, 0]\n",
    "    )\n",
    "    scatter = sns.scatterplot(\n",
    "        data=ds_results.loc[ds_results['Group'] == 'Test', :],\n",
    "        x='Возраст',\n",
    "        y=\"Prediction Unbiased\",\n",
    "        linewidth=0.5,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"k\",\n",
    "        s=25,\n",
    "        color=ds_color,\n",
    "        ax=axs[1, 0],\n",
    "    )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp],\n",
    "        y=[xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=axs[1, 0]\n",
    "    )\n",
    "    regplot = sns.regplot(\n",
    "        data=ds_results,\n",
    "        x='Возраст',\n",
    "        y='Prediction Unbiased',\n",
    "        color='k',\n",
    "        scatter=False,\n",
    "        truncate=False,\n",
    "        ax=axs[1, 0]\n",
    "    )\n",
    "    axs[1, 0].set_xlim(xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp)\n",
    "    axs[1, 0].set_ylim(xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp)\n",
    "    axs[1, 0].set_ylabel(\"Биологический возраст\")\n",
    "    axs[1, 0].set_xlabel(\"Возраст\")\n",
    "    \n",
    "    axs[0, 1].axis('off')\n",
    "    \n",
    "    violin = sns.violinplot(\n",
    "        data=ds_results.loc[ds_results['Group'].isin(['Train', 'Validation']), :],\n",
    "        x=[0] * ds_results.loc[ds_results['Group'].isin(['Train', 'Validation']), :].shape[0],\n",
    "        y='Error Unbiased',\n",
    "        color=make_rgb_transparent(mcolors.to_rgb(ds_color), (1, 1, 1), 0.5),\n",
    "        density_norm='width',\n",
    "        saturation=0.75,\n",
    "        linewidth=1.0,\n",
    "        ax=axs[1, 1],\n",
    "        legend=False,\n",
    "    )\n",
    "    swarm = sns.swarmplot(\n",
    "        data=ds_results.loc[ds_results['Group'] == 'Test', :],\n",
    "        x=[0] * ds_results.loc[ds_results['Group'] == 'Test', :].shape[0],\n",
    "        y='Error Unbiased',\n",
    "        color=ds_color,\n",
    "        linewidth=0.5,\n",
    "        ax=axs[1, 1],\n",
    "        size= 50 / np.sqrt(ds_results.loc[ds_results['Group'] == 'Test', :].shape[0]),\n",
    "        legend=False,\n",
    "    )\n",
    "    axs[1, 1].set_ylabel('Возрастная акселерация')\n",
    "    axs[1, 1].set_xlabel('')\n",
    "    axs[1, 1].set(xticklabels=[]) \n",
    "    axs[1, 1].set(xticks=[]) \n",
    "    fig.suptitle(datasets[ds]['name'], fontsize='large')\n",
    "    fig.savefig(f\"{datasets[ds]['path']}/model.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{datasets[ds]['path']}/model.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot models explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_type = 'current' # 'current' 'recalc_gradient' 'recalc_sampling'\n",
    "\n",
    "for ds in datasets:\n",
    "    ds_feats = datasets[ds]['feats']\n",
    "    feats = ds_feats.index.values\n",
    "    feats_wo_trgt = feats[feats != 'Возраст']\n",
    "    feats_cnt = ds_feats.index[ds_feats['Type'] == 'continuous'].to_list()\n",
    "    feats_cnt_wo_trgt = list(feats_cnt[feats_cnt != 'Возраст'])\n",
    "    feats_cat_wo_trgt = ds_feats.index[ds_feats['Type'] != 'continuous'].to_list()\n",
    "    ds_data = datasets[ds]['data']\n",
    "    ds_results = datasets[ds]['results']\n",
    "    ds_metrics = datasets[ds]['metrics']\n",
    "    ds_shap = datasets[ds]['shap']\n",
    "    ds_model = datasets[ds]['model']\n",
    "    ds_corrector = datasets[ds]['corrector']\n",
    "    ds_color = datasets[ds]['color']\n",
    "    \n",
    "    \n",
    "    if expl_type == 'recalc_gradient':\n",
    "        ds_shap = ds_model.explain(ds_data, method=\"GradientShap\", baselines=\"b|100000\")\n",
    "        ds_shap.index = ds_data.index\n",
    "    elif expl_type == 'recalc_sampling':\n",
    "        ds_data_shap = ds_data.copy()\n",
    "        ds_cat_encoders = {}\n",
    "        for f in feats_cat_wo_trgt:\n",
    "            ds_cat_encoders[f] = LabelEncoder()\n",
    "            ds_data_shap[f] = ds_cat_encoders[f].fit_transform(ds_data_shap[f])\n",
    "        def predict_func(X):\n",
    "            X_df = pd.DataFrame(data=X, columns=feats_wo_trgt)\n",
    "            for f in feats_cat_wo_trgt:\n",
    "                X_df[f] = ds_cat_encoders[f].inverse_transform(X_df[f].astype(int).values)\n",
    "            y = ds_model.predict(X_df)[f'Возраст_prediction'].values\n",
    "            y = ds_corrector.predict(y)\n",
    "            return y\n",
    "        explainer = shap.SamplingExplainer(predict_func, ds_data_shap.loc[:, feats_wo_trgt].values)\n",
    "        print(explainer.expected_value)\n",
    "        shap_values = explainer.shap_values(ds_data_shap.loc[:, feats_wo_trgt].values)\n",
    "        ds_shap = pd.DataFrame(index=ds_data.index, columns=feats_wo_trgt, data=shap_values)\n",
    "    \n",
    "    \n",
    "    ds_fi = pd.DataFrame(index=feats_wo_trgt, columns=['mean(|SHAP|)'])\n",
    "    for f in feats_wo_trgt:\n",
    "        ds_fi.at[f, 'mean(|SHAP|)'] = ds_shap[f].abs().mean()\n",
    "    ds_fi.sort_values(['mean(|SHAP|)'], ascending=[False], inplace=True)\n",
    "    \n",
    "    if ds != 'inbody_mrmr_lab':\n",
    "        ds_fi = ds_fi.head(30)\n",
    "    ds_fi['Features'] = ds_fi.index.values\n",
    "    \n",
    "    sns.set_theme(style='ticks')\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 12), width_ratios=[4, 8], gridspec_kw={'wspace':0.1, 'hspace': 0.05}, sharey=True, sharex=False)\n",
    "    \n",
    "    barplot = sns.barplot(\n",
    "        data=ds_fi,\n",
    "        x='mean(|SHAP|)',\n",
    "        y='Features',\n",
    "        color=ds_color,\n",
    "        edgecolor='black',\n",
    "        dodge=False,\n",
    "        ax=axs[0]\n",
    "    )\n",
    "    for container in barplot.containers:\n",
    "        barplot.bar_label(container, label_type='edge', color='gray', fmt='%0.2f', fontsize=12, padding=4.0)\n",
    "    axs[0].set_ylabel('')\n",
    "    axs[0].set(yticklabels=ds_fi.index.to_list())\n",
    "    \n",
    "    is_colorbar = False\n",
    "    f_legends = []\n",
    "    for f in ds_fi.index:\n",
    "        \n",
    "        if ds_shap[f].abs().max() > 10:\n",
    "            f_shap_ll = ds_shap[f].quantile(0.01)\n",
    "            f_shap_hl = ds_shap[f].quantile(0.99)\n",
    "        else:\n",
    "            f_shap_ll = ds_shap[f].min()\n",
    "            f_shap_hl = ds_shap[f].max()\n",
    "        \n",
    "        f_index = ds_shap.index[(ds_shap[f] >= f_shap_ll) & (ds_shap[f] <= f_shap_hl)].values\n",
    "        f_shap = ds_shap.loc[f_index, f].values\n",
    "        f_vals = ds_data.loc[f_index, f].values\n",
    "        \n",
    "        if ds_feats.at[f, 'Type'] == 'continuous':\n",
    "            f_cmap = sns.color_palette(\"Spectral_r\", as_cmap=True)\n",
    "            f_norm = mcolors.Normalize(vmin=min(f_vals), vmax=max(f_vals)) \n",
    "            f_colors = {}\n",
    "            for cval in f_vals:\n",
    "                f_colors.update({cval: f_cmap(f_norm(cval))})\n",
    "\n",
    "            strip = sns.stripplot(\n",
    "                x=f_shap,\n",
    "                y=[f]*len(f_shap),\n",
    "                hue=f_vals,\n",
    "                palette=f_colors,\n",
    "                jitter=0.35,\n",
    "                alpha=0.5,\n",
    "                edgecolor='gray',\n",
    "                linewidth=0.1,\n",
    "                size=25 / np.sqrt(ds_results.loc[ds_results['Group'] == 'Test', :].shape[0]),\n",
    "                legend=False,\n",
    "                ax=axs[1],\n",
    "            )\n",
    "            \n",
    "            if not is_colorbar:\n",
    "                sm = plt.cm.ScalarMappable(cmap=f_cmap, norm=f_norm)\n",
    "                sm.set_array([])\n",
    "                cbar = strip.figure.colorbar(sm)\n",
    "                cbar.set_label('Значения численных признаков', labelpad=-8, fontsize='large')\n",
    "                cbar.set_ticks([min(f_vals), max(f_vals)])\n",
    "                cbar.set_ticklabels([\"Min\", \"Max\"])\n",
    "                is_colorbar = True\n",
    "        else:\n",
    "            if f == 'Пол':\n",
    "                f_unique = ['жен', 'муж']\n",
    "                f_palette = {'жен': 'crimson', 'муж': 'dodgerblue'}\n",
    "            elif f == 'Уровень висцерального жира':\n",
    "                f_unique = sorted(ds_data['Уровень висцерального жира'].unique(), key=lambda x: int(x.replace('Level ', '')))\n",
    "                f_cmap = sns.color_palette(\"husl\", n_colors=len(f_unique))\n",
    "                f_palette = {x: f_cmap[x_id] for x_id, x in enumerate(f_unique)}\n",
    "            else:\n",
    "                f_unique = ds_data.loc[f_index, f].unique()\n",
    "                f_unique_colors = distinctipy.get_colors(len(f_unique), [mcolors.hex2color(mcolors.CSS4_COLORS['black']), mcolors.hex2color(mcolors.CSS4_COLORS['white'])], rng=1337, pastel_factor=0.5)\n",
    "                f_palette = {x: f_unique_colors[x_id] for x_id, x in enumerate(f_unique)}\n",
    "            strip = sns.stripplot(\n",
    "                x=f_shap,\n",
    "                y=[f]*len(f_shap),\n",
    "                hue=f_vals,\n",
    "                palette=f_palette,\n",
    "                hue_order=f_unique,\n",
    "                jitter=0.35,\n",
    "                label=f,\n",
    "                alpha=0.5,\n",
    "                edgecolor='gray',\n",
    "                linewidth=0.1,\n",
    "                size=25 / np.sqrt(ds_results.loc[ds_results['Group'] == 'Test', :].shape[0]),\n",
    "                legend=True,\n",
    "                ax=axs[1],\n",
    "            )\n",
    "            sns.move_legend(strip, \"upper left\", bbox_to_anchor=(1.3, 1), ncol=1, title='Категориальные\\nпризнаки', title_font=dict(size='large'), frameon=False) \n",
    "          \n",
    "    axs[1].set_xlabel('SHAP: Влияние на предсказание модели')\n",
    "    fig.savefig(f\"{datasets[ds]['path']}/model_importance.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{datasets[ds]['path']}/model_importance.pdf\", bbox_inches='tight')\n",
    "    ds_shap.to_excel(f\"{datasets[ds]['path']}/model_importance.xlsx\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stupid bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"D:/YandexDisk/Work/bbd/atlas\"\n",
    "\n",
    "feat_trgt = 'Возраст'\n",
    "\n",
    "datasets = {\n",
    "    'lab': \n",
    "        {\n",
    "            'name': 'Анализ Крови',\n",
    "            'path': f\"{path}/subset_lab\",\n",
    "            'path_model': f\"{path}/subset_lab/models/DANet/446\", \n",
    "            'color': 'crimson'\n",
    "        },\n",
    "}\n",
    "\n",
    "for ds in datasets:\n",
    "    ds_data = pd.read_excel(f\"{datasets[ds]['path']}/data.xlsx\", index_col=0)\n",
    "    ds_feats = pd.read_excel(f\"{datasets[ds]['path']}/feats.xlsx\", index_col=0)\n",
    "    ds_results = pd.read_excel(f\"{datasets[ds]['path_model']}/df.xlsx\", index_col=0)\n",
    "    ds_corrector = LinearBiasCorrector()\n",
    "    stupid_selection = (ds_results['Group'] == 'Train') & ((ds_results[feat_trgt] < 30) | (ds_results[feat_trgt] > 60))\n",
    "    stupid_data_for_fit = ds_results.loc[stupid_selection, :]\n",
    "    print(stupid_data_for_fit.shape)\n",
    "    ds_corrector.fit(stupid_data_for_fit.loc[:, feat_trgt].values, stupid_data_for_fit.loc[:, 'Prediction'].values)\n",
    "    ds_results['Prediction Unbiased'] = ds_corrector.predict(ds_results['Prediction'].values)\n",
    "    ds_results['Error Unbiased'] = ds_results['Prediction Unbiased'] - ds_results[feat_trgt]\n",
    "    \n",
    "    xy_min = ds_results[[feat_trgt, 'Prediction']].min().min()\n",
    "    xy_max = ds_results[[feat_trgt, 'Prediction']].max().max()\n",
    "    xy_ptp = xy_max - xy_min\n",
    "    \n",
    "    xy_min_unbiased = ds_results[[feat_trgt, 'Prediction Unbiased']].min().min()\n",
    "    xy_max_unbiased = ds_results[[feat_trgt, 'Prediction Unbiased']].max().max()\n",
    "    xy_ptp_unbiased = xy_max_unbiased - xy_min_unbiased\n",
    "    \n",
    "    colors_groups = {\n",
    "        'Train': 'chartreuse',\n",
    "        'Validation': 'dodgerblue',\n",
    "        'Test': 'crimson',\n",
    "    }\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "    for group in colors_groups.keys():    \n",
    "        regplot = sns.regplot(\n",
    "            data=ds_results.loc[ds_results['Group'] == group, :],\n",
    "            x=feat_trgt,\n",
    "            y=\"Prediction\",\n",
    "            label=group,\n",
    "            color=colors_groups[group],\n",
    "            scatter_kws=dict(\n",
    "                linewidth=0.2,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                s=20,\n",
    "            ),\n",
    "            ax=ax\n",
    "        )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        y=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    ax.set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    fig.savefig(f\"{datasets[ds]['path']}/stupid/regplot.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{datasets[ds]['path']}/stupid/regplot.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "    for group in colors_groups.keys():    \n",
    "        regplot = sns.regplot(\n",
    "            data=ds_results.loc[ds_results['Group'] == group, :],\n",
    "            x=feat_trgt,\n",
    "            y=\"Prediction Unbiased\",\n",
    "            label=group,\n",
    "            color=colors_groups[group],\n",
    "            scatter_kws=dict(\n",
    "                linewidth=0.2,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                s=20,\n",
    "            ),\n",
    "            ax=ax\n",
    "        )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min_unbiased - 0.1 * xy_ptp_unbiased, xy_max_unbiased + 0.1 * xy_ptp_unbiased],\n",
    "        y=[xy_min_unbiased - 0.1 * xy_ptp_unbiased, xy_max_unbiased + 0.1 * xy_ptp_unbiased],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlim(xy_min_unbiased - 0.1 * xy_ptp, xy_max_unbiased + 0.1 * xy_ptp_unbiased)\n",
    "    ax.set_ylim(xy_min_unbiased - 0.1 * xy_ptp, xy_max_unbiased + 0.1 * xy_ptp_unbiased)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    fig.savefig(f\"{datasets[ds]['path']}/stupid/regplot_unbiased.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{datasets[ds]['path']}/stupid/regplot_unbiased.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local explainability checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel.load_model(f\"{path}/models/DANet/1/261\")\n",
    "results = pd.read_excel(f\"{path}/models/DANet/1/261/df.xlsx\", index_col=0)\n",
    "res_cols = ['Group', 'Prediction', 'Error', 'Prediction Unbiased', 'Error Unbiased']\n",
    "data.loc[data.index, res_cols] = results.loc[data.index, res_cols]\n",
    "corrector = LinearBiasCorrector()\n",
    "corrector.fit(data.loc[data['Group'] == 'Train', feat_trgt].values, data.loc[data['Group'] == 'Train', 'Prediction'].values)\n",
    "\n",
    "data_shap = data.copy()\n",
    "cat_encoders = {}\n",
    "for f in feats_cat:\n",
    "    cat_encoders[f] = LabelEncoder()\n",
    "    data_shap[f] = cat_encoders[f].fit_transform(data_shap[f])\n",
    "\n",
    "def predict_func(X):\n",
    "    X_df = pd.DataFrame(data=X, columns=feats)\n",
    "    for f in feats_cat:\n",
    "        X_df[f] = cat_encoders[f].inverse_transform(X_df[f].astype(int).values)\n",
    "    y = model.predict(X_df)[f'{feat_trgt}_prediction'].values\n",
    "    y = corrector.predict(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgt_id = 82235 # 1159\n",
    "trgt_age = data_shap.at[trgt_id, feat_trgt]\n",
    "trgt_pred = data_shap.at[trgt_id, 'Prediction Unbiased']\n",
    "trgt_aa = trgt_pred - trgt_age\n",
    "print(trgt_age)\n",
    "print(trgt_pred)\n",
    "\n",
    "n_closest = 32\n",
    "data_closest = data_shap.iloc[(data_shap['Prediction Unbiased'] - trgt_age).abs().argsort()[:n_closest]]\n",
    "\n",
    "explainer = shap.SamplingExplainer(predict_func, data_closest.loc[:, feats].values)\n",
    "print(explainer.expected_value)\n",
    "shap_values = explainer.shap_values(data_shap.loc[[trgt_id], feats].values)[0]\n",
    "shap_values = shap_values * (trgt_pred - trgt_age) / (trgt_pred - explainer.expected_value)\n",
    "\n",
    "# shap.plots.waterfall(\n",
    "#     shap.Explanation(\n",
    "#         values=shap_values,\n",
    "#         base_values=trgt_age,\n",
    "#         data=data.loc[trgt_id, feats].values,\n",
    "#         feature_names=feats\n",
    "#     ),\n",
    "#     max_display=len(feats),\n",
    "#     show=True,\n",
    "# )\n",
    "\n",
    "df_shap = pd.DataFrame(index=feats, data=shap_values, columns=[trgt_id])\n",
    "df_shap.sort_values(by=trgt_id, key=abs, inplace=True)\n",
    "df_shap['cumsum'] = df_shap[trgt_id].cumsum()\n",
    "\n",
    "df_less_more = pd.DataFrame(index=df_shap.index, columns=['Less', 'More'])\n",
    "df_cat_part = {}\n",
    "for f_id, f in enumerate(df_less_more.index):\n",
    "    if df_feats.at[f, 'Type'] != 'categorical':\n",
    "        df_less_more.at[f, 'Меньше'] = round(scipy.stats.percentileofscore(data_closest.loc[:, f].values, data_shap.at[trgt_id, f]))\n",
    "        df_less_more.at[f, 'Больше'] = 100.0 - df_less_more.at[f, 'Меньше']\n",
    "    else:\n",
    "        df_less_more.at[f, 'Меньше'] = np.nan\n",
    "        df_less_more.at[f, 'Больше'] = np.nan\n",
    "        \n",
    "        f_value_counts = data_closest.loc[:, 'Пол'].value_counts()\n",
    "        f_value_counts_rename = {x: cat_encoders['Пол'].inverse_transform([x])[0] for x in f_value_counts.index.astype(int).values}\n",
    "        f_value_counts.rename(index=f_value_counts_rename, inplace=True)\n",
    "        f_value_counts = np.rint(f_value_counts / f_value_counts.sum() * 100)\n",
    "        \n",
    "        df_cat_part[f_id] = {\n",
    "            'name': f,\n",
    "            'distribution': f_value_counts.astype(int)\n",
    "        }\n",
    "        if f == 'Пол':\n",
    "            df_cat_part[f_id]['palette'] = {'жен': 'crimson', 'муж': 'dodgerblue'}\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, shared_yaxes=True, shared_xaxes=False, column_widths=[2.5, 1], horizontal_spacing=0.05, subplot_titles=['', \"Распределение признаков у людей<br>в данном возрастном диапазоне\"])\n",
    "fig.add_trace(\n",
    "    go.Waterfall(\n",
    "        hovertext=[\"Хронологический возраст\", \"Биологический возраст\"],\n",
    "        orientation=\"h\",\n",
    "        measure=['absolute', 'relative'],\n",
    "        y=[-1.5, df_shap.shape[0] + 0.5],\n",
    "        x=[trgt_age, trgt_aa],\n",
    "        base=0,\n",
    "        text=[f\"{trgt_age:0.2f}\", f\"+{trgt_aa:0.2f}\" if trgt_aa > 0 else f\"{trgt_aa:0.2f}\"],\n",
    "        textposition = \"auto\",\n",
    "        decreasing = {\"marker\":{\"color\": \"deepskyblue\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        increasing = {\"marker\":{\"color\": \"crimson\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        totals= {\"marker\":{\"color\": \"dimgray\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        connector={\n",
    "            \"mode\": \"between\",\n",
    "            \"line\": {\"width\": 1, \"color\": \"black\", \"dash\": \"dot\"},\n",
    "        },\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Waterfall(\n",
    "        hovertext=df_shap.index.values,\n",
    "        orientation=\"h\",\n",
    "        measure=[\"relative\"] * len(feats),\n",
    "        y=list(range(df_shap.shape[0])),\n",
    "        x=df_shap[trgt_id].values,\n",
    "        base=trgt_age,\n",
    "        text=[f\"+{x:0.2f}\" if x > 0 else f\"{x:0.2f}\" for x in df_shap[trgt_id].values],\n",
    "        textposition = \"auto\",\n",
    "        decreasing = {\"marker\":{\"color\": \"lightblue\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        increasing = {\"marker\":{\"color\": \"lightcoral\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        connector={\n",
    "            \"mode\": \"between\",\n",
    "            \"line\": {\"width\": 1, \"color\": \"black\", \"dash\": \"solid\"},\n",
    "        },\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.update_traces(row=1, col=1, showlegend=False)\n",
    "fig.update_yaxes(\n",
    "    row=1,\n",
    "    col=1,\n",
    "    automargin=True,\n",
    "    tickmode=\"array\",\n",
    "    tickvals=[-1.5] + list(range(df_shap.shape[0])) + [df_shap.shape[0] + 0.5],\n",
    "    ticktext=[\"Хронологический возраст\"] + [f\"{x} = {data.at[trgt_id, x]:0.2f}\" if df_feats.at[x, 'Type'] != 'categorical' else f\"{x} = {data.at[trgt_id, x]}\" for x in df_shap.index] + [\"Биологический возраст\"],\n",
    "    tickfont=dict(size=18),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    row=1,\n",
    "    col=1,\n",
    "    automargin=True,\n",
    "    title='Возраст',\n",
    "    titlefont=dict(size=25),\n",
    "    range=[\n",
    "        trgt_age - df_shap['cumsum'].abs().max() * 1.25,\n",
    "        trgt_age + df_shap['cumsum'].abs().max() * 1.25\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        hovertext=df_shap.index.values,\n",
    "        orientation=\"h\",\n",
    "        name='Меньше',\n",
    "        x=df_less_more.loc[df_shap.index.values, 'Меньше'],\n",
    "        y=list(range(df_shap.shape[0])),\n",
    "        marker=dict(color='steelblue', line=dict(color=\"black\", width=1)),\n",
    "        text=df_less_more.loc[df_shap.index.values, 'Меньше'],\n",
    "        textposition='auto'\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        hovertext=df_shap.index.values,\n",
    "        orientation=\"h\",\n",
    "        name='Больше',\n",
    "        x=df_less_more.loc[df_shap.index.values, 'Больше'],\n",
    "        y=list(range(df_shap.shape[0])),\n",
    "        marker=dict(color='violet', line=dict(color=\"black\", width=1)),\n",
    "        text=df_less_more.loc[df_shap.index.values, 'Больше'],\n",
    "        textposition='auto',\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2\n",
    ")\n",
    "\n",
    "for f_cat_id, f_cat_dict in df_cat_part.items():\n",
    "    for f_val in f_cat_dict['distribution'].index:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                hovertext=[f_cat_dict['name']],\n",
    "                orientation=\"h\",\n",
    "                name=f_val,\n",
    "                x=[f_cat_dict['distribution'][f_val]],\n",
    "                y=[f_cat_id],\n",
    "                marker=dict(color=f_cat_dict['palette'][f_val], line=dict(color=\"black\", width=1)),\n",
    "                text=[f_val],\n",
    "                textposition='auto',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2\n",
    "        )\n",
    "\n",
    "fig.update_xaxes(\n",
    "    row=1,\n",
    "    col=2,\n",
    "    automargin=True,\n",
    "    showgrid=False,\n",
    "    showline=False,\n",
    "    zeroline=False,\n",
    "    showticklabels=False,\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    row=1,\n",
    "    col=2,\n",
    "    automargin=True,\n",
    "    showgrid=False,\n",
    "    showline=False,\n",
    "    zeroline=False,\n",
    "    showticklabels=False,\n",
    "    # tickmode=\"array\",\n",
    "    # tickvals=list(range(df_less_more.shape[0])),\n",
    "    # ticktext=[f\"{data.at[trgt_id, x]:0.2f}\" if df_feats.at[x, 'Type'] != 'categorical' else data.at[trgt_id, x] for x in df_less_more.index],\n",
    "    # tickfont=dict(size=18),\n",
    "    # showticklabels=True\n",
    ")\n",
    "fig.update_layout(barmode=\"stack\")\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        title=dict(side=\"top\"),\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=0.95,\n",
    "        xanchor=\"center\",\n",
    "        x=0.84\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Возрастная акселерация для {trgt_id}\",\n",
    "    titlefont=dict(size=25),\n",
    "    template=\"none\",\n",
    "    width=1200,\n",
    "    height=1000,\n",
    "    margin=go.layout.Margin(l=120, r=80, b=50, t=50, pad=0),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
