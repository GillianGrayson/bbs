{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from plotly.subplots import make_subplots\n",
    "from pytorch_tabular import TabularModel\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "from src.utils.hash import dict_hash\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "from plottable import ColumnDefinition, Table\n",
    "from scipy.stats import chi2_contingency\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import optuna\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.cm\n",
    "import matplotlib as mpl\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import re\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from itertools import chain\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import mannwhitneyu, variation, levene, zscore\n",
    "import pyaging as pya\n",
    "import matplotlib.lines as mlines\n",
    "from src.models.simage.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "import statsmodels.formula.api as smf\n",
    "from itertools import chain\n",
    "from pingouin import ancova\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from functools import reduce\n",
    "import upsetplot\n",
    "from src.plot.plotly_layout import add_layout\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Cm, Mm, Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "from docx.shared import RGBColor\n",
    "from pathlib import Path\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "import functools\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)\n",
    "\n",
    "    # Добавление текста с форматированием\n",
    "    fragments = []\n",
    "    last_pos = 0\n",
    "    \n",
    "    # Разделение текста на фрагменты с форматированием\n",
    "    for match in bold_re.finditer(text):\n",
    "        start, end = match.start(), match.end()\n",
    "        if last_pos < start:\n",
    "            fragments.append(('normal', text[last_pos:start]))\n",
    "        fragments.append(('bold', match.group(2)))\n",
    "        last_pos = end\n",
    "    \n",
    "    if last_pos < len(text):\n",
    "        fragments.append(('normal', text[last_pos:]))\n",
    "    \n",
    "    # Обработка курсива внутри оставшихся фрагментов\n",
    "    final_fragments = []\n",
    "    for frag_type, content in fragments:\n",
    "        if frag_type == 'bold':\n",
    "            final_fragments.append(('bold', content))\n",
    "            continue\n",
    "            \n",
    "        sub_last = 0\n",
    "        for match in italic_re.finditer(content):\n",
    "            start, end = match.start(), match.end()\n",
    "            if sub_last < start:\n",
    "                final_fragments.append(('normal', content[sub_last:start]))\n",
    "            final_fragments.append(('italic', match.group(2)))\n",
    "            sub_last = end\n",
    "        \n",
    "        if sub_last < len(content):\n",
    "            final_fragments.append(('normal', content[sub_last:]))\n",
    "    \n",
    "    # Добавление фрагментов в параграф\n",
    "    for frag_type, content in final_fragments:\n",
    "        run = paragraph.add_run(content)\n",
    "        if frag_type == 'bold':\n",
    "            run.bold = True\n",
    "        elif frag_type == 'italic':\n",
    "            run.italic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping for full selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"E:/YandexDisk/Work/bbd/fmba/associations/dnam/Special Status/mapping_comparison\"\n",
    "path_draft = \"E:/YandexDisk/Work/pydnameth/draft/13_fmba_cvd_dnam/data/120_1\"\n",
    "\n",
    "df_1 = pd.read_excel(f\"{path}/2025_05.xlsx\", index_col=0)\n",
    "ctrls_1 = df_1.index[df_1['Special Status'] == 'Control'].tolist()\n",
    "cases_1 = df_1.index[df_1['Special Status'] == 'Case'].tolist()\n",
    "\n",
    "df_2 = pd.read_excel(f\"{path}/2025_11.xlsx\", index_col=0)\n",
    "ctrls_2 = df_2.index[df_2['Special Status'] == 'Control'].tolist()\n",
    "cases_2 = df_2.index[df_2['Special Status'] == 'Case'].tolist()\n",
    "\n",
    "df_ori = pd.read_excel(f\"{path_draft}/pheno_funnorm.xlsx\", index_col=0)\n",
    "display(len(df_ori.index.intersection(df_1.index)))\n",
    "\n",
    "display(list(set(ctrls_1) - set(ctrls_2)))\n",
    "\n",
    "display(list(set(cases_1) - set(cases_2)))\n",
    "display(list(set(cases_2) - set(cases_1)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "venn = venn2(\n",
    "    subsets=(set(ctrls_1), set(ctrls_2)),\n",
    "    set_labels = ('Old', 'New'),\n",
    "    set_colors=('chartreuse', 'red'),\n",
    "    alpha = 0.8\n",
    ")\n",
    "venn2_circles(\n",
    "    subsets=(set(ctrls_1), set(ctrls_2)),\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{path}/venn_ctrls.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/venn_ctrls.pdf\", bbox_inches='tight', dpi=400)\n",
    "plt.clf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "venn = venn2(\n",
    "    subsets=(set(cases_1), set(cases_2)),\n",
    "    set_labels = ('Old', 'New'),\n",
    "    set_colors=('chartreuse', 'red'),\n",
    "    alpha = 0.8\n",
    ")\n",
    "venn2_circles(\n",
    "    subsets=(set(cases_1), set(cases_2)),\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{path}/venn_cases.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/venn_cases.pdf\", bbox_inches='tight', dpi=400)\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"E:/YandexDisk/Work/bbd/fmba/associations/dnam/Special Status/mapping_comparison\"\n",
    "path_draft = \"E:/YandexDisk/Work/pydnameth/draft/13_fmba_cvd_dnam/data/120_1\"\n",
    "\n",
    "df_1 = pd.read_excel(f\"{path}/2025_05.xlsx\", index_col=0)\n",
    "df_2 = pd.read_excel(f\"{path}/2025_11.xlsx\", index_col=0)\n",
    "df_ori = pd.read_excel(f\"{path_draft}/pheno_funnorm.xlsx\", index_col=0)\n",
    "\n",
    "index_cmn = df_2.index.intersection(df_ori.index).values\n",
    "\n",
    "df_2.loc[index_cmn, 'Special Status Old'] = df_ori.loc[index_cmn, 'Special Status']\n",
    "df_2.to_excel(f\"{path}/ololo.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
