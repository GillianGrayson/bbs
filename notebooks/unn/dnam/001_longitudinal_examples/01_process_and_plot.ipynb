{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from plotly.subplots import make_subplots\n",
    "from pytorch_tabular import TabularModel\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import optuna\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.cm\n",
    "import matplotlib as mpl\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import re\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from itertools import chain\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pyaging as pya\n",
    "import matplotlib.lines as mlines\n",
    "import statsmodels.formula.api as smf\n",
    "from itertools import chain\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import upsetplot\n",
    "\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]\n",
    "\n",
    "\n",
    "def form_bar(base):\n",
    "    def formatter(x):\n",
    "        return f'{str(int(round(x * base)))}/{base}'\n",
    "    return formatter\n",
    "\n",
    "\n",
    "def get_sections(sets):\n",
    "    \"\"\"\n",
    "    Given a list of sets, return a new list of sets with all the possible\n",
    "    mutually exclusive overlapping combinations of those sets.  Another way\n",
    "    to think of this is the mutually exclusive sections of a venn diagram\n",
    "    of the sets.  If the original list has N sets, the returned list will\n",
    "    have (2**N)-1 sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sets : list of set\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    combinations : list of tuple\n",
    "        tag : str\n",
    "            Binary string representing which sets are included / excluded in\n",
    "            the combination.\n",
    "        set : set\n",
    "            The set formed by the overlapping input sets.\n",
    "    \"\"\"\n",
    "    num_combinations = 2 ** len(sets)\n",
    "    bit_flags = [2 ** n for n in range(len(sets))]\n",
    "    flags_zip_sets = [z for z in zip(bit_flags, sets)]\n",
    "\n",
    "    combo_sets = {}\n",
    "    for bits in range(num_combinations - 1, 0, -1):\n",
    "        include_sets = [s for flag, s in flags_zip_sets if bits & flag]\n",
    "        exclude_sets = [s for flag, s in flags_zip_sets if not bits & flag]\n",
    "        combo = set.intersection(*include_sets)\n",
    "        combo = set.difference(combo, *exclude_sets)\n",
    "        tag = ''.join([str(int((bits & flag) > 0)) for flag in bit_flags])\n",
    "        combo_sets[tag] = combo\n",
    "    return combo_sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process DNAm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betas to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/YandexDisk/Work/bbd/unn/dnam/001_longitudinal_examples\"\n",
    "pheno = pd.read_csv(f\"{path}/controls_from_central(169).csv\", index_col=0)\n",
    "pheno.index = pheno.index.astype(str)\n",
    "betas = pd.read_csv(f\"{path}/betas_funnorm.csv\", index_col=0).transpose()\n",
    "betas = betas.loc[pheno.index.values, :]\n",
    "betas.set_index(pheno['ID'], inplace=True)\n",
    "betas.to_pickle(f\"{path}/betas_funnorm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate epigenetic ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DNAm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/YandexDisk/Work/bbd/unn/dnam/001_longitudinal_examples\"\n",
    "pheno = pd.read_csv(f\"{path}/controls_from_central(169).csv\", index_col='ID')\n",
    "pheno.index = pheno.index.astype(str)\n",
    "betas = pd.read_pickle(f\"{path}/betas_funnorm.pkl\")\n",
    "\n",
    "feats_for_ages = ['Age', 'Sex', 'Tissue']\n",
    "\n",
    "df_for_ages = pd.merge(pheno[feats_for_ages], betas, left_index=True, right_index=True)\n",
    "\n",
    "df_for_ages['Female'] = (df_for_ages['Sex'] == 'F').astype(int)\n",
    "df_for_ages = pya.pp.epicv2_probe_aggregation(df_for_ages, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate pyaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clocks = \"E:/YandexDisk/Work/pydnameth/datasets/pyaging\"\n",
    "clocks = [\n",
    "    \"altumage\",\n",
    "    \"dunedinpace\",\n",
    "    \"han\",\n",
    "    \"knight\",\n",
    "    \"leecontrol\",\n",
    "    \"leerefinedrobust\",\n",
    "    \"leerobust\",\n",
    "    \"dnamfitage\",\n",
    "    \"dnamphenoage\",\n",
    "    \"dnamtl\",\n",
    "    \"encen100\",\n",
    "    \"encen40\",\n",
    "    \"grimage\",\n",
    "    \"grimage2\",\n",
    "    \"hannum\",\n",
    "    \"horvath2013\",\n",
    "    \"hrsinchphenoage\",\n",
    "    \"lin\",\n",
    "    \"pcdnamtl\",\n",
    "    \"pcgrimage\",\n",
    "    \"pchannum\",\n",
    "    \"pchorvath2013\",\n",
    "    \"pcphenoage\",\n",
    "    \"pcskinandblood\",\n",
    "    \"pedbe\",\n",
    "    \"replitali\",\n",
    "    \"skinandblood\",\n",
    "    \"stemtoc\",\n",
    "    \"stoch\",\n",
    "    \"stocp\",\n",
    "    \"stocz\",\n",
    "    \"yingadaptage\",\n",
    "    \"yingcausage\",\n",
    "    \"yingdamage\",\n",
    "    \"zhangblup\",\n",
    "    \"zhangen\",\n",
    "    \"zhangmortality\",\n",
    "    \"epitoc1\",\n",
    "    \"retroelementagev1\",\n",
    "    \"retroelementagev2\",\n",
    "    \"intrinclock\",\n",
    "    \"abec\",\n",
    "    \"cabec\",\n",
    "    \"eabec\",\n",
    "    \"pipekelasticnet\",\n",
    "    \"pipekfilteredh\",\n",
    "    \"pipekretrainedh\",\n",
    "    \"dnamic\"\n",
    "]\n",
    "\n",
    "adata = pya.pp.df_to_adata(df_for_ages, metadata_cols=['Sex', 'Tissue'], imputer_strategy='knn', verbose=True)\n",
    "pya.pred.predict_age(adata=adata, dir=path_clocks, clock_names=clocks, verbose=True)\n",
    "results = pd.merge(pheno, adata.obs[clocks], left_index=True, right_index=True)\n",
    "\n",
    "pyaging_meta = pd.read_excel(f\"{path_clocks}/clocks_meta_upd.xlsx\", index_col='Clock Name')\n",
    "pyaging_meta['Clock Name'] = pyaging_meta.index\n",
    "results.rename(columns=dict(zip(pyaging_meta['Model ID'].values, pyaging_meta['Clock Name'].values)), inplace=True)\n",
    "\n",
    "results.to_excel(f\"{path}/pheno.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate EpImAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_epim = \"E:/Git/EpImAge\"\n",
    "\n",
    "imms_epim = pd.read_excel(f\"{path_epim}/models/InflammatoryMarkers/InflammatoryMarkers.xlsx\", index_col='feature').index.values\n",
    "imms_epim_log = [f\"{f}_log\" for f in imms_epim]\n",
    "cpgs_epim = pd.read_excel(f\"{path_epim}/data/CpGs.xlsx\", index_col=0).index.to_list()\n",
    "cpgs_epim_missed = list(set(cpgs_epim) - set(df_for_ages.columns.values))\n",
    "cpgs_epim_present = list(set.intersection(set(cpgs_epim), set(df_for_ages.columns.values)))\n",
    "\n",
    "unn_samples = pd.read_excel(f\"{path_epim}/data/cytokines-regression/data.xlsx\", index_col=0)\n",
    "unn_samples = unn_samples.index[unn_samples['Status'] == 'Control'].values\n",
    "\n",
    "df_for_epim = df_for_ages.loc[:, ['Age'] + cpgs_epim_present]\n",
    "df_for_epim.loc[:, cpgs_epim_missed] = None\n",
    "\n",
    "models_imms = {}\n",
    "for imm in (pbar := tqdm(imms_epim)):\n",
    "    pbar.set_description(f\"Loading model for {imm}\")\n",
    "    models_imms[imm] = TabularModel.load_model(f\"{path_epim}/models/InflammatoryMarkers/{imm}\")\n",
    "\n",
    "model_age = TabularModel.load_model(f\"{path_epim}/models/EpInflammAge\")\n",
    "\n",
    "bkgrd_imp = pd.read_pickle(f\"{path_epim}/models/background-imputation.pkl\")\n",
    "# bkgrd_imp = bkgrd_imp.loc[bkgrd_imp.index.intersection(set(unn_samples)), :]\n",
    "\n",
    "imp_method = 'KNN'\n",
    "n_nans = df_for_epim.isna().sum().sum()\n",
    "if n_nans > 0:\n",
    "    bkgrd_imp.set_index(bkgrd_imp.index.astype(str) + f'_imputation_{imp_method}', inplace=True)\n",
    "    data_epim_all = pd.concat([df_for_epim, bkgrd_imp], axis=0, verify_integrity=True)\n",
    "    if imp_method == \"KNN\":\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "    data_epim_all.loc[:, cpgs_epim] = imputer.fit_transform(data_epim_all.loc[:, cpgs_epim].values) \n",
    "    df_for_epim.loc[df_for_epim.index, cpgs_epim] = data_epim_all.loc[df_for_epim.index, cpgs_epim]\n",
    "\n",
    "for imm in imms_epim:\n",
    "    df_for_epim[f\"{imm}_log\"] = models_imms[imm].predict(df_for_epim)\n",
    "df_for_epim['EpInflammAge'] = model_age.predict(df_for_epim.loc[:, [f\"{imm}_log\" for imm in imms_epim]])\n",
    "\n",
    "for f in ['EpInflammAge'] + imms_epim_log:\n",
    "    results.loc[results.index, f] = df_for_epim.loc[results.index, f]\n",
    "    \n",
    "results.to_excel(f\"{path}/pheno.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot epigenetic ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/YandexDisk/Work/bbd/unn/dnam/001_longitudinal_examples\"\n",
    "path_clocks = \"E:/YandexDisk/Work/pydnameth/datasets/pyaging\"\n",
    "\n",
    "df = pd.read_excel(f\"{path}/pheno.xlsx\", index_col=0)\n",
    "df.drop('I1_duplicate', inplace=True)\n",
    "\n",
    "pyaging_meta = pd.read_excel(f\"{path_clocks}/clocks_meta_upd.xlsx\", index_col='Clock Name')\n",
    "pyaging_meta['Clock Name'] = pyaging_meta.index\n",
    "pyaging_meta.drop(index=['Knight', 'LeeControl', 'LeeRefinedRobust', 'LeeRobust', 'PedBE', 'RepliTali', 'ENCen100', 'CpGPTGrimAge3', 'CpGPTPCGrimAge3',\n",
    "                         'GrimAge2ADM', 'GrimAge2B2M', 'GrimAge2CystatinC', 'GrimAge2GDF15', 'GrimAge2Leptin', 'GrimAge2LogA1C', 'GrimAge2LogCRP', 'GrimAge2PackYrs', 'GrimAge2PAI1', 'GrimAge2TIMP1', \n",
    "                         'DNAmFitAgeGaitF', 'DNAmFitAgeGaitM', 'DNAmFitAgeGripF', 'DNAmFitAgeGripM', 'DNAmFitAgeVO2Max', 'DNAmIC'], inplace=True)\n",
    "epi_ages = pyaging_meta[pyaging_meta['Type'] == 'Age'].index.to_list() + ['EpInflammAge']\n",
    "\n",
    "df['Group'] = 'Other'\n",
    "df.loc[df['Subject_ID'] == 'I1', 'Group'] = 'I1'\n",
    "df.loc[df['Subject_ID'] == 'I8', 'Group'] = 'I8'\n",
    "\n",
    "colors_groups = {\n",
    "    'Other': 'gray',\n",
    "    'I1': 'dodgerblue',\n",
    "    'I8': 'crimson',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40720\\1989089275.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['MarkerSize'] = 10\n"
     ]
    }
   ],
   "source": [
    "for epiage_id, epiage in enumerate(epi_ages):\n",
    "    linreg = smf.ols(formula=f\"{epiage} ~ Age\", data=df).fit()\n",
    "    df[f\"{epiage}_linear_pred\"] = linreg.predict(df)\n",
    "    df[f\"{epiage} acceleration (Linreg)\"] = df[epiage] - df[f\"{epiage}_linear_pred\"]\n",
    "    df[f\"{epiage} acceleration (True)\"] = df[epiage] - df[\"Age\"]\n",
    "    df[f\"{epiage} corrected\"] = df[\"Age\"] + df[f\"{epiage} acceleration (Linreg)\"]\n",
    "\n",
    "df['MarkerSize'] = 10\n",
    "df.loc[df['Subject_ID'] == 'I1', 'MarkerSize'] = 40\n",
    "df.loc[df['Subject_ID'] == 'I8', 'MarkerSize'] = 40\n",
    "\n",
    "nrows = 5\n",
    "ncols = 7\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig = plt.figure(\n",
    "    figsize=(30, 20),\n",
    "    layout=\"constrained\"\n",
    ")\n",
    "\n",
    "subfigs = fig.subfigures(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    # wspace=0.001,\n",
    "    # hspace=0.001,\n",
    ")\n",
    "for epiage_id, epiage in enumerate(epi_ages):\n",
    "    row_id, col_id = divmod(epiage_id, ncols)\n",
    "\n",
    "    axs = subfigs[row_id, col_id].subplot_mosaic(\n",
    "        [\n",
    "            ['11'],\n",
    "        ],\n",
    "        # height_ratios=[1, 4],\n",
    "        # width_ratios=[3, 1.5],\n",
    "        gridspec_kw={\n",
    "            # \"bottom\": 0.14,\n",
    "            # \"top\": 0.95,\n",
    "            # \"left\": 0.1,\n",
    "            # \"right\": 0.5,\n",
    "            # \"wspace\": 0.33,\n",
    "            # \"hspace\": 0.01,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    xy_min = df[['Age', epiage]].min().min()\n",
    "    xy_max = df[['Age', epiage]].max().max()\n",
    "    xy_ptp = xy_max - xy_min\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        y=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=axs['11']\n",
    "    )\n",
    "    regplot = sns.regplot(\n",
    "        data=df,\n",
    "        x='Age',\n",
    "        y=epiage,\n",
    "        color='black',\n",
    "        line_kws={'linewidth': 1},\n",
    "        scatter=False,\n",
    "        truncate=False,\n",
    "        ax=axs['11']\n",
    "    )\n",
    "    scatter = sns.scatterplot(\n",
    "        data=df,\n",
    "        x='Age',\n",
    "        y=epiage,\n",
    "        hue='Group',\n",
    "        palette=colors_groups,\n",
    "        linewidth=0.5,\n",
    "        alpha=0.75,\n",
    "        edgecolor=\"k\",\n",
    "        size='MarkerSize',\n",
    "        # s=20,\n",
    "        hue_order=list(colors_groups.keys()),\n",
    "        #legend=True,\n",
    "        ax=axs['11'],\n",
    "    )\n",
    "    \n",
    "    # To remove other legends, if they were generated\n",
    "    handles, labels = axs['11'].get_legend_handles_labels()\n",
    "    # Assuming 'species' is the first legend entry and you want to keep only that\n",
    "    # You might need to inspect 'labels' to find the correct indices for hue\n",
    "    if len(handles) > 1:\n",
    "        axs['11'].legend(handles=handles[0:4], labels=labels[0:4]) # Keep only the first legend (hue)\n",
    "    \n",
    "    axs['11'].set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    axs['11'].set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "\n",
    "fig.savefig(f\"{path}/ages_distribution.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path}/ages_distribution.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'I8'\n",
    "subject_ids = df[df['Subject_ID'] == subject].sort_values(by=['Age'], ascending=[True]).index.values\n",
    "\n",
    "nrows = 1\n",
    "ncols = len(subject_ids) * 2\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig = plt.figure(\n",
    "    figsize=(2 * ncols * 2, 10),\n",
    "    layout=\"constrained\"\n",
    ")\n",
    "\n",
    "subfigs = fig.subfigures(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    # wspace=0.001,\n",
    "    # hspace=0.001,\n",
    ")\n",
    "\n",
    "for plot_id, subject_id in enumerate(subject_ids):\n",
    "    df_subject_id = pd.DataFrame(index=epi_ages, columns=['Age acceleration (True)', 'Acceleration type (True)', 'Age acceleration (Linreg)', 'Acceleration type (Linreg)'])\n",
    "    df_subject_id['EpiAges'] = epi_ages\n",
    "    df_subject_id.loc[epi_ages, 'Age acceleration (True)'] = df.loc[subject_id, [f\"{epiage} acceleration (True)\" for epiage in epi_ages]].values\n",
    "    df_subject_id.loc[df_subject_id['Age acceleration (True)'] > 0, 'Acceleration type (True)'] = '+'\n",
    "    df_subject_id.loc[df_subject_id['Age acceleration (True)'] <= 0, 'Acceleration type (True)'] = '-'\n",
    "    df_subject_id.loc[epi_ages, 'Age acceleration (Linreg)'] = df.loc[subject_id, [f\"{epiage} acceleration (Linreg)\" for epiage in epi_ages]].values\n",
    "    df_subject_id.loc[df_subject_id['Age acceleration (Linreg)'] > 0, 'Acceleration type (Linreg)'] = '+'\n",
    "    df_subject_id.loc[df_subject_id['Age acceleration (Linreg)'] <= 0, 'Acceleration type (Linreg)'] = '-'\n",
    "    \n",
    "    df_subject_id.sort_values(by='Age acceleration (True)', key=abs, ascending=False, inplace=True)\n",
    "    max_x = df_subject_id['Age acceleration (True)'].abs().max()\n",
    "    axs = subfigs[plot_id].subplot_mosaic(\n",
    "        [\n",
    "            ['11'],\n",
    "        ],\n",
    "        # height_ratios=[1, 4],\n",
    "        # width_ratios=[3, 1.5],\n",
    "        gridspec_kw={\n",
    "            # \"bottom\": 0.14,\n",
    "            # \"top\": 0.95,\n",
    "            # \"left\": 0.1,\n",
    "            # \"right\": 0.5,\n",
    "            # \"wspace\": 0.33,\n",
    "            # \"hspace\": 0.01,\n",
    "        },\n",
    "    )\n",
    "    barplot = sns.barplot(\n",
    "        data=df_subject_id,\n",
    "        y='EpiAges',\n",
    "        x='Age acceleration (True)',\n",
    "        edgecolor='black',\n",
    "        palette={'+': 'crimson', '-': 'dodgerblue'},\n",
    "        hue='Acceleration type (True)',\n",
    "        ax=axs['11'],\n",
    "        legend=False,\n",
    "    )\n",
    "    axs['11'].set_xlim([-max_x * 1.2, max_x * 1.2])\n",
    "    axs['11'].set_ylabel('')\n",
    "    axs['11'].set_title(f\"{subject_id}: {df.at[subject_id, 'Age']:0.2f}\")\n",
    "    \n",
    "    df_subject_id.sort_values(by='Age acceleration (Linreg)', key=abs, ascending=False, inplace=True)\n",
    "    max_x = df_subject_id['Age acceleration (Linreg)'].abs().max()\n",
    "    axs = subfigs[len(subject_ids) + plot_id].subplot_mosaic(\n",
    "        [\n",
    "            ['11'],\n",
    "        ],\n",
    "        # height_ratios=[1, 4],\n",
    "        # width_ratios=[3, 1.5],\n",
    "        gridspec_kw={\n",
    "            # \"bottom\": 0.14,\n",
    "            # \"top\": 0.95,\n",
    "            # \"left\": 0.1,\n",
    "            # \"right\": 0.5,\n",
    "            # \"wspace\": 0.33,\n",
    "            # \"hspace\": 0.01,\n",
    "        },\n",
    "    )\n",
    "    barplot = sns.barplot(\n",
    "        data=df_subject_id,\n",
    "        y='EpiAges',\n",
    "        x='Age acceleration (Linreg)',\n",
    "        edgecolor='black',\n",
    "        palette={'+': 'crimson', '-': 'dodgerblue'},\n",
    "        hue='Acceleration type (Linreg)',\n",
    "        ax=axs['11'],\n",
    "        legend=False,\n",
    "    )\n",
    "    axs['11'].set_xlim([-max_x * 1.2, max_x * 1.2])\n",
    "    axs['11'].set_ylabel('')\n",
    "    axs['11'].set_title(f\"{subject_id}: {df.at[subject_id, 'Age']:0.2f}\")\n",
    "\n",
    "fig.savefig(f\"{path}/{subject}.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path}/{subject}.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
