{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import BaseCrossValidator, ParameterGrid, ParameterSampler\n",
    "from sklearn.impute import KNNImputer\n",
    "import torch\n",
    "import pickle\n",
    "import shutil\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "from regression_bias_corrector import LinearBiasCorrector\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import matplotlib.lines as mlines\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best models plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"E:/Git/MillenniumAge/data/small_models\"\n",
    "\n",
    "expl_type = 'current'\n",
    "\n",
    "feat_trgt = 'Возраст'\n",
    "\n",
    "feats_sets_models = {\n",
    "    'Биохимические исследования, женщины': 'Биохимические исследования/F',\n",
    "    'Биохимические исследования, мужчины': 'Биохимические исследования/M',\n",
    "    'Гематологические исследования, женщины': 'Гематологические исследования/F',\n",
    "    'Гематологические исследования, мужчины': 'Гематологические исследования/M',\n",
    "    'Оценка состава тела, женщины': 'Оценка состава тела/F',\n",
    "    'Оценка состава тела, мужчины': 'Оценка состава тела/M',\n",
    "    'Половые гормоны, женщины': 'Половые гормоны/F',\n",
    "    'Половые гормоны, мужчины': 'Половые гормоны/M',\n",
    "    'Электрокардиограмма': 'Электрокардиограмма',\n",
    "}\n",
    "\n",
    "colors_feats_sets = {\n",
    "    'Биохимические исследования, женщины': 'crimson',\n",
    "    'Биохимические исследования, мужчины': 'darkred',\n",
    "    'Гематологические исследования, женщины': 'orchid',\n",
    "    'Гематологические исследования, мужчины': 'fuchsia',\n",
    "    'Оценка состава тела, женщины': 'mediumblue',\n",
    "    'Оценка состава тела, мужчины': 'darkblue',\n",
    "    'Половые гормоны, женщины': 'gold',\n",
    "    'Половые гормоны, мужчины': 'orange',\n",
    "    'Электрокардиограмма': '#088F8F',\n",
    "}\n",
    "\n",
    "for feats_set, feats_set_path in feats_sets_models.items():\n",
    "    data = pd.read_excel(f\"{path}/{feats_set_path}/data.xlsx\", index_col=0)\n",
    "    feats = pd.read_excel(f\"{path}/{feats_set_path}/feats.xlsx\", index_col=0)\n",
    "    results = pd.read_excel(f\"{path}/{feats_set_path}/model/df.xlsx\", index_col=0)\n",
    "    metrics = pd.read_excel(f\"{path}/{feats_set_path}/model/metrics.xlsx\", index_col=0)\n",
    "    df_shap = pd.read_excel(f\"{path}/{feats_set_path}/model/explanation.xlsx\", index_col=0)\n",
    "    model = TabularModel.load_model(f\"{path}/{feats_set_path}/model\")\n",
    "    corrector = LinearBiasCorrector()\n",
    "    corrector.fit(results.loc[results['Group'] == 'Train', feat_trgt].values, results.loc[results['Group'] == 'Train', 'Prediction'].values)\n",
    "    \n",
    "    \n",
    "    sns.set_theme(style='ticks')\n",
    "    fig = plt.figure(\n",
    "        figsize=(8, 5 + 1.5 + 0.15 * feats.shape[0]),\n",
    "        layout=\"constrained\"\n",
    "    )\n",
    "    subfigs = fig.subfigures(\n",
    "        nrows=2,\n",
    "        ncols=1,\n",
    "        height_ratios=[5, 1.5 + 0.15 * feats.shape[0]],\n",
    "        wspace=0.01,\n",
    "        hspace=0.01,\n",
    "    )\n",
    "    \n",
    "    subfigs_row = subfigs[0].subfigures(\n",
    "        nrows=1,\n",
    "        ncols=1,\n",
    "        # width_ratios=[1, 1],\n",
    "        wspace=0.15,\n",
    "        hspace=0.01,\n",
    "    )\n",
    "    \n",
    "    axs = subfigs_row.subplot_mosaic(\n",
    "        [\n",
    "            ['table', 'table'],\n",
    "            ['scatter', 'violin'],\n",
    "        ],\n",
    "        # figsize=(6, 1.5 + 6),\n",
    "        height_ratios=[1, 4],\n",
    "        width_ratios=[3, 1.5],\n",
    "        gridspec_kw={\n",
    "            # \"bottom\": 0.14,\n",
    "            # \"top\": 0.95,\n",
    "            # \"left\": 0.1,\n",
    "            # \"right\": 0.5,\n",
    "            \"wspace\": 0.01,\n",
    "            \"hspace\": 0.01,\n",
    "        },\n",
    "    )\n",
    "    subfigs_row.suptitle(feats_set, fontsize='large')\n",
    "\n",
    "    df_table = pd.DataFrame(index=['MAE', fr\"Pearson $\\mathbf{{\\rho}}$\", \"Bias\"], columns=['Train', 'Validation', 'Test'])\n",
    "    for part in ['Train', 'Validation', 'Test']:\n",
    "        df_table.at['MAE', part] = f\"{metrics.at[part, 'mean_absolute_error_unbiased']:0.3f}\"\n",
    "        df_table.at[fr\"Pearson $\\mathbf{{\\rho}}$\", part] = f\"{metrics.at[part, 'pearson_corrcoef_unbiased']:0.3f}\"\n",
    "        df_table.at[\"Bias\", part] = f\"{metrics.at[part, 'bias_unbiased']:0.3f}\"\n",
    "\n",
    "    col_defs = [\n",
    "        ColumnDefinition(\n",
    "            name=\"index\",\n",
    "            title='',\n",
    "            textprops={\"ha\": \"center\", \"weight\": \"bold\"},\n",
    "            width=2.5,\n",
    "            # border=\"both\",\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Train\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "            border=\"left\",\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Validation\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Test\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "        )\n",
    "    ]\n",
    "    table = Table(\n",
    "        df_table,\n",
    "        column_definitions=col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        ax=axs['table'],\n",
    "        textprops={\"fontsize\": 8},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=['Train', 'Validation', 'Test'])\n",
    "\n",
    "    xy_min, xy_max = np.quantile(results[[feat_trgt, 'Prediction Unbiased']].values.flatten(), [0.01, 0.99])\n",
    "    xy_ptp = xy_max - xy_min\n",
    "\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=results.loc[results['Group'].isin(['Train', 'Validation']), :],\n",
    "        x=feat_trgt,\n",
    "        y='Prediction Unbiased',\n",
    "        fill=True,\n",
    "        cbar=False,\n",
    "        thresh=0.05,\n",
    "        color=colors_feats_sets[feats_set],\n",
    "        legend=False,\n",
    "        ax=axs['scatter']\n",
    "    )\n",
    "    scatter = sns.scatterplot(\n",
    "        data=results.loc[results['Group'] == 'Test', :],\n",
    "        x=feat_trgt,\n",
    "        y=\"Prediction Unbiased\",\n",
    "        linewidth=0.5,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"k\",\n",
    "        s=25,\n",
    "        color=colors_feats_sets[feats_set],\n",
    "        ax=axs['scatter'],\n",
    "    )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp],\n",
    "        y=[xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=axs['scatter']\n",
    "    )\n",
    "    regplot = sns.regplot(\n",
    "        data=results.loc[results['Group'] == 'Train', :],\n",
    "        x=feat_trgt,\n",
    "        y='Prediction Unbiased',\n",
    "        color='k',\n",
    "        scatter=False,\n",
    "        truncate=False,\n",
    "        ax=axs['scatter']\n",
    "    )\n",
    "    axs['scatter'].set_xlim(xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp)\n",
    "    axs['scatter'].set_ylim(xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp)\n",
    "    axs['scatter'].set_ylabel(\"Биологический возраст\")\n",
    "    axs['scatter'].set_xlabel(\"Возраст\")\n",
    "\n",
    "    violin = sns.violinplot(\n",
    "        data=results.loc[results['Group'].isin(['Train', 'Validation']), :],\n",
    "        x=[0] * results.loc[results['Group'].isin(['Train', 'Validation']), :].shape[0],\n",
    "        y='Error Unbiased',\n",
    "        color=make_rgb_transparent(mcolors.to_rgb(colors_feats_sets[feats_set]), (1, 1, 1), 0.5),\n",
    "        density_norm='width',\n",
    "        saturation=0.75,\n",
    "        linewidth=1.0,\n",
    "        ax=axs['violin'],\n",
    "        legend=False,\n",
    "    )\n",
    "    swarm = sns.swarmplot(\n",
    "        data=results.loc[results['Group'] == 'Test', :],\n",
    "        x=[0] * results.loc[results['Group'] == 'Test', :].shape[0],\n",
    "        y='Error Unbiased',\n",
    "        color=colors_feats_sets[feats_set],\n",
    "        linewidth=0.5,\n",
    "        ax=axs['violin'],\n",
    "        size= 50 / np.sqrt(results.loc[results['Group'] == 'Test', :].shape[0]),\n",
    "        legend=False,\n",
    "    )\n",
    "    axs['violin'].set_ylabel('Возрастная акселерация')\n",
    "    axs['violin'].set_xlabel('')\n",
    "    axs['violin'].set(xticklabels=[]) \n",
    "    axs['violin'].set(xticks=[])\n",
    "    \n",
    "    \n",
    "    if expl_type == 'recalc_gradient':\n",
    "        df_shap = model.explain(data, method=\"GradientShap\", baselines=\"b|100000\")\n",
    "        df_shap.index = data.index\n",
    "    elif expl_type == 'recalc_sampling':\n",
    "        ds_data_shap = data.copy()\n",
    "        ds_cat_encoders = {}\n",
    "        for f in feats.index:\n",
    "            ds_cat_encoders[f] = LabelEncoder()\n",
    "            ds_data_shap[f] = ds_cat_encoders[f].fit_transform(ds_data_shap[f])\n",
    "        def predict_func(X):\n",
    "            X_df = pd.DataFrame(data=X, columns=feats.index.to_list())\n",
    "            for f in feats.index:\n",
    "                X_df[f] = ds_cat_encoders[f].inverse_transform(X_df[f].astype(int).values)\n",
    "            y = model.predict(X_df)[f'{feat_trgt}_prediction'].values\n",
    "            y = corrector.predict(y)\n",
    "            return y\n",
    "        explainer = shap.SamplingExplainer(predict_func, ds_data_shap.loc[:, feats.index.to_list()].values)\n",
    "        print(explainer.expected_value)\n",
    "        shap_values = explainer.shap_values(ds_data_shap.loc[:, feats.index.to_list()].values)\n",
    "        df_shap = pd.DataFrame(index=data.index, columns=feats.index.to_list(), data=shap_values)\n",
    "\n",
    "    \n",
    "    ds_fi = pd.DataFrame(index=feats.index.to_list(), columns=['mean(|SHAP|)', 'rho'])\n",
    "    for f in feats.index.to_list():\n",
    "        ds_fi.at[f, 'mean(|SHAP|)'] = df_shap[f].abs().mean()\n",
    "        df_tmp = data.loc[:, [feat_trgt, f]].dropna(axis=0, how='any')\n",
    "        if df_tmp.shape[0] > 1:\n",
    "            vals_1 = df_tmp.loc[:, feat_trgt].values\n",
    "            vals_2 = df_tmp.loc[:, f].values\n",
    "            ds_fi.at[f, 'rho'], _ = scipy.stats.pearsonr(vals_1, vals_2)\n",
    "    ds_fi.sort_values(['mean(|SHAP|)'], ascending=[False], inplace=True)\n",
    "    ds_fi['Features'] = ds_fi.index.values\n",
    "    \n",
    "    axs_importance = subfigs[1].subplots(1, 2, width_ratios=[1, 4], gridspec_kw={'wspace':0.02, 'hspace': 0.02}, sharey=False, sharex=False)\n",
    "    \n",
    "    heatmap = sns.heatmap(\n",
    "        ds_fi.loc[:, ['rho']].apply(pd.to_numeric).values,\n",
    "        yticklabels=ds_fi.index.to_list(),\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        vmin=-1.0,\n",
    "        vmax=1.0,\n",
    "        cmap='coolwarm',\n",
    "        linewidth=0.1,\n",
    "        linecolor='black',\n",
    "        cbar=False,\n",
    "        #annot_kws={\"fontsize\": 15},\n",
    "        # cbar_kws={\n",
    "        #     # \"shrink\": 0.9,\n",
    "        #     # \"aspect\": 30,\n",
    "        #     #'fraction': 0.046, \n",
    "        #     #'pad': 0.04,\n",
    "        # },\n",
    "        ax=axs_importance[0]\n",
    "    )\n",
    "    # axs_importance[0].set(yticklabels=ds_fi.index.to_list())\n",
    "    # heatmap_pos = axs_importance[2].get_position()\n",
    "    # axs_importance[2].figure.axes[-1].set_position([heatmap_pos.x1 + 0.05, heatmap_pos.y0, 0.1, heatmap_pos.height])\n",
    "    # axs_importance[2].figure.axes[-1].set_ylabel(r\"Pearson $\\rho$\")\n",
    "    # for spine in axs_importance[2].figure.axes[-1].spines.values():\n",
    "    #     spine.set(visible=True, lw=0.25, edgecolor=\"black\")\n",
    "    # axs_importance[2].set_xlabel('')\n",
    "    # axs_importance[2].set_ylabel('')\n",
    "    # axs_importance[2].set(xticklabels=[])\n",
    "    # axs_importance[2].set(xticks=[])\n",
    "    \n",
    "    \n",
    "    barplot = sns.barplot(\n",
    "        data=ds_fi,\n",
    "        x='mean(|SHAP|)',\n",
    "        y='Features',\n",
    "        color=colors_feats_sets[feats_set],\n",
    "        edgecolor='black',\n",
    "        dodge=False,\n",
    "        ax=axs_importance[1]\n",
    "    )\n",
    "    for container in barplot.containers:\n",
    "        barplot.bar_label(container, label_type='edge', color='gray', fmt='%0.2f', fontsize=12, padding=4.0)\n",
    "    axs_importance[1].set_ylabel('')\n",
    "    # axs_importance[1].set(yticklabels=ds_fi.index.to_list())\n",
    "    axs_importance[1].set(yticklabels=[])\n",
    "\n",
    "    # is_colorbar = False\n",
    "    # f_legends = []\n",
    "    # for f in ds_fi.index:\n",
    "        \n",
    "    #     if df_shap[f].abs().max() > 10:\n",
    "    #         f_shap_ll = df_shap[f].quantile(0.01)\n",
    "    #         f_shap_hl = df_shap[f].quantile(0.99)\n",
    "    #     else:\n",
    "    #         f_shap_ll = df_shap[f].min()\n",
    "    #         f_shap_hl = df_shap[f].max()\n",
    "        \n",
    "    #     f_index = df_shap.index[(df_shap[f] >= f_shap_ll) & (df_shap[f] <= f_shap_hl)].values\n",
    "    #     f_shap = df_shap.loc[f_index, f].values\n",
    "    #     f_vals = data.loc[f_index, f].values\n",
    "        \n",
    "    #     f_cmap = sns.color_palette(\"Spectral_r\", as_cmap=True)\n",
    "    #     f_norm = mcolors.Normalize(vmin=min(f_vals), vmax=max(f_vals)) \n",
    "    #     f_colors = {}\n",
    "    #     for cval in f_vals:\n",
    "    #         f_colors.update({cval: f_cmap(f_norm(cval))})\n",
    "\n",
    "    #     strip = sns.stripplot(\n",
    "    #         x=f_shap,\n",
    "    #         y=[f]*len(f_shap),\n",
    "    #         hue=f_vals,\n",
    "    #         palette=f_colors,\n",
    "    #         jitter=0.35,\n",
    "    #         alpha=0.5,\n",
    "    #         edgecolor='gray',\n",
    "    #         linewidth=0.1,\n",
    "    #         size=25 / np.sqrt(results.loc[results['Group'] == 'Test', :].shape[0]),\n",
    "    #         legend=False,\n",
    "    #         ax=axs_importance[2],\n",
    "    #     )\n",
    "        \n",
    "    #     if not is_colorbar:\n",
    "    #         sm = plt.cm.ScalarMappable(cmap=f_cmap, norm=f_norm)\n",
    "    #         sm.set_array([])\n",
    "    #         cbar = strip.figure.colorbar(sm)\n",
    "    #         # cbar.set_label('Значения\\nчисленных\\nпризнаков', labelpad=-8, fontsize='large')\n",
    "    #         cbar.set_ticks([min(f_vals), max(f_vals)])\n",
    "    #         cbar.set_ticklabels([\"Min\", \"Max\"])\n",
    "    #         is_colorbar = True \n",
    "    # # axs_importance[2].set(yticklabels=[])\n",
    "    # axs_importance[2].set_xlabel('SHAP')\n",
    "    \n",
    "    # df_shap.to_excel(f\"{path}/{feats_set_path}/{feats_set}/model/model_importance.xlsx\")\n",
    "    \n",
    "    fig.savefig(f\"{path}/{feats_set_path}/model/model.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path}/{feats_set_path}/model/model.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best models inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = f\"E:/Git/MillenniumAge\"\n",
    "\n",
    "feat_trgt = 'Возраст'\n",
    "\n",
    "components = {\n",
    "    'Оценка состава тела, женщины': {\n",
    "        'name': 'Оценка состава тела',\n",
    "        'path': f\"{dir_root}/data/small_models/Оценка состава тела/F\",\n",
    "        'bkg_count': 10,\n",
    "        'likelihood': 0.60,\n",
    "        'mae_thld': 0.6\n",
    "    },\n",
    "    'Оценка состава тела, мужчины': {\n",
    "        'name': 'Оценка состава тела',\n",
    "        'path': f\"{dir_root}/data/small_models/Оценка состава тела/M\",\n",
    "        'bkg_count': 10,\n",
    "        'likelihood': 0.60,\n",
    "        'mae_thld': 0.6\n",
    "    },\n",
    "    \n",
    "    'Электрокардиограмма, все': {\n",
    "        'name': 'Электрокардиограмма',\n",
    "        'path': f\"{dir_root}/data/small_models/Электрокардиограмма\",\n",
    "        'bkg_count': 15,\n",
    "        'likelihood': 0.50,\n",
    "        'mae_thld': 0.6\n",
    "    },\n",
    "    \n",
    "    'Гематологические исследования, женщины': {\n",
    "        'name': 'Гематологические исследования',\n",
    "        'path': f\"{dir_root}/data/small_models/Гематологические исследования/F\",\n",
    "        'bkg_count': 20,\n",
    "        'likelihood': 0.4,\n",
    "        'mae_thld': 1.0\n",
    "    },\n",
    "    'Гематологические исследования, мужчины': {\n",
    "        'name': 'Гематологические исследования',\n",
    "        'path': f\"{dir_root}/data/small_models/Гематологические исследования/M\",\n",
    "        'bkg_count': 20,\n",
    "        'likelihood': 0.4,\n",
    "        'mae_thld': 0.8\n",
    "    },\n",
    "    \n",
    "    'Биохимические исследования, женщины': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/small_models/Биохимические исследования/F\",\n",
    "        'bkg_count': 12,\n",
    "        'likelihood': 0.90,\n",
    "        'mae_thld': 0.4\n",
    "    },\n",
    "    'Биохимические исследования, мужчины': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/small_models/Биохимические исследования/M\",\n",
    "        'bkg_count': 12,\n",
    "        'likelihood': 0.90,\n",
    "        'mae_thld': 0.6\n",
    "    },\n",
    "    \n",
    "    'Половые гормоны, женщины': {\n",
    "        'name': 'Половые гормоны',\n",
    "        'path': f\"{dir_root}/data/small_models/Половые гормоны/F\",\n",
    "        'bkg_count': 15,\n",
    "        'likelihood': 0.90,\n",
    "        'mae_thld': 0.4\n",
    "    },\n",
    "    'Половые гормоны, мужчины': {\n",
    "        'name': 'Половые гормоны',\n",
    "        'path': f\"{dir_root}/data/small_models/Половые гормоны/M\",\n",
    "        'bkg_count': 12,\n",
    "        'likelihood': 0.90,\n",
    "        'mae_thld': 0.4\n",
    "    },\n",
    "}\n",
    "\n",
    "component_color_dict = {\n",
    "    'Биохимические исследования': \"#880808\",\n",
    "    'Гематологические исследования': \"#DA70D6\",\n",
    "    'Половые гормоны': \"#E49B0F\",\n",
    "    'Оценка состава тела': \"#000080\",\n",
    "    'Электрокардиограмма': \"#088F8F\"\n",
    "}\n",
    "\n",
    "feats_all = ['Пол']\n",
    "feats_pred_all = []\n",
    "feats_input_all = []\n",
    "feats_aux = []\n",
    "for comp in components:\n",
    "    components[comp]['data'] = pd.read_excel(f\"{components[comp]['path']}/data.xlsx\", index_col=0)\n",
    "    components[comp]['feats'] = pd.read_excel(f\"{components[comp]['path']}/feats.xlsx\", index_col=0)\n",
    "    components[comp]['results'] = pd.read_excel(f\"{components[comp]['path']}/model/df.xlsx\", index_col=0)\n",
    "    components[comp]['metrics'] = pd.read_excel(f\"{components[comp]['path']}/model/metrics.xlsx\", index_col=0)\n",
    "    components[comp]['model'] = TabularModel.load_model(f\"{components[comp]['path']}/model\")\n",
    "    components[comp]['corrector'] = LinearBiasCorrector()\n",
    "    comp_results = components[comp]['results']\n",
    "    components[comp]['corrector'].fit(comp_results.loc[comp_results['Group'] == 'Train', feat_trgt].values, comp_results.loc[comp_results['Group'] == 'Train', 'Prediction'].values)\n",
    "    res_cols = ['Group', 'Prediction', 'Error', 'Prediction Unbiased', 'Error Unbiased']\n",
    "    components[comp]['data'].loc[components[comp]['data'].index, res_cols] = comp_results.loc[components[comp]['data'].index, res_cols]\n",
    "    components[comp]['data_shap'] = components[comp]['data'].copy()\n",
    "    \n",
    "    feats = components[comp]['feats'].index.values\n",
    "    feats = feats[feats != feat_trgt]\n",
    "    feats_all += list(feats)\n",
    "    feats_pred_all += [f\"Предсказание {components[comp]['name']}\", f\"Возрастная Акселерация {components[comp]['name']}\", f\"Модель {components[comp]['name']}\",]\n",
    "    feats_all += [f\"Модель {comp}\", f\"Предсказание {comp}\", f\"Возрастная Акселерация {comp}\"]\n",
    "    feats_aux += [f\"Модель {comp}\", f\"Предсказание {comp}\", f\"Возрастная Акселерация {comp}\"]\n",
    "    feats_input_all += list(feats)\n",
    "    \n",
    "    components[comp]['feats_corr'] = pd.DataFrame(index=feats, columns=['Correlation'])\n",
    "    for f in feats:\n",
    "        components[comp]['feats_corr'].at[f, 'Correlation'], _ = scipy.stats.pearsonr(components[comp]['data'].loc[:, f].values, components[comp]['data'].loc[:, feat_trgt].values)\n",
    "\n",
    "feats_all = list(dict.fromkeys(feats_all)) + list(dict.fromkeys(feats_pred_all))\n",
    "feats_input_all = list(dict.fromkeys(feats_input_all))\n",
    "feats_aux = list(dict.fromkeys(feats_aux))\n",
    "\n",
    "for comp in components:\n",
    "    print(f\"{comp}: {components[comp]['data'].shape[0]}\")\n",
    "    mae = components[comp]['metrics'].at['Test', 'mean_absolute_error_unbiased']\n",
    "    # rho = components[comp]['metrics'].at['Test', 'pearson_corrcoef_unbiased'] * components[comp]['likelihood']\n",
    "    # rho = components[comp]['metrics'].at['Test', 'pearson_corrcoef_unbiased'] * components[comp]['feats_corr']['Correlation'].abs().max()\n",
    "    rho = components[comp]['metrics'].at['Test', 'pearson_corrcoef_unbiased'] * components[comp]['feats_corr']['Correlation'].abs().max() * components[comp]['likelihood']\n",
    "    curr_threshold = rho * mae * components[comp]['mae_thld']\n",
    "    print(f'MAE: {mae}, rho: {rho}, threshold (rho*MAE*mae_thld): {curr_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"E:/YandexDisk/Work/bbd/millennium/models/data.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Вычисление биологического возраста: 100%|██████████| 3825/3825 [03:24<00:00, 18.69it/s]\n"
     ]
    }
   ],
   "source": [
    "nan_part = 0.1\n",
    "\n",
    "data_models = pd.DataFrame(columns=feats_all)\n",
    "for sample_id in tqdm(data.index.values, desc='Вычисление биологического возраста'):\n",
    "    \n",
    "    data_models.at[sample_id, \"Пол\"] = data.at[sample_id, \"Пол\"]\n",
    "    \n",
    "    components_trgt = {}\n",
    "    \n",
    "    if data.at[sample_id, \"Пол\"] == 'Ж':\n",
    "        \n",
    "        components_trgt['Оценка состава тела'] = 'Оценка состава тела, женщины'\n",
    "        \n",
    "        components_sex_hormones = [\n",
    "            'Половые гормоны, женщины',\n",
    "        ]\n",
    "        for comp in components_sex_hormones:\n",
    "            feats = components[comp]['feats'].index.values\n",
    "            n_feats = len(feats)\n",
    "            n_nans = data.loc[sample_id, feats].isna().sum()\n",
    "            if n_nans / n_feats < nan_part:\n",
    "                components_trgt['Половые гормоны'] = comp\n",
    "                break\n",
    "            else:\n",
    "                data_models.at[sample_id, f\"Модель {comp}\"] = False\n",
    "        \n",
    "        components_hematology = [\n",
    "            'Гематологические исследования, женщины',\n",
    "        ]\n",
    "        for comp in components_hematology:\n",
    "            feats = components[comp]['feats'].index.values\n",
    "            n_feats = len(feats)\n",
    "            n_nans = data.loc[sample_id, feats].isna().sum()\n",
    "            if n_nans / n_feats < nan_part:\n",
    "                components_trgt['Гематологические исследования'] = comp\n",
    "                break\n",
    "            else:\n",
    "                data_models.at[sample_id, f\"Модель {comp}\"] = False\n",
    "                \n",
    "        components_biochem = [\n",
    "            'Биохимические исследования, женщины',\n",
    "        ]\n",
    "        for comp in components_biochem:\n",
    "            feats = components[comp]['feats'].index.values\n",
    "            n_feats = len(feats)\n",
    "            n_nans = data.loc[sample_id, feats].isna().sum()\n",
    "            if n_nans / n_feats < nan_part:\n",
    "                components_trgt['Биохимические исследования'] = comp\n",
    "                break\n",
    "            else:\n",
    "                data_models.at[sample_id, f\"Модель {comp}\"] = False\n",
    "        \n",
    "    elif data.at[sample_id, \"Пол\"] == 'М':\n",
    "        \n",
    "        components_trgt['Оценка состава тела'] = 'Оценка состава тела, мужчины'\n",
    "        \n",
    "        components_sex_hormones = [\n",
    "            'Половые гормоны, мужчины',\n",
    "        ]\n",
    "        for comp in components_sex_hormones:\n",
    "            feats = components[comp]['feats'].index.values\n",
    "            n_feats = len(feats)\n",
    "            n_nans = data.loc[sample_id, feats].isna().sum()\n",
    "            if n_nans / n_feats < nan_part:\n",
    "                components_trgt['Половые гормоны'] = comp\n",
    "                break\n",
    "            else:\n",
    "                data_models.at[sample_id, f\"Модель {comp}\"] = False\n",
    "                \n",
    "        components_hematology = [\n",
    "            'Гематологические исследования, мужчины',\n",
    "        ]\n",
    "        for comp in components_hematology:\n",
    "            feats = components[comp]['feats'].index.values\n",
    "            n_feats = len(feats)\n",
    "            n_nans = data.loc[sample_id, feats].isna().sum()\n",
    "            if n_nans / n_feats < nan_part:\n",
    "                components_trgt['Гематологические исследования'] = comp\n",
    "                break\n",
    "            else:\n",
    "                data_models.at[sample_id, f\"Модель {comp}\"] = False\n",
    "                \n",
    "        components_biochem = [\n",
    "            'Биохимические исследования, мужчины',\n",
    "        ]\n",
    "        for comp in components_biochem:\n",
    "            feats = components[comp]['feats'].index.values\n",
    "            n_feats = len(feats)\n",
    "            n_nans = data.loc[sample_id, feats].isna().sum()\n",
    "            if n_nans / n_feats < nan_part:\n",
    "                components_trgt['Биохимические исследования'] = comp\n",
    "                break\n",
    "            else:\n",
    "                data_models.at[sample_id, f\"Модель {comp}\"] = False\n",
    "        \n",
    "    else:\n",
    "        print(f\"Пол для {sample_id}: {data.at[sample_id, 'Пол']}\")\n",
    "    \n",
    "    if data.at[sample_id, 'Возраст'] < 15:\n",
    "        components_trgt['Электрокардиограмма'] = 'Электрокардиограмма, все'\n",
    "    else:\n",
    "        components_trgt['Электрокардиограмма'] = 'Электрокардиограмма, все'\n",
    "        \n",
    "    n_pos = 0\n",
    "    n_neg = 0\n",
    "    comp_present = []\n",
    "    for _, comp in components_trgt.items():\n",
    "        data_models.at[sample_id, f\"Модель {comp}\"] = False\n",
    "        feats = components[comp]['feats'].index.values\n",
    "        feats_w_trgt = list(feats) + [feat_trgt]\n",
    "        n_feats = len(feats)\n",
    "        if set(feats).issubset(data.columns):\n",
    "            n_nans = data.loc[sample_id, feats].isna().sum()\n",
    "            # rho = components[comp]['metrics'].at['Test', 'pearson_corrcoef_unbiased'] * components[comp]['likelihood']\n",
    "            # rho = components[comp]['metrics'].at['Test', 'pearson_corrcoef_unbiased'] * components[comp]['feats_corr']['Correlation'].abs().max()\n",
    "            rho = components[comp]['metrics'].at['Test', 'pearson_corrcoef_unbiased'] * components[comp]['feats_corr']['Correlation'].abs().max() * components[comp]['likelihood']\n",
    "            if n_nans / n_feats < nan_part:\n",
    "                comp_present.append(comp)\n",
    "                data_sample = data.loc[[sample_id], feats_w_trgt]\n",
    "                if n_nans != 0:\n",
    "                    data_bkcg = components[comp]['data'].loc[:, feats_w_trgt]\n",
    "                    data_imp = pd.concat([data_sample, data_bkcg], axis=0, ignore_index=True)\n",
    "                    imputer = KNNImputer(n_neighbors=5)\n",
    "                    data_sample.loc[sample_id, feats_w_trgt] = imputer.fit_transform(data_imp.loc[:, feats_w_trgt].values)[0, :]\n",
    "                pred = components[comp]['model'].predict(data_sample)[f'{feat_trgt}_prediction'].values\n",
    "                pred = components[comp]['corrector'].predict(pred)\n",
    "                data_sample.at[sample_id, f\"Предсказание {components[comp]['name']}\"] = pred\n",
    "                data_sample.at[sample_id, f\"Предсказание {comp}\"] = pred\n",
    "                \n",
    "                gt = data_sample.at[sample_id, feat_trgt]\n",
    "                aa = pred - gt\n",
    "                if aa > 0:\n",
    "                    n_pos += 1\n",
    "                else:\n",
    "                    n_neg += 1\n",
    "                \n",
    "                data_sample.at[sample_id, f\"Возрастная Акселерация {components[comp]['name']}\"] = aa * rho\n",
    "                data_sample.at[sample_id, f\"Возрастная Акселерация {comp}\"] = aa * rho\n",
    "                \n",
    "                data_sample.at[sample_id, f\"Модель {components[comp]['name']}\"] = comp\n",
    "                \n",
    "                data_models.loc[sample_id, data_sample.columns] = data_sample.loc[sample_id, data_sample.columns]\n",
    "            \n",
    "    if len(comp_present) > 0:\n",
    "        data_models.at[sample_id, \"Число моделей\"] = len(comp_present)\n",
    "        data_models.at[sample_id, \"Число моделей c отрицательной аккселерацией\"] = n_neg\n",
    "        data_models.at[sample_id, \"Число моделей c положительной аккселерацией\"] = n_pos\n",
    "        data_models.at[sample_id, \"Возрастная Акселерация\"] = 0.0\n",
    "        for comp in comp_present:\n",
    "            data_models.at[sample_id, f\"Модель {comp}\"] = True\n",
    "            # samples.at[sample_id, f\"Возрастная Акселерация {components[comp]['name']}\"] /= max(n_pos - 1, n_neg - 1, 1)\n",
    "            # samples.at[sample_id, f\"Возрастная Акселерация {comp}\"] /= max(n_pos - 1, n_neg - 1, 1)\n",
    "            data_models.at[sample_id, \"Возрастная Акселерация\"] += data_models.at[sample_id, f\"Возрастная Акселерация {comp}\"]\n",
    "        \n",
    "data_models.insert(len(data_models.columns) - 1, \"Число моделей\", data_models.pop(\"Число моделей\"))\n",
    "data_models.insert(len(data_models.columns) - 1, \"Число моделей c отрицательной аккселерацией\", data_models.pop(\"Число моделей c отрицательной аккселерацией\"))\n",
    "data_models.insert(len(data_models.columns) - 1, \"Число моделей c положительной аккселерацией\", data_models.pop(\"Число моделей c положительной аккселерацией\"))\n",
    "data_models.insert(len(data_models.columns) - 1, \"Возрастная Акселерация\", data_models.pop(\"Возрастная Акселерация\"))\n",
    "data_models['Биологический возраст'] = data_models[feat_trgt] + data_models[\"Возрастная Акселерация\"]\n",
    "\n",
    "data_models = data_models.dropna(subset=['Биологический возраст'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_models.to_excel(\"E:/YandexDisk/Work/bbd/millennium/models/data_with_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='ticks')\n",
    "fig = plt.figure(\n",
    "    figsize=(7, 5),\n",
    "    layout=\"constrained\"\n",
    ")\n",
    "\n",
    "axs = fig.subplot_mosaic(\n",
    "    [\n",
    "        ['table', 'none'],\n",
    "        ['scatter', 'violin'],\n",
    "    ],\n",
    "    # figsize=(6, 1.5 + 6),\n",
    "    height_ratios=[1, 4],\n",
    "    width_ratios=[3, 1.5],\n",
    "    gridspec_kw={\n",
    "        # \"bottom\": 0.14,\n",
    "        # \"top\": 0.95,\n",
    "        # \"left\": 0.1,\n",
    "        # \"right\": 0.5,\n",
    "        \"wspace\": 0.01,\n",
    "        \"hspace\": 0.01,\n",
    "    },\n",
    ")\n",
    "axs['none'].axis('off')\n",
    "\n",
    "df_table = pd.DataFrame(index=['MAE', fr\"Pearson $\\mathbf{{\\rho}}$\", \"Bias\"], columns=['Женщины', 'Мужчины'])\n",
    "\n",
    "y_true = data_models.loc[data_models['Пол'] == 'Ж', 'Возраст'].values\n",
    "y_pred = data_models.loc[data_models['Пол'] == 'Ж', 'Биологический возраст'].values\n",
    "y_error = data_models.loc[data_models['Пол'] == 'Ж', 'Биологический возраст'].values\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "pearsonr, _ = scipy.stats.pearsonr(y_true, y_pred)\n",
    "bias = np.mean(data_models.loc[data_models['Пол'] == 'Ж', 'Возрастная Акселерация'].values)\n",
    "df_table.at['MAE', 'Женщины'] = f\"{mean_absolute_error(y_true, y_pred):0.3f}\"\n",
    "df_table.at[fr\"Pearson $\\mathbf{{\\rho}}$\", 'Женщины'] = f\"{pearsonr:0.3f}\"\n",
    "df_table.at[\"Bias\", 'Женщины'] = f\"{bias:0.3f}\"\n",
    "\n",
    "y_true = data_models.loc[data_models['Пол'] == 'М', 'Возраст'].values\n",
    "y_pred = data_models.loc[data_models['Пол'] == 'М', 'Биологический возраст'].values\n",
    "y_error = data_models.loc[data_models['Пол'] == 'М', 'Биологический возраст'].values\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "pearsonr, _ = scipy.stats.pearsonr(y_true, y_pred)\n",
    "bias = np.mean(data_models.loc[data_models['Пол'] == 'М', 'Возрастная Акселерация'].values)\n",
    "df_table.at['MAE', 'Мужчины'] = f\"{mean_absolute_error(y_true, y_pred):0.3f}\"\n",
    "df_table.at[fr\"Pearson $\\mathbf{{\\rho}}$\", 'Мужчины'] = f\"{pearsonr:0.3f}\"\n",
    "df_table.at[\"Bias\", 'Мужчины'] = f\"{bias:0.3f}\"\n",
    "\n",
    "col_defs = [\n",
    "    ColumnDefinition(\n",
    "        name=\"index\",\n",
    "        title='',\n",
    "        textprops={\"ha\": \"center\", \"weight\": \"bold\"},\n",
    "        width=2.5,\n",
    "        # border=\"both\",\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=\"Женщины\",\n",
    "        textprops={\"ha\": \"left\"},\n",
    "        width=1.5,\n",
    "        border=\"left\",\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=\"Мужчины\",\n",
    "        textprops={\"ha\": \"left\"},\n",
    "        width=1.5,\n",
    "    ),\n",
    "]\n",
    "table = Table(\n",
    "    df_table,\n",
    "    column_definitions=col_defs,\n",
    "    row_dividers=True,\n",
    "    footer_divider=False,\n",
    "    ax=axs['table'],\n",
    "    textprops={\"fontsize\": 8},\n",
    "    row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "    col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    ").autoset_fontcolors(colnames=['Женщины', 'Мужчины'])\n",
    "\n",
    "xy_min, xy_max = np.quantile(data_models[['Возраст', 'Биологический возраст']].values.flatten(), [0.01, 0.99])\n",
    "xy_ptp = xy_max - xy_min\n",
    "\n",
    "# kdeplot = sns.kdeplot(\n",
    "#     data=data_models,\n",
    "#     x='Возраст',\n",
    "#     y='Биологический возраст',\n",
    "#     fill=True,\n",
    "#     cbar=False,\n",
    "#     thresh=0.01,\n",
    "#     hue=\"Пол\",\n",
    "#     palette={'Ж': 'crimson', 'М': 'dodgerblue'},\n",
    "#     # color='crimson',\n",
    "#     legend=False,\n",
    "#     ax=axs['scatter']\n",
    "# )\n",
    "scatter = sns.scatterplot(\n",
    "    data=data_models,\n",
    "    x='Возраст',\n",
    "    y='Биологический возраст',\n",
    "    linewidth=0.3,\n",
    "    alpha=0.75,\n",
    "    edgecolor=\"k\",\n",
    "    s=20,\n",
    "    hue=\"Пол\",\n",
    "    palette={'Ж': 'crimson', 'М': 'dodgerblue'},\n",
    "    # color='crimson',\n",
    "    ax=axs['scatter'],\n",
    ")\n",
    "bisect = sns.lineplot(\n",
    "    x=[xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp],\n",
    "    y=[xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp],\n",
    "    linestyle='--',\n",
    "    color='black',\n",
    "    linewidth=1.0,\n",
    "    ax=axs['scatter']\n",
    ")\n",
    "# regplot = sns.regplot(\n",
    "#     data=results.loc[results['Group'] == 'Train', :],\n",
    "#     x=feat_trgt,\n",
    "#     y='Prediction Unbiased',\n",
    "#     color='k',\n",
    "#     scatter=False,\n",
    "#     truncate=False,\n",
    "#     ax=axs['scatter']\n",
    "# )\n",
    "axs['scatter'].set_xlim(xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp)\n",
    "axs['scatter'].set_ylim(xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp)\n",
    "axs['scatter'].set_ylabel(\"Биологический возраст\")\n",
    "axs['scatter'].set_xlabel(\"Возраст\")\n",
    "\n",
    "q01 = data_models['Возрастная Акселерация'].quantile(0.01)\n",
    "q99 = data_models['Возрастная Акселерация'].quantile(0.99)\n",
    "\n",
    "violin = sns.violinplot(\n",
    "    data=data_models.loc[(data_models['Возрастная Акселерация'] > q01) & (data_models['Возрастная Акселерация'] < q99), :],\n",
    "    # x=[0] * data_models.shape[0],\n",
    "    y='Возрастная Акселерация',\n",
    "    # color='crimson',\n",
    "    hue=\"Пол\",\n",
    "    x='Пол',\n",
    "    palette={'Ж': 'crimson', 'М': 'dodgerblue'},\n",
    "    density_norm='width',\n",
    "    saturation=0.75,\n",
    "    linewidth=1.0,\n",
    "    ax=axs['violin'],\n",
    "    legend=False,\n",
    ")\n",
    "# swarm = sns.swarmplot(\n",
    "#     data=results.loc[results['Group'] == 'Test', :],\n",
    "#     x=[0] * results.loc[results['Group'] == 'Test', :].shape[0],\n",
    "#     y='Error Unbiased',\n",
    "#     color=colors_feats_sets[feats_set],\n",
    "#     linewidth=0.5,\n",
    "#     ax=axs['violin'],\n",
    "#     size= 50 / np.sqrt(results.loc[results['Group'] == 'Test', :].shape[0]),\n",
    "#     legend=False,\n",
    "# )\n",
    "axs['violin'].set_ylabel('Возрастная Акселерация')\n",
    "axs['violin'].set_xlabel('')\n",
    "axs['violin'].set(xticklabels=[]) \n",
    "axs['violin'].set(xticks=[])\n",
    "\n",
    "fig.savefig(f\"E:/YandexDisk/Work/bbd/millennium/models/data_with_results.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"E:/YandexDisk/Work/bbd/millennium/models/data_with_results.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"E:/YandexDisk/Work/bbd/millennium/models/Электрокардиограмма (чекап)\"\n",
    "path_model = f\"{path}/models/DANet/424\"\n",
    "dataset = 'Электрокардиограмма'\n",
    "expl_type = 'current'\n",
    "color = 'olive'\n",
    "\n",
    "feat_trgt = 'Возраст'\n",
    "\n",
    "data = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path}/feats.xlsx\", index_col=0)\n",
    "results = pd.read_excel(f\"{path_model}/df.xlsx\", index_col=0)\n",
    "metrics = pd.read_excel(f\"{path_model}/metrics.xlsx\", index_col=0)\n",
    "df_shap = pd.read_excel(f\"{path_model}/explanation.xlsx\", index_col=0)\n",
    "model = TabularModel.load_model(f\"{path_model}\")\n",
    "corrector = LinearBiasCorrector()\n",
    "corrector.fit(results.loc[results['Group'] == 'Train', feat_trgt].values, results.loc[results['Group'] == 'Train', 'Prediction'].values)\n",
    "\n",
    "xy_min, xy_max = np.quantile(results[[feat_trgt, 'Prediction Unbiased']].values.flatten(), [0.01, 0.99])\n",
    "xy_ptp = xy_max - xy_min\n",
    "\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig = plt.figure(\n",
    "    figsize=(8, 5 + 1.5 + 0.15 * feats.shape[0] + 1.5 + 0.15 * feats.shape[0]),\n",
    "    layout=\"constrained\"\n",
    ")\n",
    "subfigs = fig.subfigures(\n",
    "    nrows=3,\n",
    "    ncols=1,\n",
    "    height_ratios=[5, 1.5 + 0.15 * feats.shape[0], 1.5 + 0.15 * feats.shape[0]],\n",
    "    wspace=0.001,\n",
    "    hspace=0.001,\n",
    ")\n",
    "\n",
    "axs = subfigs[0].subplot_mosaic(\n",
    "    [\n",
    "        ['table', 'table'],\n",
    "        ['scatter', 'violin'],\n",
    "    ],\n",
    "    # figsize=(6, 1.5 + 6),\n",
    "    height_ratios=[1, 4],\n",
    "    width_ratios=[3, 1.5],\n",
    "    gridspec_kw={\n",
    "        # \"bottom\": 0.14,\n",
    "        # \"top\": 0.95,\n",
    "        # \"left\": 0.1,\n",
    "        # \"right\": 0.5,\n",
    "        \"wspace\": 0.01,\n",
    "        \"hspace\": 0.01,\n",
    "    },\n",
    ")\n",
    "\n",
    "df_table = pd.DataFrame(index=['MAE', fr\"Pearson $\\mathbf{{\\rho}}$\", \"Bias\"], columns=['Train', 'Validation', 'Test'])\n",
    "for part in ['Train', 'Validation', 'Test']:\n",
    "    df_table.at['MAE', part] = f\"{metrics.at[part, 'mean_absolute_error_unbiased']:0.3f}\"\n",
    "    df_table.at[fr\"Pearson $\\mathbf{{\\rho}}$\", part] = f\"{metrics.at[part, 'pearson_corrcoef_unbiased']:0.3f}\"\n",
    "    df_table.at[\"Bias\", part] = f\"{metrics.at[part, 'bias_unbiased']:0.3f}\"\n",
    "\n",
    "col_defs = [\n",
    "    ColumnDefinition(\n",
    "        name=\"index\",\n",
    "        title='',\n",
    "        textprops={\"ha\": \"center\", \"weight\": \"bold\"},\n",
    "        width=2.5,\n",
    "        # border=\"both\",\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=\"Train\",\n",
    "        textprops={\"ha\": \"left\"},\n",
    "        width=1.5,\n",
    "        border=\"left\",\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=\"Validation\",\n",
    "        textprops={\"ha\": \"left\"},\n",
    "        width=1.5,\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=\"Test\",\n",
    "        textprops={\"ha\": \"left\"},\n",
    "        width=1.5,\n",
    "    )\n",
    "]\n",
    "\n",
    "table = Table(\n",
    "    df_table,\n",
    "    column_definitions=col_defs,\n",
    "    row_dividers=True,\n",
    "    footer_divider=False,\n",
    "    ax=axs['table'],\n",
    "    textprops={\"fontsize\": 8},\n",
    "    row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "    col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    ").autoset_fontcolors(colnames=['Train', 'Validation', 'Test'])\n",
    "\n",
    "kdeplot = sns.kdeplot(\n",
    "    data=results.loc[results['Group'].isin(['Train', 'Validation']), :],\n",
    "    x=feat_trgt,\n",
    "    y='Prediction Unbiased',\n",
    "    fill=True,\n",
    "    cbar=False,\n",
    "    thresh=0.05,\n",
    "    color=color,\n",
    "    legend=False,\n",
    "    ax=axs['scatter']\n",
    ")\n",
    "scatter = sns.scatterplot(\n",
    "    data=results.loc[results['Group'] == 'Test', :],\n",
    "    x=feat_trgt,\n",
    "    y=\"Prediction Unbiased\",\n",
    "    linewidth=0.5,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"k\",\n",
    "    s=25,\n",
    "    color=color,\n",
    "    ax=axs['scatter'],\n",
    ")\n",
    "bisect = sns.lineplot(\n",
    "    x=[xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp],\n",
    "    y=[xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp],\n",
    "    linestyle='--',\n",
    "    color='black',\n",
    "    linewidth=1.0,\n",
    "    ax=axs['scatter']\n",
    ")\n",
    "regplot = sns.regplot(\n",
    "    data=results,\n",
    "    x=feat_trgt,\n",
    "    y='Prediction Unbiased',\n",
    "    color='k',\n",
    "    scatter=False,\n",
    "    truncate=False,\n",
    "    ax=axs['scatter']\n",
    ")\n",
    "axs['scatter'].set_xlim(xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp)\n",
    "axs['scatter'].set_ylim(xy_min - 0.15 * xy_ptp, xy_max + 0.15 * xy_ptp)\n",
    "axs['scatter'].set_ylabel(\"Биологический возраст\")\n",
    "axs['scatter'].set_xlabel(\"Возраст\")\n",
    "\n",
    "violin = sns.violinplot(\n",
    "    data=results.loc[results['Group'].isin(['Train', 'Validation']), :],\n",
    "    x=[0] * results.loc[results['Group'].isin(['Train', 'Validation']), :].shape[0],\n",
    "    y='Error Unbiased',\n",
    "    color=make_rgb_transparent(mcolors.to_rgb(color), (1, 1, 1), 0.5),\n",
    "    density_norm='width',\n",
    "    saturation=0.75,\n",
    "    linewidth=1.0,\n",
    "    ax=axs['violin'],\n",
    "    legend=False,\n",
    ")\n",
    "swarm = sns.swarmplot(\n",
    "    data=results.loc[results['Group'] == 'Test', :],\n",
    "    x=[0] * results.loc[results['Group'] == 'Test', :].shape[0],\n",
    "    y='Error Unbiased',\n",
    "    color=color,\n",
    "    linewidth=0.5,\n",
    "    ax=axs['violin'],\n",
    "    size= 50 / np.sqrt(results.loc[results['Group'] == 'Test', :].shape[0]),\n",
    "    legend=False,\n",
    ")\n",
    "axs['violin'].set_ylabel('Возрастная акселерация')\n",
    "axs['violin'].set_xlabel('')\n",
    "axs['violin'].set(xticklabels=[]) \n",
    "axs['violin'].set(xticks=[]) \n",
    "\n",
    "ax_heatmap = subfigs[1].subplots()\n",
    "df_corr = pd.DataFrame(index=feats.index.to_list(), columns=['rho'])\n",
    "for f in tqdm(feats.index.to_list()):\n",
    "    df_tmp = data.loc[:, [feat_trgt, f]].dropna(axis=0, how='any')\n",
    "    if df_tmp.shape[0] > 1:\n",
    "        vals_1 = df_tmp.loc[:, feat_trgt].values\n",
    "        vals_2 = df_tmp.loc[:, f].values\n",
    "        df_corr.at[f, 'rho'], _ = scipy.stats.pearsonr(vals_1, vals_2)\n",
    "df_corr.dropna(axis=0, how='any', inplace=True)\n",
    "df_corr.insert(1, \"abs(rho)\", df_corr['rho'].abs())\n",
    "df_corr.sort_values([\"abs(rho)\"], ascending=[False], inplace=True)\n",
    "feats_cnt_wo_age = df_corr.index.to_list()\n",
    "feats_cnt = ['Возраст'] + feats_cnt_wo_age\n",
    "df_corr = df_corr.apply(pd.to_numeric)\n",
    "heatmap = sns.heatmap(\n",
    "    df_corr.loc[:, ['rho']],\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmin=-1.0,\n",
    "    vmax=1.0,\n",
    "    cmap='coolwarm',\n",
    "    linewidth=0.1,\n",
    "    linecolor='black',\n",
    "    #annot_kws={\"fontsize\": 15},\n",
    "    cbar_kws={\n",
    "        # \"shrink\": 0.9,\n",
    "        # \"aspect\": 30,\n",
    "        #'fraction': 0.046, \n",
    "        #'pad': 0.04,\n",
    "    },\n",
    "    ax=ax_heatmap\n",
    ")\n",
    "heatmap_pos = ax_heatmap.get_position()\n",
    "ax_heatmap.figure.axes[-1].set_position([heatmap_pos.x1 + 0.05, heatmap_pos.y0, 0.1, heatmap_pos.height])\n",
    "ax_heatmap.figure.axes[-1].set_ylabel(r\"Pearson $\\rho$\")\n",
    "for spine in ax_heatmap.figure.axes[-1].spines.values():\n",
    "    spine.set(visible=True, lw=0.25, edgecolor=\"black\")\n",
    "ax_heatmap.set_xlabel('')\n",
    "ax_heatmap.set_ylabel('')\n",
    "ax_heatmap.set(xticklabels=[])\n",
    "ax_heatmap.set(xticks=[])\n",
    "\n",
    "\n",
    "if expl_type == 'recalc_gradient':\n",
    "    df_shap = model.explain(data, method=\"GradientShap\", baselines=\"b|100000\")\n",
    "    df_shap.index = data.index\n",
    "elif expl_type == 'recalc_sampling':\n",
    "    ds_data_shap = data.copy()\n",
    "    ds_cat_encoders = {}\n",
    "    for f in feats.index:\n",
    "        ds_cat_encoders[f] = LabelEncoder()\n",
    "        ds_data_shap[f] = ds_cat_encoders[f].fit_transform(ds_data_shap[f])\n",
    "    def predict_func(X):\n",
    "        X_df = pd.DataFrame(data=X, columns=feats.index.to_list())\n",
    "        for f in feats.index:\n",
    "            X_df[f] = ds_cat_encoders[f].inverse_transform(X_df[f].astype(int).values)\n",
    "        y = model.predict(X_df)[f'{feat_trgt}_prediction'].values\n",
    "        y = corrector.predict(y)\n",
    "        return y\n",
    "    explainer = shap.SamplingExplainer(predict_func, ds_data_shap.loc[:, feats.index.to_list()].values)\n",
    "    print(explainer.expected_value)\n",
    "    shap_values = explainer.shap_values(ds_data_shap.loc[:, feats.index.to_list()].values)\n",
    "    df_shap = pd.DataFrame(index=data.index, columns=feats.index.to_list(), data=shap_values)\n",
    "\n",
    "ds_fi = pd.DataFrame(index=feats.index.to_list(), columns=['mean(|SHAP|)'])\n",
    "for f in feats.index.to_list():\n",
    "    ds_fi.at[f, 'mean(|SHAP|)'] = df_shap[f].abs().mean()\n",
    "ds_fi.sort_values(['mean(|SHAP|)'], ascending=[False], inplace=True)\n",
    "ds_fi['Features'] = ds_fi.index.values\n",
    "\n",
    "\n",
    "axs_importance = subfigs[2].subplots(1, 2, width_ratios=[4, 8], gridspec_kw={'wspace':0.02, 'hspace': 0.02}, sharey=True, sharex=False)\n",
    "\n",
    "barplot = sns.barplot(\n",
    "    data=ds_fi,\n",
    "    x='mean(|SHAP|)',\n",
    "    y='Features',\n",
    "    color=color,\n",
    "    edgecolor='black',\n",
    "    dodge=False,\n",
    "    ax=axs_importance[0]\n",
    ")\n",
    "for container in barplot.containers:\n",
    "    barplot.bar_label(container, label_type='edge', color='gray', fmt='%0.2f', fontsize=12, padding=4.0)\n",
    "axs_importance[0].set_ylabel('')\n",
    "axs_importance[0].set(yticklabels=ds_fi.index.to_list())\n",
    "\n",
    "is_colorbar = False\n",
    "f_legends = []\n",
    "for f in ds_fi.index:\n",
    "    \n",
    "    if df_shap[f].abs().max() > 10:\n",
    "        f_shap_ll = df_shap[f].quantile(0.01)\n",
    "        f_shap_hl = df_shap[f].quantile(0.99)\n",
    "    else:\n",
    "        f_shap_ll = df_shap[f].min()\n",
    "        f_shap_hl = df_shap[f].max()\n",
    "    \n",
    "    f_index = df_shap.index[(df_shap[f] >= f_shap_ll) & (df_shap[f] <= f_shap_hl)].values\n",
    "    f_shap = df_shap.loc[f_index, f].values\n",
    "    f_vals = data.loc[f_index, f].values\n",
    "    \n",
    "    f_cmap = sns.color_palette(\"Spectral_r\", as_cmap=True)\n",
    "    f_norm = mcolors.Normalize(vmin=min(f_vals), vmax=max(f_vals)) \n",
    "    f_colors = {}\n",
    "    for cval in f_vals:\n",
    "        f_colors.update({cval: f_cmap(f_norm(cval))})\n",
    "\n",
    "    strip = sns.stripplot(\n",
    "        x=f_shap,\n",
    "        y=[f]*len(f_shap),\n",
    "        hue=f_vals,\n",
    "        palette=f_colors,\n",
    "        jitter=0.35,\n",
    "        alpha=0.5,\n",
    "        edgecolor='gray',\n",
    "        linewidth=0.1,\n",
    "        size=25 / np.sqrt(results.loc[results['Group'] == 'Test', :].shape[0]),\n",
    "        legend=False,\n",
    "        ax=axs_importance[1],\n",
    "    )\n",
    "    \n",
    "    if not is_colorbar:\n",
    "        sm = plt.cm.ScalarMappable(cmap=f_cmap, norm=f_norm)\n",
    "        sm.set_array([])\n",
    "        cbar = strip.figure.colorbar(sm)\n",
    "        # cbar.set_label('Значения\\nчисленных\\nпризнаков', labelpad=-8, fontsize='large')\n",
    "        cbar.set_ticks([min(f_vals), max(f_vals)])\n",
    "        cbar.set_ticklabels([\"Min\", \"Max\"])\n",
    "        is_colorbar = True \n",
    "\n",
    "axs_importance[1].set_xlabel('SHAP')\n",
    "df_shap.to_excel(f\"{path}/model_importance.xlsx\")\n",
    "\n",
    "fig.suptitle(dataset, fontsize='large')\n",
    "fig.savefig(f\"{path}/model.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path}/model.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
