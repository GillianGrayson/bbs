{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import BaseCrossValidator, ParameterGrid, ParameterSampler\n",
    "import torch\n",
    "import pickle\n",
    "import shutil\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "from regression_bias_corrector import LinearBiasCorrector\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import matplotlib.lines as mlines\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats\n",
    "from functools import reduce\n",
    "import shutil\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check initial data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/YandexDisk/Work/bbd/millennium'\n",
    "\n",
    "data_anl = pd.read_excel(f\"{path}/Результаты анализов/data.xlsx\", index_col=0)\n",
    "data_anl['Дата обследования'] = data_anl['Дата обследования'].dt.date\n",
    "data_anl.insert(0, 'ID', data_anl['ФИО'].astype(str) + ' ' + data_anl['Дата обследования'].astype(str))\n",
    "ids_counts_anl = data_anl['ФИО'].value_counts()\n",
    "sorter_anl = ids_counts_anl.index.to_list()\n",
    "data_anl.sort_values(by=\"ФИО\", key=lambda column: column.map(lambda e: sorter_anl.index(e)), inplace=True)\n",
    "feats_anl = pd.read_excel(f\"{path}/Результаты анализов/feats_with_metrics.xlsx\", index_col=0)\n",
    "\n",
    "data_ecg = pd.read_excel(f\"{path}/Результаты экг/data.xlsx\", index_col=0)\n",
    "data_ecg['Дата обследования'] = data_ecg['Дата и время обследования'].dt.date\n",
    "data_ecg.insert(0, 'ID', data_ecg['ФИО'].astype(str) + ' ' + data_ecg['Дата обследования'].astype(str))\n",
    "ids_counts_ecg = data_ecg['ФИО'].value_counts()\n",
    "sorter_ecg = ids_counts_ecg.index.to_list()\n",
    "data_ecg.sort_values(by=\"ФИО\", key=lambda column: column.map(lambda e: sorter_ecg.index(e)), inplace=True)\n",
    "feats_ecg = pd.read_excel(f\"{path}/Результаты экг/feats_with_metrics.xlsx\", index_col=0)\n",
    "\n",
    "data_bcp = pd.read_excel(f\"{path}/Результаты медасс/data.xlsx\", index_col=0)\n",
    "data_bcp['Дата обследования'] = data_bcp['Дата и время обследования'].dt.date\n",
    "data_bcp.insert(0, 'ID', data_bcp['ФИО'].astype(str) + ' ' + data_bcp['Дата обследования'].astype(str))\n",
    "ids_counts_bcp = data_bcp['ФИО'].value_counts()\n",
    "sorter_bcp = ids_counts_bcp.index.to_list()\n",
    "data_bcp.sort_values(by=\"ФИО\", key=lambda column: column.map(lambda e: sorter_bcp.index(e)), inplace=True)\n",
    "feats_bcp = pd.read_excel(f\"{path}/Результаты медасс/feats_with_metrics.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_anl.index.is_unique)\n",
    "print(data_ecg.index.is_unique)\n",
    "print(data_bcp.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set.intersection(set(data_anl['ФИО']), set(data_ecg['ФИО']))))\n",
    "print(len(set.intersection(set(data_bcp['ФИО']), set(data_ecg['ФИО']))))\n",
    "print(len(set.intersection(set(data_anl['ФИО']), set(data_bcp['ФИО']))))\n",
    "print(len(set.intersection(set(data_anl['ФИО']), set(data_bcp['ФИО']), set(data_ecg['ФИО']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set.intersection(set(data_anl['ID']), set(data_ecg['ID']))))\n",
    "print(len(set.intersection(set(data_bcp['ID']), set(data_ecg['ID']))))\n",
    "print(len(set.intersection(set(data_anl['ID']), set(data_bcp['ID']))))\n",
    "print(len(set.intersection(set(data_anl['ID']), set(data_bcp['ID']), set(data_ecg['ID']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anl_new = data_anl.set_index('ID')\n",
    "data_anl_new.loc[data_anl_new.index.duplicated(keep=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ecg_new = data_ecg.set_index('ID')\n",
    "data_ecg_new.loc[data_ecg_new.index.duplicated(keep=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bcp_new = data_bcp.set_index('ID')\n",
    "data_bcp_new.loc[data_bcp_new.index.duplicated(keep=False), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = f\"E:/Git/MillenniumAge\"\n",
    "\n",
    "feat_trgt = 'Возраст'\n",
    "\n",
    "components = {\n",
    "    'Оценка состава тела, женщины': {\n",
    "        'name': 'Оценка состава тела',\n",
    "        'path': f\"{dir_root}/data/Оценка состава тела/females\",\n",
    "        'bkg_count': 128,\n",
    "        'likelihood': 0.5\n",
    "    },\n",
    "    'Оценка состава тела, мужчины': {\n",
    "        'name': 'Оценка состава тела',\n",
    "        'path': f\"{dir_root}/data/Оценка состава тела/males\",\n",
    "        'bkg_count': 50,\n",
    "        'likelihood': 0.8\n",
    "    },\n",
    "    \n",
    "    'Электрокардиограмма, все': {\n",
    "        'name': 'Электрокардиограмма',\n",
    "        'path': f\"{dir_root}/data/Электрокардиограмма/all\",\n",
    "        'bkg_count': 200,\n",
    "        'likelihood': 0.8\n",
    "    },\n",
    "    'Электрокардиограмма, старше 15': {\n",
    "        'name': 'Электрокардиограмма',\n",
    "        'path': f\"{dir_root}/data/Электрокардиограмма/over15\",\n",
    "        'bkg_count': 180,\n",
    "        'likelihood': 0.66\n",
    "    },\n",
    "    'Электрокардиограмма, младше 15': {\n",
    "        'name': 'Электрокардиограмма',\n",
    "        'path': f\"{dir_root}/data/Электрокардиограмма/under15\",\n",
    "        'bkg_count': 30,\n",
    "        'likelihood': 0.66\n",
    "    },\n",
    "    \n",
    "    'Гематологические исследования, все': {\n",
    "        'name': 'Гематологические исследования',\n",
    "        'path': f\"{dir_root}/data/Гематологические исследования/all\",\n",
    "        'bkg_count': 600,\n",
    "        'likelihood': 0.6\n",
    "    },\n",
    "    'Гематологические исследования, старше 15': {\n",
    "        'name': 'Гематологические исследования',\n",
    "        'path': f\"{dir_root}/data/Гематологические исследования/over15\",\n",
    "        'bkg_count': 520,\n",
    "        'likelihood': 0.4\n",
    "    },\n",
    "    'Гематологические исследования, младше 15': {\n",
    "        'name': 'Гематологические исследования',\n",
    "        'path': f\"{dir_root}/data/Гематологические исследования/under15\",\n",
    "        'bkg_count': 80,\n",
    "        'likelihood': 0.6\n",
    "    },\n",
    "    \n",
    "    'Биохимические исследования 7, все': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/Биохимические исследования/7/all\",\n",
    "        'bkg_count': 280,\n",
    "        'likelihood': 0.77\n",
    "    },\n",
    "    'Биохимические исследования 7, старше 15': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/Биохимические исследования/7/over15\",\n",
    "        'bkg_count': 250,\n",
    "        'likelihood': 0.6\n",
    "    },\n",
    "    'Биохимические исследования 7, младше 15': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/Биохимические исследования/7/under15\",\n",
    "        'bkg_count': 36,\n",
    "        'likelihood': 0.9\n",
    "    },\n",
    "    'Биохимические исследования 9, все': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/Биохимические исследования/9/all\",\n",
    "        'bkg_count': 250,\n",
    "        'likelihood': 0.8\n",
    "    },\n",
    "    'Биохимические исследования 9, старше 15': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/Биохимические исследования/9/over15\",\n",
    "        'bkg_count': 200,\n",
    "        'likelihood': 0.62\n",
    "    },\n",
    "    'Биохимические исследования 9, младше 15': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/Биохимические исследования/9/under15\",\n",
    "        'bkg_count': 32,\n",
    "        'likelihood': 0.9\n",
    "    },\n",
    "    'Биохимические исследования 12': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/Биохимические исследования/12\",\n",
    "        'bkg_count': 180,\n",
    "        'likelihood': 0.65\n",
    "    },\n",
    "    'Биохимические исследования 23': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/data/Биохимические исследования/23\",\n",
    "        'bkg_count': 144,\n",
    "        'likelihood': 0.7\n",
    "    },\n",
    "    \n",
    "    'Половые гормоны, женщины': {\n",
    "        'name': 'Половые гормоны',\n",
    "        'path': f\"{dir_root}/data/Половые гормоны/females\",\n",
    "        'bkg_count': 62,\n",
    "        'likelihood': 0.85\n",
    "    },\n",
    "    'Половые гормоны, мужчины': {\n",
    "        'name': 'Половые гормоны',\n",
    "        'path': f\"{dir_root}/data/Половые гормоны/males\",\n",
    "        'bkg_count': 36,\n",
    "        'likelihood': 0.55\n",
    "    },\n",
    "    \n",
    "    'Гормоны 3, все': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/data/Гормоны/3/all\",\n",
    "        'bkg_count': 300,\n",
    "        'likelihood': 0.4\n",
    "    },\n",
    "    'Гормоны 3, старше 18': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/data/Гормоны/3/over18\",\n",
    "        'bkg_count': 280,\n",
    "        'likelihood': 0.17\n",
    "    },\n",
    "    'Гормоны 3, младше 18': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/data/Гормоны/3/under18\",\n",
    "        'bkg_count': 32,\n",
    "        'likelihood': 0.5\n",
    "    },\n",
    "    'Гормоны 5': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/data/Гормоны/5\",\n",
    "        'bkg_count': 200,\n",
    "        'likelihood': 0.37\n",
    "    },\n",
    "    'Гормоны 6': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/data/Гормоны/6\",\n",
    "        'bkg_count': 180,\n",
    "        'likelihood': 0.35\n",
    "    },\n",
    "}\n",
    "\n",
    "feats_all = []\n",
    "for comp in components:\n",
    "    components[comp]['data'] = pd.read_excel(f\"{components[comp]['path']}/data.xlsx\", index_col=0)\n",
    "    if 'Дата обследования' in components[comp]['data'].columns:\n",
    "        components[comp]['data']['Дата обследования'] = components[comp]['data']['Дата обследования'].dt.date\n",
    "    if 'Дата и время обследования' in components[comp]['data'].columns:\n",
    "        components[comp]['data']['Дата обследования'] = components[comp]['data']['Дата и время обследования'].dt.date\n",
    "    components[comp]['data'].insert(0, 'ID', components[comp]['data']['ФИО'].astype(str) + ' ' + components[comp]['data']['Дата обследования'].astype(str))\n",
    "    components[comp]['data'].insert(0, 'index', components[comp]['data'].index.astype(str))\n",
    "    components[comp]['feats'] = pd.read_excel(f\"{components[comp]['path']}/feats.xlsx\", index_col=0)\n",
    "    components[comp]['results'] = pd.read_excel(f\"{components[comp]['path']}/model/df.xlsx\", index_col=0)\n",
    "    components[comp]['metrics'] = pd.read_excel(f\"{components[comp]['path']}/model/metrics.xlsx\", index_col=0)\n",
    "    components[comp]['model'] = TabularModel.load_model(f\"{components[comp]['path']}/model\")\n",
    "    components[comp]['corrector'] = LinearBiasCorrector()\n",
    "    comp_results = components[comp]['results']\n",
    "    components[comp]['corrector'].fit(comp_results.loc[comp_results['Group'] == 'Train', feat_trgt].values, comp_results.loc[comp_results['Group'] == 'Train', 'Prediction'].values)\n",
    "    res_cols = ['Group', 'Prediction', 'Error', 'Prediction Unbiased', 'Error Unbiased']\n",
    "    components[comp]['data'].loc[components[comp]['data'].index, res_cols] = comp_results.loc[components[comp]['data'].index, res_cols]\n",
    "    components[comp]['data_shap'] = components[comp]['data'].copy()\n",
    "    \n",
    "    feats = components[comp]['feats'].index.values\n",
    "    feats = feats[feats != feat_trgt]\n",
    "    feats_all += list(feats)\n",
    "    feats_all += [f\"Предсказание {components[comp]['name']}\", f\"Возрастная Акселерация {components[comp]['name']}\"]\n",
    "    \n",
    "    components[comp]['feats_corr'] = pd.DataFrame(index=feats, columns=['Correlation'])\n",
    "    for f in feats:\n",
    "        components[comp]['feats_corr'].at[f, 'Correlation'], _ = scipy.stats.pearsonr(components[comp]['data'].loc[:, f].values, components[comp]['data'].loc[:, feat_trgt].values)\n",
    "        \n",
    "feats_all = list(dict.fromkeys(feats_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in components:\n",
    "    print(f\"{comp}: {components[comp]['data'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create united data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgt_components = [\n",
    "    'Гематологические исследования, старше 15',\n",
    "    # 'Биохимические исследования 7, старше 15',\n",
    "    # 'Биохимические исследования 9, старше 15',\n",
    "    # 'Биохимические исследования 12',\n",
    "    'Биохимические исследования 23',\n",
    "    'Половые гормоны, женщины',\n",
    "    'Половые гормоны, мужчины',\n",
    "    'Гормоны 6',\n",
    "    \n",
    "    'Оценка состава тела, женщины',\n",
    "    'Оценка состава тела, мужчины',\n",
    "    \n",
    "    'Электрокардиограмма, старше 15',\n",
    "]\n",
    "\n",
    "dfs = {}\n",
    "for comp in trgt_components:\n",
    "    feats = ['Возраст', 'Пол'] + components[comp]['feats'].index.to_list()\n",
    "    df = components[comp]['data'].set_index('ID').loc[:, feats]\n",
    "    if not df.index.is_unique:\n",
    "        print(f\"{comp} {df.shape} index unique: {df.index.is_unique}, number of duplicates: {len(df.index[df.index.duplicated()])}\")\n",
    "        df = df[~df.index.duplicated(keep='first')]\n",
    "    else:\n",
    "        print(f\"{comp} {df.shape} index unique: {df.index.is_unique}\")\n",
    "    dfs[comp] = df\n",
    "\n",
    "index_cmn = reduce(pd.Index.union, [dfs[comp].index for comp in trgt_components]).to_list()\n",
    "feats_cmn = ['Возраст', 'Пол'] + reduce(pd.Index.union, [components[comp]['feats'].index for comp in trgt_components]).to_list()\n",
    "\n",
    "data = pd.DataFrame(index=index_cmn, columns=feats_cmn)\n",
    "for comp in trgt_components:\n",
    "    data = data.combine_first(dfs[comp])\n",
    "\n",
    "print(data.shape)\n",
    "data.to_excel(f\"{dir_root}/data/data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/YandexDisk/Work/bbd/millennium/Результаты чекап'\n",
    "checkup_series = 1\n",
    "path_to = f\"{path}/test\"\n",
    "\n",
    "shutil.unpack_archive(f\"{path}/{checkup_series}/example.zip\", path_to)\n",
    "\n",
    "folders = [os.path.split(f.path)[1] for f in os.scandir(path_to) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse folders with samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/YandexDisk/Work/bbd/millennium/Результаты чекап/2'\n",
    "folders = [os.path.split(f.path)[1] for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "dir_root = f\"E:/Git/MillenniumAge\"\n",
    "\n",
    "# Анализы\n",
    "feats_anl = pd.read_excel(f\"{dir_root}/data/processing/Результаты анализов/features.xlsx\")\n",
    "if feats_anl['prefix'].is_unique:\n",
    "    feats_anl.set_index('prefix', inplace=True)\n",
    "else:\n",
    "    raise ValueError(f\"Features' prefixes are not unique!\")\n",
    "feats_anl_same_line = feats_anl.loc[feats_anl['line'] == 0, :]\n",
    "feats_anl_diff_line = feats_anl.loc[feats_anl['line'] != 0, :]\n",
    "\n",
    "feats_anl_same_line_dict = dict(zip(feats_anl_same_line.index.values, feats_anl_same_line['feature'].values))\n",
    "feats_anl_diff_line_dict = dict(zip(feats_anl_diff_line.index.values, feats_anl_diff_line['feature'].values))\n",
    "\n",
    "with open(f\"{dir_root}/data/processing/Результаты анализов/skip_starts.txt\") as f:\n",
    "    skip_starts_anl = tuple(list(set(f.read().splitlines())))\n",
    "\n",
    "missed_pages_anl = {}\n",
    "missed_lines_anl = []\n",
    "\n",
    "df_anl = pd.DataFrame(columns=['Sample ID', 'Pages', 'File', '№ направления', 'ФИО', 'Дата рождения', 'Дата обследования', 'Пол'] + list(feats_anl['feature'].unique()))\n",
    "\n",
    "# ЭКГ\n",
    "feats_ecg = pd.read_excel(f\"{dir_root}/data/processing/Результаты экг/features.xlsx\", index_col=0)\n",
    "df_ecg = pd.DataFrame(columns=['Sample ID', 'File'] + feats_ecg.index.to_list())\n",
    "\n",
    "# Медасс\n",
    "feats_bcp = pd.read_excel(f\"{dir_root}/data/processing/Результаты медасс/features.xlsx\", index_col=0)\n",
    "df_bcp = pd.DataFrame(columns=['Sample ID', 'File'] + feats_bcp.index.to_list())\n",
    "\n",
    "\n",
    "folders_files_types = {}\n",
    "\n",
    "for folder in folders:\n",
    "    files = glob(f\"{path}/{folder}/*.pdf\")\n",
    "    \n",
    "    folders_files_types[folder] = {}\n",
    "    \n",
    "    for file in files:\n",
    "        head, fn = os.path.split(file)\n",
    "        reader = PdfReader(file)\n",
    "        \n",
    "        print(f\"{folder}: {fn}\")\n",
    "        \n",
    "        start_page_lines = reader.pages[0].extract_text().splitlines()\n",
    "        \n",
    "        if len(start_page_lines) > 50 and (start_page_lines[48] == 'КОМПЬЮТЕРНАЯ ИНТЕРПРЕТАЦИЯ ЭКГ' or start_page_lines[49] == 'КОМПЬЮТЕРНАЯ ИНТЕРПРЕТАЦИЯ ЭКГ'):\n",
    "            folders_files_types[folder][file] = 'ЭКГ'\n",
    "            \n",
    "            pages = {0: reader.pages[0].extract_text().splitlines()}\n",
    "            \n",
    "            # Нет роста или веса\n",
    "            if not any(x in pages[0][15] for x in ['см', 'кг']):\n",
    "                pages[0] = pages[0][0:15] + [''] + pages[0][15:]\n",
    "            # Лишняя строчка - есть ФИО врача    \n",
    "            if (pages[0][17] != 'Дата/время:') and (pages[0][18] == 'Дата/время:'):\n",
    "                pages[0].pop(17)\n",
    "            # Нет номера \n",
    "            if pages[0][16] == 'Дата/время:':\n",
    "                pages[0] = pages[0][0:16] + [''] + pages[0][16:]\n",
    "                \n",
    "            sample_name = re.sub(' +', ' ', pages[int(feats_ecg.at['ФИО', 'page'])][int(feats_ecg.at['ФИО', 'row'])]).rstrip()\n",
    "            sample_number = re.sub(' +', ' ', pages[int(feats_ecg.at['Номер', 'page'])][int(feats_ecg.at['Номер', 'row'])]).rstrip()\n",
    "            sample_datetime = re.sub(' +', ' ', pages[int(feats_ecg.at['Дата и время обследования', 'page'])][int(feats_ecg.at['Дата и время обследования', 'row'])]).rstrip()\n",
    "            \n",
    "            sample_id = folder\n",
    "            sample_id_second = f\"{sample_name} {sample_number} {sample_datetime}\"\n",
    "            \n",
    "            df_ecg.at[sample_id, 'Sample ID'] = sample_id_second\n",
    "            df_ecg.at[sample_id, 'File'] = fn\n",
    "            \n",
    "            for f in feats_ecg.index:\n",
    "                \n",
    "                f_str = re.sub(' +', ' ', pages[int(feats_ecg.at[f, 'page'])][int(feats_ecg.at[f, 'row'])]).rstrip()\n",
    "                f_re_str = feats_ecg.at[f, 're_string']\n",
    "                if not pd.isna(f_re_str):\n",
    "                    f_re_res = re.findall(fr\"{f_re_str}\", f_str)\n",
    "                    if len(f_re_res) > 0:\n",
    "                        f_re_res = f_re_res[0]\n",
    "                        f_re_group = feats_ecg.at[f, 're_group']\n",
    "                        if not pd.isna(f_re_group):\n",
    "                            f_val = f_re_res[int(f_re_group)]\n",
    "                        else:\n",
    "                            f_val = f_re_res\n",
    "                    else:\n",
    "                        f_val = ''\n",
    "                else:\n",
    "                    f_val = f_str\n",
    "                \n",
    "                df_ecg.at[sample_id, f] = f_val\n",
    "            \n",
    "        elif start_page_lines[2] == 'Оценка состава тела (биоимпедансный анализ)':\n",
    "            folders_files_types[folder][file] = 'Биоимпеданс'\n",
    "            \n",
    "            pages = {}\n",
    "            for p_id, p in enumerate(reader.pages):\n",
    "                pages[p_id] = p.extract_text().splitlines()\n",
    "                \n",
    "            if len(pages) == 5:\n",
    "            \n",
    "                if 'Удельный основной обмен (ккал/м2/сут.)' in pages[0]:\n",
    "                    pages[0].remove('Удельный основной обмен (ккал/м2/сут.)')\n",
    "                if 'Удельный основной обмен (ккал/м 2/сут.)' in pages[0]:\n",
    "                    pages[0].remove('Удельный основной обмен (ккал/м 2/сут.)')\n",
    "                if 'по БЖМ' in pages[0]:\n",
    "                    pages[0].remove('по БЖМ')\n",
    "                if pages[2][7].startswith('Ваш удельный основной обмен:'):\n",
    "                    pages[2].pop(7)\n",
    "                skip_rows_page_4 = [\n",
    "                    'Индекс',\n",
    "                    'скелетно-мышечной',\n",
    "                    'массы (кг/м2)',\n",
    "                    'массы (кг/м 2)',\n",
    "                    '(кг)'\n",
    "                ]\n",
    "                for sr in skip_rows_page_4:\n",
    "                    if sr in pages[4]:\n",
    "                        pages[4].remove(sr)\n",
    "                \n",
    "                sample_name = re.sub(' +', ' ', pages[int(feats_bcp.at['ФИО', 'page'])][int(feats_bcp.at['ФИО', 'row'])]).rstrip()\n",
    "                datetime_re_str = feats_bcp.at['Дата и время обследования', 're_string']\n",
    "                sample_datetime = re.findall(fr\"{datetime_re_str}\", pages[int(feats_bcp.at['Дата и время обследования', 'page'])][int(feats_bcp.at['Дата и время обследования', 'row'])])[0]\n",
    "                \n",
    "                sample_id = folder\n",
    "                sample_id_second = f\"{sample_name} {sample_datetime}\"\n",
    "                \n",
    "                df_bcp.at[sample_id, 'File'] = fn\n",
    "                df_bcp.at[sample_id, 'Sample ID'] = sample_id_second\n",
    "                \n",
    "                for f in feats_bcp.index:\n",
    "                    \n",
    "                    f_str = re.sub(' +', ' ', pages[int(feats_bcp.at[f, 'page'])][int(feats_bcp.at[f, 'row'])]).rstrip()\n",
    "                    f_re_str = feats_bcp.at[f, 're_string']\n",
    "                    if not pd.isna(f_re_str):\n",
    "                        f_re_res = re.findall(fr\"{f_re_str}\", f_str)[0]\n",
    "                        f_re_group = feats_bcp.at[f, 're_group']\n",
    "                        if not pd.isna(f_re_group):\n",
    "                            f_val = f_re_res[int(f_re_group)]\n",
    "                        else:\n",
    "                            f_val = f_re_res\n",
    "                    else:\n",
    "                        f_val = f_str\n",
    "                    \n",
    "                    df_bcp.at[sample_id, f] = f_val\n",
    "            \n",
    "        else:\n",
    "            folders_files_types[folder][file] = 'Другое'\n",
    "            \n",
    "            pages = {}\n",
    "            for p_id, p in enumerate(reader.pages):\n",
    "                lines = p.extract_text().splitlines()\n",
    "                \n",
    "                if lines[0] == 'Фамилия:':\n",
    "                    \n",
    "                    line_sex = 7\n",
    "                    line_birth = 4\n",
    "                    if lines[1] == 'Дата рождения:ЛПУ:':\n",
    "                        line_sex = 6\n",
    "                        line_birth = 3\n",
    "                    \n",
    "                    if lines[10].startswith('Дата:'):\n",
    "                        line_date = 10\n",
    "                        line_name = 12\n",
    "                    elif lines[9].startswith('Дата:'):\n",
    "                        line_date = 9\n",
    "                        line_name = 11\n",
    "                    else:\n",
    "                        raise ValueError(f\"Wrong ID parsing: {fn} {p_id}\")\n",
    "                        \n",
    "                    sample_name = lines[line_name].capitalize() + ' ' + re.findall(r\"(.*)Имя\", lines[line_name - 1])[0]\n",
    "                    sample_date = re.findall(r\"Дата: (.*)\", lines[line_date])[0]\n",
    "                    sample_number = lines[3]\n",
    "                    \n",
    "                    sample_id = folder\n",
    "                    sample_id_second = f\"{sample_name} {sample_date} {sample_number}\"\n",
    "                    \n",
    "                    if sample_id in df_anl.index:\n",
    "                        df_anl.at[sample_id, 'Pages'] += f' {p_id}'\n",
    "                    else:\n",
    "                        df_anl.at[sample_id, 'Pages'] = f'{p_id}'\n",
    "\n",
    "                    df_anl.at[sample_id, 'File'] = fn\n",
    "                    df_anl.at[sample_id, 'Sample ID'] = sample_id_second\n",
    "                    df_anl.at[sample_id, '№ направления'] = sample_number\n",
    "                    df_anl.at[sample_id, 'ФИО'] = sample_name\n",
    "                    df_anl.at[sample_id, 'Дата рождения'] = lines[line_birth].replace('17.03.7979', '17.03.1979')\n",
    "                    df_anl.at[sample_id, 'Дата обследования'] = sample_date\n",
    "                    df_anl.at[sample_id, 'Пол'] = re.findall(r\"Пол: (.+)\", lines[line_sex])[0][0]\n",
    "\n",
    "                    for line_id, line in enumerate(lines):\n",
    "                        line = line.replace(\"не обнаружено\", \"0.0\")\n",
    "                        line = line.replace(\"\\u2009\", \"\")\n",
    "                        line = line.replace(\"в 1 мл\", \"в мл\")\n",
    "                        if line in feats_anl_diff_line_dict:\n",
    "                            target_line = lines[line_id + feats_anl_diff_line.at[line, 'line']]\n",
    "                            line_parse = re.findall(fr\"([-+]?(?:\\d+\\.\\d+|\\d+|\\.\\d+)).*\", target_line)\n",
    "                            df_anl.at[sample_id, feats_anl_diff_line_dict[line]] = line_parse[0]\n",
    "                        else:\n",
    "                            line = line.replace(\" - \", \"-\")\n",
    "                            line_parse_w_units = re.findall(fr\"(.*)\\s([-+]?(?:\\d+\\.\\d+|\\d+|\\.\\d+)) (.*)\", line)\n",
    "                            line_parse_wo_units = re.findall(fr\"(.*)\\s([-+]?(?:\\d+\\.\\d+|\\d+|\\.\\d+)) \", line)\n",
    "                            if len(line_parse_w_units) > 0:\n",
    "                                if line_parse_w_units[0][0] in feats_anl_same_line_dict:\n",
    "                                    feat_unit = feats_anl_same_line.at[line_parse_w_units[0][0], 'unit']\n",
    "                                    if not pd.isna(feat_unit):\n",
    "                                        if feat_unit in line_parse_w_units[0][2] or feat_unit.replace('МЕ/', 'Ед/') in line_parse_w_units[0][2]:\n",
    "                                            df_anl.at[sample_id, feats_anl_same_line_dict[line_parse_w_units[0][0]]] = line_parse_w_units[0][1]\n",
    "                                        else:\n",
    "                                            print(f\"{line} ({fn} {p_id} {line_id})\")\n",
    "                                    else:\n",
    "                                        df_anl.at[sample_id, feats_anl_same_line_dict[line_parse_w_units[0][0]]] = line_parse_w_units[0][1]\n",
    "                            elif len(line_parse_wo_units) > 0:\n",
    "                                print(f\"Check: {line_parse_wo_units}\")\n",
    "                                df_anl.at[sample_id, feats_anl_same_line_dict[line_parse_wo_units[0][0]]] = line_parse_wo_units[0][1]\n",
    "\n",
    "df_anl = df_anl.apply(pd.to_numeric, errors='ignore')\n",
    "df_anl['Дата рождения'] = pd.to_datetime(df_anl['Дата рождения'], format=\"%d.%m.%Y\").dt.date\n",
    "df_anl['Дата обследования'] = pd.to_datetime(df_anl['Дата обследования'], format=\"%d.%m.%Y\").dt.date\n",
    "df_anl.insert(7, 'Возраст', (df_anl['Дата обследования'] - df_anl['Дата рождения']) / np.timedelta64(1, 'D') / 365.25)\n",
    "df_anl = df_anl.loc[:, ['Возраст', 'Пол'] + list(feats_anl['feature'].unique())]\n",
    "df_anl.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "df_ecg = df_ecg.apply(pd.to_numeric, errors='ignore')\n",
    "df_ecg['Пол'] = df_ecg['Пол'].str.upper()\n",
    "df_ecg['Дата и время обследования'] = pd.to_datetime(df_ecg['Дата и время обследования'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df_ecg = df_ecg.loc[:, feats_ecg.index.to_list()]\n",
    "df_ecg.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "df_bcp = df_bcp.apply(pd.to_numeric, errors='ignore')\n",
    "df_bcp['Дата и время обследования'] = pd.to_datetime(df_bcp['Дата и время обследования'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df_bcp = df_bcp.loc[:, feats_bcp.index.to_list()]\n",
    "df_bcp.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "index_cmn = reduce(pd.Index.union, [x.index for x in [df_anl, df_bcp, df_ecg]]).to_list()\n",
    "feats_cmn = df_anl.columns.to_list() + df_ecg.columns.to_list() + df_bcp.columns.to_list()\n",
    "feats_cmn = list(dict.fromkeys(feats_cmn))\n",
    "\n",
    "data = pd.DataFrame(index=index_cmn, columns=feats_cmn)\n",
    "for x in [df_anl, df_bcp, df_ecg]:\n",
    "    data = data.combine_first(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_bcp.at[f, 're_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg.columns[df_ecg.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/YandexDisk/Work/bbd/millennium/Результаты чекап/3'\n",
    "folder = 'Бармина Т. Н' #'Авдеева Г. Н' #'Бармина Т. Н'\n",
    "file = 'cf16542c2ce505abe7da0de1f8ed430e.pdf' #'Биоимпеданс.pdf' #'cf16542c2ce505abe7da0de1f8ed430e.pdf'\n",
    "reader = PdfReader(f\"{path}/{folder}/{file}\")\n",
    "print(reader.pages[4].extract_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
