{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import BaseCrossValidator, ParameterGrid, ParameterSampler\n",
    "import torch\n",
    "import pickle\n",
    "import shutil\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "from regression_bias_corrector import LinearBiasCorrector\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import matplotlib.lines as mlines\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats\n",
    "from functools import reduce\n",
    "import shutil\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "import logging\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "logging.getLogger(\"pypdf\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check initial data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/YandexDisk/Work/bbd/millennium'\n",
    "\n",
    "data_anl = pd.read_excel(f\"{path}/Результаты анализов/data.xlsx\", index_col=0)\n",
    "data_anl['Дата обследования'] = data_anl['Дата обследования'].dt.date\n",
    "data_anl.insert(0, 'ID', data_anl['ФИО'].astype(str) + ' ' + data_anl['Дата обследования'].astype(str))\n",
    "ids_counts_anl = data_anl['ФИО'].value_counts()\n",
    "sorter_anl = ids_counts_anl.index.to_list()\n",
    "data_anl.sort_values(by=\"ФИО\", key=lambda column: column.map(lambda e: sorter_anl.index(e)), inplace=True)\n",
    "feats_anl = pd.read_excel(f\"{path}/Результаты анализов/feats_with_metrics.xlsx\", index_col=0)\n",
    "\n",
    "data_ecg = pd.read_excel(f\"{path}/Результаты экг/data.xlsx\", index_col=0)\n",
    "data_ecg['Дата обследования'] = data_ecg['Дата и время обследования'].dt.date\n",
    "data_ecg.insert(0, 'ID', data_ecg['ФИО'].astype(str) + ' ' + data_ecg['Дата обследования'].astype(str))\n",
    "ids_counts_ecg = data_ecg['ФИО'].value_counts()\n",
    "sorter_ecg = ids_counts_ecg.index.to_list()\n",
    "data_ecg.sort_values(by=\"ФИО\", key=lambda column: column.map(lambda e: sorter_ecg.index(e)), inplace=True)\n",
    "feats_ecg = pd.read_excel(f\"{path}/Результаты экг/feats_with_metrics.xlsx\", index_col=0)\n",
    "\n",
    "data_bcp = pd.read_excel(f\"{path}/Результаты медасс/data.xlsx\", index_col=0)\n",
    "data_bcp['Дата обследования'] = data_bcp['Дата и время обследования'].dt.date\n",
    "data_bcp.insert(0, 'ID', data_bcp['ФИО'].astype(str) + ' ' + data_bcp['Дата обследования'].astype(str))\n",
    "ids_counts_bcp = data_bcp['ФИО'].value_counts()\n",
    "sorter_bcp = ids_counts_bcp.index.to_list()\n",
    "data_bcp.sort_values(by=\"ФИО\", key=lambda column: column.map(lambda e: sorter_bcp.index(e)), inplace=True)\n",
    "feats_bcp = pd.read_excel(f\"{path}/Результаты медасс/feats_with_metrics.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_anl.index.is_unique)\n",
    "print(data_ecg.index.is_unique)\n",
    "print(data_bcp.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set.intersection(set(data_anl['ФИО']), set(data_ecg['ФИО']))))\n",
    "print(len(set.intersection(set(data_bcp['ФИО']), set(data_ecg['ФИО']))))\n",
    "print(len(set.intersection(set(data_anl['ФИО']), set(data_bcp['ФИО']))))\n",
    "print(len(set.intersection(set(data_anl['ФИО']), set(data_bcp['ФИО']), set(data_ecg['ФИО']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set.intersection(set(data_anl['ID']), set(data_ecg['ID']))))\n",
    "print(len(set.intersection(set(data_bcp['ID']), set(data_ecg['ID']))))\n",
    "print(len(set.intersection(set(data_anl['ID']), set(data_bcp['ID']))))\n",
    "print(len(set.intersection(set(data_anl['ID']), set(data_bcp['ID']), set(data_ecg['ID']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anl_new = data_anl.set_index('ID')\n",
    "data_anl_new.loc[data_anl_new.index.duplicated(keep=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ecg_new = data_ecg.set_index('ID')\n",
    "data_ecg_new.loc[data_ecg_new.index.duplicated(keep=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bcp_new = data_bcp.set_index('ID')\n",
    "data_bcp_new.loc[data_bcp_new.index.duplicated(keep=False), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = f\"E:/YandexDisk/Work/bbd/millennium/models\"\n",
    "\n",
    "feat_trgt = 'Возраст'\n",
    "\n",
    "components = {\n",
    "    'Оценка состава тела, женщины': {\n",
    "        'name': 'Оценка состава тела',\n",
    "        'path': f\"{dir_root}/Оценка состава тела/subsets/females(641)\",\n",
    "    },\n",
    "    'Оценка состава тела, мужчины': {\n",
    "        'name': 'Оценка состава тела',\n",
    "        'path': f\"{dir_root}/Оценка состава тела/subsets/males(240)\",\n",
    "    },\n",
    "    \n",
    "    'Электрокардиограмма, все': {\n",
    "        'name': 'Электрокардиограмма',\n",
    "        'path': f\"{dir_root}/Электрокардиограмма/subsets/all(1049)\",\n",
    "    },\n",
    "    'Электрокардиограмма, старше 15': {\n",
    "        'name': 'Электрокардиограмма',\n",
    "        'path': f\"{dir_root}/Электрокардиограмма/subsets/over15(899)\",\n",
    "    },\n",
    "    'Электрокардиограмма, младше 15': {\n",
    "        'name': 'Электрокардиограмма',\n",
    "        'path': f\"{dir_root}/Электрокардиограмма/subsets/under15(150)\",\n",
    "    },\n",
    "    \n",
    "    'Гематологические исследования, все': {\n",
    "        'name': 'Гематологические исследования',\n",
    "        'path': f\"{dir_root}/Гематологические исследования/subsets/all(3160)\",\n",
    "    },\n",
    "    'Гематологические исследования, старше 15': {\n",
    "        'name': 'Гематологические исследования',\n",
    "        'path': f\"{dir_root}/Гематологические исследования/subsets/over15(2735)\",\n",
    "    },\n",
    "    'Гематологические исследования, младше 15': {\n",
    "        'name': 'Гематологические исследования',\n",
    "        'path': f\"{dir_root}/Гематологические исследования/subsets/under15(425)\",\n",
    "    },\n",
    "    \n",
    "    'Биохимические исследования 7, все': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (7)/subsets/all(1444)\",\n",
    "    },\n",
    "    'Биохимические исследования 7, старше 15': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (7)/subsets/over15(1262)\",\n",
    "    },\n",
    "    'Биохимические исследования 7, младше 15': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (7)/subsets/under15(182)\",\n",
    "    },\n",
    "    'Биохимические исследования 9, все': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (9)/subsets/all(1238)\",\n",
    "    },\n",
    "    'Биохимические исследования 9, старше 15': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (9)/subsets/over15(1074)\",\n",
    "    },\n",
    "    'Биохимические исследования 9, младше 15': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (9)/subsets/under15(164)\",\n",
    "    },\n",
    "    'Биохимические исследования 12': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (12)/subsets/all(907)\",\n",
    "    },\n",
    "    'Биохимические исследования 23': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (23)/subsets/all(721)\",\n",
    "    },\n",
    "    'Биохимические исследования 25, женщины': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (чекап)/subsets/F\",\n",
    "    },\n",
    "    'Биохимические исследования 25, мужчины': {\n",
    "        'name': 'Биохимические исследования',\n",
    "        'path': f\"{dir_root}/Биохимические исследования (чекап)/subsets/M\",\n",
    "    },\n",
    "    \n",
    "    'Половые гормоны 6, женщины': {\n",
    "        'name': 'Половые гормоны',\n",
    "        'path': f\"{dir_root}/Половые гормоны (6)/subsets/females(312)\",\n",
    "    },\n",
    "    'Половые гормоны 8, женщины': {\n",
    "        'name': 'Половые гормоны',\n",
    "        'path': f\"{dir_root}/Половые гормоны (чекап)/subsets/F\",\n",
    "    },\n",
    "    'Половые гормоны 6, мужчины': {\n",
    "        'name': 'Половые гормоны',\n",
    "        'path': f\"{dir_root}/Половые гормоны (6)/subsets/males(179)\",\n",
    "    },\n",
    "    'Половые гормоны 10, мужчины': {\n",
    "        'name': 'Половые гормоны',\n",
    "        'path': f\"{dir_root}/Половые гормоны (чекап)/subsets/M\",\n",
    "    },\n",
    "    \n",
    "    'Гормоны 3, все': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/Гормоны (3)/subsets/all(1558)\",\n",
    "    },\n",
    "    'Гормоны 3, старше 18': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/Гормоны (3)/subsets/over18(1396)\",\n",
    "    },\n",
    "    'Гормоны 3, младше 18': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/Гормоны (3)/subsets/under18(162)\",\n",
    "    },\n",
    "    'Гормоны 5': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/Гормоны (5)/subsets/all(1069)\",\n",
    "    },\n",
    "    'Гормоны 6': {\n",
    "        'name': 'Гормоны',\n",
    "        'path': f\"{dir_root}/Гормоны (6)/subsets//all(906)\",\n",
    "    },\n",
    "}\n",
    "\n",
    "feats_all = []\n",
    "for comp in components:\n",
    "    components[comp]['data'] = pd.read_excel(f\"{components[comp]['path']}/data.xlsx\", index_col=0)\n",
    "    if 'Дата обследования' in components[comp]['data'].columns:\n",
    "        components[comp]['data']['Дата обследования'] = components[comp]['data']['Дата обследования'].dt.date\n",
    "    if 'Дата и время обследования' in components[comp]['data'].columns:\n",
    "        components[comp]['data']['Дата обследования'] = components[comp]['data']['Дата и время обследования'].dt.date\n",
    "    components[comp]['data'].insert(0, 'ID', components[comp]['data']['ФИО'].astype(str) + ' ' + components[comp]['data']['Дата обследования'].astype(str))\n",
    "    components[comp]['data'].insert(0, 'index', components[comp]['data'].index.astype(str))\n",
    "    components[comp]['feats'] = pd.read_excel(f\"{components[comp]['path']}/feats.xlsx\", index_col=0)\n",
    "    #components[comp]['results'] = pd.read_excel(f\"{components[comp]['path']}/model/df.xlsx\", index_col=0)\n",
    "    #components[comp]['metrics'] = pd.read_excel(f\"{components[comp]['path']}/model/metrics.xlsx\", index_col=0)\n",
    "    #components[comp]['model'] = TabularModel.load_model(f\"{components[comp]['path']}/model\")\n",
    "    #components[comp]['corrector'] = LinearBiasCorrector()\n",
    "    #comp_results = components[comp]['results']\n",
    "    #components[comp]['corrector'].fit(comp_results.loc[comp_results['Group'] == 'Train', feat_trgt].values, comp_results.loc[comp_results['Group'] == 'Train', 'Prediction'].values)\n",
    "    #res_cols = ['Group', 'Prediction', 'Error', 'Prediction Unbiased', 'Error Unbiased']\n",
    "    #components[comp]['data'].loc[components[comp]['data'].index, res_cols] = comp_results.loc[components[comp]['data'].index, res_cols]\n",
    "    #components[comp]['data_shap'] = components[comp]['data'].copy()\n",
    "    \n",
    "    feats = components[comp]['feats'].index.values\n",
    "    feats = feats[feats != feat_trgt]\n",
    "    feats_all += list(feats)\n",
    "    feats_all += [f\"Предсказание {components[comp]['name']}\", f\"Возрастная Акселерация {components[comp]['name']}\"]\n",
    "    \n",
    "    components[comp]['feats_corr'] = pd.DataFrame(index=feats, columns=['Correlation'])\n",
    "    for f in feats:\n",
    "        components[comp]['feats_corr'].at[f, 'Correlation'], _ = scipy.stats.pearsonr(components[comp]['data'].loc[:, f].values, components[comp]['data'].loc[:, feat_trgt].values)\n",
    "        \n",
    "feats_all = list(dict.fromkeys(feats_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in components:\n",
    "    print(f\"{comp}: {components[comp]['data'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create united data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgt_components = [\n",
    "    'Гематологические исследования, старше 15',\n",
    "    \n",
    "    # 'Биохимические исследования 7, старше 15',\n",
    "    # 'Биохимические исследования 9, старше 15',\n",
    "    # 'Биохимические исследования 12',\n",
    "    # 'Биохимические исследования 23',\n",
    "    'Биохимические исследования 25, женщины',\n",
    "    'Биохимические исследования 25, мужчины',\n",
    "    \n",
    "    'Половые гормоны 8, женщины',\n",
    "    'Половые гормоны 10, мужчины',\n",
    "    \n",
    "    'Гормоны 6',\n",
    "    \n",
    "    'Оценка состава тела, женщины',\n",
    "    'Оценка состава тела, мужчины',\n",
    "    \n",
    "    'Электрокардиограмма, старше 15',\n",
    "]\n",
    "\n",
    "dfs = {}\n",
    "for comp in trgt_components:\n",
    "    feats = ['Возраст', 'Пол'] + components[comp]['feats'].index.to_list()\n",
    "    df = components[comp]['data'].set_index('ID').loc[:, feats]\n",
    "    if not df.index.is_unique:\n",
    "        print(f\"{comp} {df.shape} index unique: {df.index.is_unique}, number of duplicates: {len(df.index[df.index.duplicated()])}\")\n",
    "        df = df[~df.index.duplicated(keep='first')]\n",
    "    else:\n",
    "        print(f\"{comp} {df.shape} index unique: {df.index.is_unique}\")\n",
    "    dfs[comp] = df\n",
    "\n",
    "index_cmn = reduce(pd.Index.union, [dfs[comp].index for comp in trgt_components]).to_list()\n",
    "feats_cmn = ['Возраст', 'Пол'] + reduce(pd.Index.union, [components[comp]['feats'].index for comp in trgt_components]).to_list()\n",
    "\n",
    "data = pd.DataFrame(index=index_cmn, columns=feats_cmn)\n",
    "for comp in trgt_components:\n",
    "    data = data.combine_first(dfs[comp])\n",
    "\n",
    "print(data.shape)\n",
    "data.to_excel(f\"{dir_root}/data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/YandexDisk/Work/bbd/millennium/Результаты чекап'\n",
    "checkup_series = 1\n",
    "path_to = f\"{path}/test\"\n",
    "\n",
    "shutil.unpack_archive(f\"{path}/{checkup_series}/example.zip\", path_to)\n",
    "\n",
    "folders = [os.path.split(f.path)[1] for f in os.scandir(path_to) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse folders with samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/YandexDisk/Work/bbd/millennium/Результаты чекап/1'\n",
    "folders = [os.path.split(f.path)[1] for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "dir_root = f\"E:/Git/MillenniumAge\"\n",
    "\n",
    "# Анализы\n",
    "feats_anl = pd.read_excel(f\"{dir_root}/data/processing/Результаты анализов/features.xlsx\")\n",
    "if feats_anl['prefix'].is_unique:\n",
    "    feats_anl.set_index('prefix', inplace=True)\n",
    "else:\n",
    "    raise ValueError(f\"Features' prefixes are not unique!\")\n",
    "feats_anl_same_line = feats_anl.loc[feats_anl['line'] == 0, :]\n",
    "feats_anl_diff_line = feats_anl.loc[feats_anl['line'] != 0, :]\n",
    "\n",
    "feats_anl_same_line_dict = dict(zip(feats_anl_same_line.index.values, feats_anl_same_line['feature'].values))\n",
    "feats_anl_diff_line_dict = dict(zip(feats_anl_diff_line.index.values, feats_anl_diff_line['feature'].values))\n",
    "\n",
    "df_anl = pd.DataFrame(columns=['Sample ID', 'Pages', 'File', '№ направления', 'ФИО', 'Дата рождения', 'Дата обследования', 'Пол'] + list(feats_anl['feature'].unique()))\n",
    "\n",
    "# ЭКГ\n",
    "feats_ecg = pd.read_excel(f\"{dir_root}/data/processing/Результаты экг/features.xlsx\", index_col=0)\n",
    "df_ecg = pd.DataFrame(columns=['Sample ID', 'File'] + feats_ecg.index.to_list())\n",
    "\n",
    "# Медасс\n",
    "feats_bcp = pd.read_excel(f\"{dir_root}/data/processing/Результаты медасс/features.xlsx\", index_col=0)\n",
    "df_bcp = pd.DataFrame(columns=['Sample ID', 'File'] + feats_bcp.index.to_list())\n",
    "\n",
    "\n",
    "folders_files_types = {}\n",
    "\n",
    "for folder in folders:\n",
    "    files = glob(f\"{path}/{folder}/*.pdf\")\n",
    "    \n",
    "    folders_files_types[folder] = {}\n",
    "    \n",
    "    for file in files:\n",
    "        head, fn = os.path.split(file)\n",
    "        reader = PdfReader(file)\n",
    "        \n",
    "        print(f\"{folder}: {fn}\")\n",
    "        \n",
    "        start_page_lines = reader.pages[0].extract_text().splitlines()\n",
    "        \n",
    "        if len(start_page_lines) > 50 and (start_page_lines[47] == 'КОМПЬЮТЕРНАЯ ИНТЕРПРЕТАЦИЯ ЭКГ' or start_page_lines[48] == 'КОМПЬЮТЕРНАЯ ИНТЕРПРЕТАЦИЯ ЭКГ' or start_page_lines[49] == 'КОМПЬЮТЕРНАЯ ИНТЕРПРЕТАЦИЯ ЭКГ'):\n",
    "            folders_files_types[folder][file] = 'ЭКГ'\n",
    "            \n",
    "            pages = {0: reader.pages[0].extract_text().splitlines()}\n",
    "            \n",
    "            # Нет роста или веса\n",
    "            if not any(x in pages[0][15] for x in ['см', 'кг']):\n",
    "                pages[0] = pages[0][0:15] + [''] + pages[0][15:]\n",
    "            # Лишняя строчка - есть ФИО врача    \n",
    "            if (pages[0][17] != 'Дата/время:') and (pages[0][18] == 'Дата/время:'):\n",
    "                pages[0].pop(17)\n",
    "            # Нет номера \n",
    "            if pages[0][16] == 'Дата/время:':\n",
    "                pages[0] = pages[0][0:16] + [''] + pages[0][16:]\n",
    "                \n",
    "            sample_name = re.sub(' +', ' ', pages[int(feats_ecg.at['ФИО', 'page'])][int(feats_ecg.at['ФИО', 'row'])]).rstrip()\n",
    "            sample_number = re.sub(' +', ' ', pages[int(feats_ecg.at['Номер', 'page'])][int(feats_ecg.at['Номер', 'row'])]).rstrip()\n",
    "            sample_datetime = re.sub(' +', ' ', pages[int(feats_ecg.at['Дата и время обследования', 'page'])][int(feats_ecg.at['Дата и время обследования', 'row'])]).rstrip()\n",
    "            \n",
    "            sample_id = folder\n",
    "            sample_id_second = f\"{sample_name} {sample_number} {sample_datetime}\"\n",
    "            \n",
    "            df_ecg.at[sample_id, 'Sample ID'] = sample_id_second\n",
    "            df_ecg.at[sample_id, 'File'] = fn\n",
    "            \n",
    "            for f in feats_ecg.index:\n",
    "                \n",
    "                f_str = re.sub(' +', ' ', pages[int(feats_ecg.at[f, 'page'])][int(feats_ecg.at[f, 'row'])]).rstrip()\n",
    "                f_re_str = feats_ecg.at[f, 're_string']\n",
    "                if not pd.isna(f_re_str):\n",
    "                    f_re_res = re.findall(fr\"{f_re_str}\", f_str)\n",
    "                    if len(f_re_res) > 0:\n",
    "                        f_re_res = f_re_res[0]\n",
    "                        f_re_group = feats_ecg.at[f, 're_group']\n",
    "                        if not pd.isna(f_re_group):\n",
    "                            f_val = f_re_res[int(f_re_group)]\n",
    "                        else:\n",
    "                            f_val = f_re_res\n",
    "                    else:\n",
    "                        f_val = ''\n",
    "                else:\n",
    "                    f_val = f_str\n",
    "                \n",
    "                df_ecg.at[sample_id, f] = f_val\n",
    "            \n",
    "        elif start_page_lines[2] == 'Оценка состава тела (биоимпедансный анализ)':\n",
    "            folders_files_types[folder][file] = 'Биоимпеданс'\n",
    "            \n",
    "            pages = {}\n",
    "            for p_id, p in enumerate(reader.pages):\n",
    "                pages[p_id] = p.extract_text().splitlines()\n",
    "                \n",
    "            if len(pages) == 5:\n",
    "            \n",
    "                if 'Удельный основной обмен (ккал/м2/сут.)' in pages[0]:\n",
    "                    pages[0].remove('Удельный основной обмен (ккал/м2/сут.)')\n",
    "                if 'Удельный основной обмен (ккал/м 2/сут.)' in pages[0]:\n",
    "                    pages[0].remove('Удельный основной обмен (ккал/м 2/сут.)')\n",
    "                if 'по БЖМ' in pages[0]:\n",
    "                    pages[0].remove('по БЖМ')\n",
    "                if pages[2][7].startswith('Ваш удельный основной обмен:'):\n",
    "                    pages[2].pop(7)\n",
    "                skip_rows_page_4 = [\n",
    "                    'Индекс',\n",
    "                    'скелетно-мышечной',\n",
    "                    'массы (кг/м2)',\n",
    "                    'массы (кг/м 2)',\n",
    "                    '(кг)'\n",
    "                ]\n",
    "                for sr in skip_rows_page_4:\n",
    "                    if sr in pages[4]:\n",
    "                        pages[4].remove(sr)\n",
    "                \n",
    "                sample_name = re.sub(' +', ' ', pages[int(feats_bcp.at['ФИО', 'page'])][int(feats_bcp.at['ФИО', 'row'])]).rstrip()\n",
    "                datetime_re_str = feats_bcp.at['Дата и время обследования', 're_string']\n",
    "                sample_datetime = re.findall(fr\"{datetime_re_str}\", pages[int(feats_bcp.at['Дата и время обследования', 'page'])][int(feats_bcp.at['Дата и время обследования', 'row'])])[0]\n",
    "                \n",
    "                sample_id = folder\n",
    "                sample_id_second = f\"{sample_name} {sample_datetime}\"\n",
    "                \n",
    "                df_bcp.at[sample_id, 'File'] = fn\n",
    "                df_bcp.at[sample_id, 'Sample ID'] = sample_id_second\n",
    "                \n",
    "                for f in feats_bcp.index:\n",
    "                    \n",
    "                    f_str = re.sub(' +', ' ', pages[int(feats_bcp.at[f, 'page'])][int(feats_bcp.at[f, 'row'])]).rstrip()\n",
    "                    f_re_str = feats_bcp.at[f, 're_string']\n",
    "                    if not pd.isna(f_re_str):\n",
    "                        f_re_res = re.findall(fr\"{f_re_str}\", f_str)[0]\n",
    "                        f_re_group = feats_bcp.at[f, 're_group']\n",
    "                        if not pd.isna(f_re_group):\n",
    "                            f_val = f_re_res[int(f_re_group)]\n",
    "                        else:\n",
    "                            f_val = f_re_res\n",
    "                    else:\n",
    "                        f_val = f_str\n",
    "                    \n",
    "                    df_bcp.at[sample_id, f] = f_val\n",
    "            \n",
    "        else:\n",
    "            folders_files_types[folder][file] = 'Другое'\n",
    "            \n",
    "            pages = {}\n",
    "            for p_id, p in enumerate(reader.pages):\n",
    "                lines = p.extract_text().splitlines()\n",
    "                \n",
    "                if lines[0] == 'Фамилия:':\n",
    "                    \n",
    "                    line_sex = 7\n",
    "                    line_birth = 4\n",
    "                    if lines[1] == 'Дата рождения:ЛПУ:':\n",
    "                        line_sex = 6\n",
    "                        line_birth = 3\n",
    "                    \n",
    "                    if lines[10].startswith('Дата:'):\n",
    "                        line_date = 10\n",
    "                        line_name = 12\n",
    "                    elif lines[9].startswith('Дата:'):\n",
    "                        line_date = 9\n",
    "                        line_name = 11\n",
    "                    else:\n",
    "                        raise ValueError(f\"Wrong ID parsing: {fn} {p_id}\")\n",
    "                        \n",
    "                    sample_name = lines[line_name].capitalize() + ' ' + re.findall(r\"(.*)Имя\", lines[line_name - 1])[0]\n",
    "                    sample_date = re.findall(r\"Дата: (.*)\", lines[line_date])[0]\n",
    "                    sample_number = lines[3]\n",
    "                    \n",
    "                    sample_id = folder\n",
    "                    sample_id_second = f\"{sample_name} {sample_date} {sample_number}\"\n",
    "                    \n",
    "                    if sample_id in df_anl.index:\n",
    "                        df_anl.at[sample_id, 'Pages'] += f' {p_id}'\n",
    "                    else:\n",
    "                        df_anl.at[sample_id, 'Pages'] = f'{p_id}'\n",
    "\n",
    "                    df_anl.at[sample_id, 'File'] = fn\n",
    "                    df_anl.at[sample_id, 'Sample ID'] = sample_id_second\n",
    "                    df_anl.at[sample_id, '№ направления'] = sample_number\n",
    "                    df_anl.at[sample_id, 'ФИО'] = sample_name\n",
    "                    df_anl.at[sample_id, 'Дата рождения'] = lines[line_birth].replace('17.03.7979', '17.03.1979')\n",
    "                    df_anl.at[sample_id, 'Дата обследования'] = sample_date\n",
    "                    df_anl.at[sample_id, 'Пол'] = re.findall(r\"Пол: (.+)\", lines[line_sex])[0][0]\n",
    "\n",
    "                    for line_id, line in enumerate(lines):\n",
    "                        line = line.replace(\"не обнаружено\", \"0.0\")\n",
    "                        line = line.replace(\"\\u2009\", \"\")\n",
    "                        line = line.replace(\"в 1 мл\", \"в мл\")\n",
    "                        if line in feats_anl_diff_line_dict:\n",
    "                            target_line = lines[line_id + feats_anl_diff_line.at[line, 'line']]\n",
    "                            line_parse = re.findall(fr\"([-+]?(?:\\d+\\.\\d+|\\d+|\\.\\d+)).*\", target_line)\n",
    "                            df_anl.at[sample_id, feats_anl_diff_line_dict[line]] = line_parse[0]\n",
    "                        else:\n",
    "                            line = line.replace(\" - \", \"-\")\n",
    "                            line_parse_w_units = re.findall(fr\"(.*)\\s([-+]?(?:\\d+\\.\\d+|\\d+|\\.\\d+)) (.*)\", line)\n",
    "                            line_parse_wo_units = re.findall(fr\"(.*)\\s([-+]?(?:\\d+\\.\\d+|\\d+|\\.\\d+)) \", line)\n",
    "                            if len(line_parse_w_units) > 0:\n",
    "                                if line_parse_w_units[0][0] in feats_anl_same_line_dict:\n",
    "                                    feat_unit = feats_anl_same_line.at[line_parse_w_units[0][0], 'unit']\n",
    "                                    if not pd.isna(feat_unit):\n",
    "                                        if feat_unit in line_parse_w_units[0][2] or feat_unit.replace('МЕ/', 'Ед/') in line_parse_w_units[0][2]:\n",
    "                                            df_anl.at[sample_id, feats_anl_same_line_dict[line_parse_w_units[0][0]]] = line_parse_w_units[0][1]\n",
    "                                        else:\n",
    "                                            print(f\"{line} ({fn} {p_id} {line_id})\")\n",
    "                                    else:\n",
    "                                        df_anl.at[sample_id, feats_anl_same_line_dict[line_parse_w_units[0][0]]] = line_parse_w_units[0][1]\n",
    "                            elif len(line_parse_wo_units) > 0:\n",
    "                                print(f\"Check: {line_parse_wo_units}\")\n",
    "                                df_anl.at[sample_id, feats_anl_same_line_dict[line_parse_wo_units[0][0]]] = line_parse_wo_units[0][1]\n",
    "\n",
    "df_anl = df_anl.apply(pd.to_numeric, errors='ignore')\n",
    "df_anl['Дата рождения'] = pd.to_datetime(df_anl['Дата рождения'], format=\"%d.%m.%Y\").dt.date\n",
    "df_anl['Дата обследования'] = pd.to_datetime(df_anl['Дата обследования'], format=\"%d.%m.%Y\").dt.date\n",
    "df_anl.insert(7, 'Возраст', (df_anl['Дата обследования'] - df_anl['Дата рождения']) / np.timedelta64(1, 'D') / 365.25)\n",
    "df_anl = df_anl.loc[:, ['Возраст', 'Пол'] + list(feats_anl['feature'].unique())]\n",
    "\n",
    "df_ecg = df_ecg.apply(pd.to_numeric, errors='ignore')\n",
    "df_ecg['Пол'] = df_ecg['Пол'].str.upper()\n",
    "df_ecg['Дата и время обследования'] = pd.to_datetime(df_ecg['Дата и время обследования'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df_ecg = df_ecg.loc[:, feats_ecg.index.to_list()]\n",
    "\n",
    "df_bcp = df_bcp.apply(pd.to_numeric, errors='ignore')\n",
    "df_bcp['Дата и время обследования'] = pd.to_datetime(df_bcp['Дата и время обследования'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df_bcp = df_bcp.loc[:, feats_bcp.index.to_list()]\n",
    "\n",
    "index_cmn = reduce(pd.Index.union, [x.index for x in [df_anl, df_bcp, df_ecg]]).to_list()\n",
    "feats_cmn = df_anl.columns.to_list() + df_ecg.columns.to_list() + df_bcp.columns.to_list()\n",
    "feats_cmn = list(dict.fromkeys(feats_cmn))\n",
    "\n",
    "data = pd.DataFrame(index=index_cmn, columns=feats_cmn)\n",
    "for x in [df_anl, df_bcp, df_ecg]:\n",
    "    data = data.combine_first(x)\n",
    "\n",
    "data = data.loc[:, feats_cmn]\n",
    "data.dropna(axis=1, how='all', inplace=True)\n",
    "data.to_excel(f\"{path}/data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg.columns[df_ecg.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/YandexDisk/Work/bbd/millennium/Результаты чекап/3'\n",
    "folder = ''\n",
    "file = 'cf16542c2ce505abe7da0de1f8ed430e.pdf' #'Биоимпеданс.pdf' #'cf16542c2ce505abe7da0de1f8ed430e.pdf'\n",
    "reader = PdfReader(f\"{path}/{folder}/{file}\")\n",
    "print(reader.pages[4].extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly distribution figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/YandexDisk/Work/bbd/millennium/models/small_with_fixes/Биохимические исследования/F\"\n",
    "\n",
    "feat_trgt = 'Возраст'\n",
    "\n",
    "df_all = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "sample_id = df_all.index.values[0]\n",
    "\n",
    "df_feats = pd.read_excel(f\"{path}/feats.xlsx\", index_col=0)\n",
    "feats = df_feats.index.to_list()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, shared_yaxes=False, shared_xaxes=False, column_widths=[1, 1], horizontal_spacing=0.1)\n",
    "            \n",
    "x_min = df_all['Возраст'].min()\n",
    "x_max = df_all['Возраст'].max()\n",
    "x_ptp = x_max - x_min\n",
    "\n",
    "x_int = np.linspace(round(x_min) - 1, round(x_max) + 1, round(x_max) - round(x_min) + 3)\n",
    "x_window = 5.0\n",
    "\n",
    "\n",
    "\n",
    "for feat_id in range(2):\n",
    "    \n",
    "    # Generated linear fit\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(df_all.loc[:, 'Возраст'].values, df_all.loc[:, feats[feat_id]].values)\n",
    "    reg_line = slope * np.array([x_min - 0.1 * x_ptp, x_max + 0.1 * x_ptp]) + intercept\n",
    "\n",
    "    y_min = min(df_all[feats[feat_id]].min(), df_all.at[sample_id, feats[0]])\n",
    "    y_max = max(df_all[feats[feat_id]].max(), df_all.at[sample_id, feats[0]])\n",
    "    y_ptp = y_max - y_min\n",
    "    \n",
    "    y_dist = pd.DataFrame(index=x_int, columns=['mean', 'std'])\n",
    "    for x_p in x_int:\n",
    "        ys_p = df_all.loc[(df_all[feat_trgt] > x_p - x_window) & (df_all[feat_trgt] < x_p + x_window), feats[feat_id]].values\n",
    "        y_dist.at[x_p, 'mean'] = np.mean(ys_p)\n",
    "        y_dist.at[x_p, 'std'] = np.std(ys_p)\n",
    "    \n",
    "    y_dist['low'] = y_dist['mean'] - y_dist['std']\n",
    "    y_dist['high'] = y_dist['mean'] + y_dist['std']\n",
    "    y_dist['low_f'] = savgol_filter(y_dist['low'].values, window_length=21, polyorder=3)\n",
    "    y_dist['high_f'] = savgol_filter(y_dist['high'].values, window_length=21, polyorder=3)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=y_dist['low_f'].values,\n",
    "            x=y_dist.index.values,\n",
    "            showlegend=False,\n",
    "            mode=\"lines\",\n",
    "            line=dict(\n",
    "                width=1,\n",
    "                color='#939393',\n",
    "            ),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=feat_id+1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=y_dist['high_f'].values,\n",
    "            x=y_dist.index.values,\n",
    "            showlegend=False,\n",
    "            mode=\"lines\",\n",
    "            fill=\"tonexty\",\n",
    "            line=dict(\n",
    "                width=1,\n",
    "                color='#939393',\n",
    "            ),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=feat_id+1,\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=df_all.loc[:, feats[feat_id]].values,\n",
    "            x=df_all.loc[:, 'Возраст'].values,\n",
    "            showlegend=False,\n",
    "            name='Распределение',\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=7,\n",
    "                opacity=0.75,\n",
    "                line=dict(\n",
    "                    width=1,\n",
    "                    color='black',\n",
    "                ),\n",
    "                color='#D5D5D5'\n",
    "            )\n",
    "        ),\n",
    "        row=1,\n",
    "        col=feat_id+1,\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=[df_all.at[sample_id, feats[feat_id]]],\n",
    "            x=[df_all.at[sample_id, 'Возраст']],\n",
    "            showlegend=False,\n",
    "            name=sample_id,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=20,\n",
    "                opacity=1.0,\n",
    "                line=dict(\n",
    "                    width=1,\n",
    "                    color='#676664',\n",
    "                ),\n",
    "                color='crimson'\n",
    "            )\n",
    "        ),\n",
    "        row=1,\n",
    "        col=feat_id+1,\n",
    "    )\n",
    "    # fig.add_trace(\n",
    "    #     go.Scatter(\n",
    "    #         y=reg_line,\n",
    "    #         x=[x_min - 0.1 * x_ptp, x_max + 0.1 * x_ptp],\n",
    "    #         showlegend=False,\n",
    "    #         name='Regression',\n",
    "    #         mode=\"lines\",\n",
    "    #         line=dict(\n",
    "    #             width=3,\n",
    "    #             color='676664',\n",
    "    #         ),\n",
    "    #     ),\n",
    "    #     row=1,\n",
    "    #     col=feat_id+1,\n",
    "    # )\n",
    "    fig.update_xaxes(\n",
    "        row=1,\n",
    "        col=feat_id+1,\n",
    "        automargin=True,\n",
    "        title_text=\"Возраст\",\n",
    "        autorange=False,\n",
    "        range=[x_min - 0.1 * x_ptp, x_max + 0.1 * x_ptp],\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        linecolor='black',\n",
    "        showline=True,\n",
    "        gridcolor='gainsboro',\n",
    "        gridwidth=0.05,\n",
    "        mirror=True,\n",
    "        ticks='outside',\n",
    "        titlefont=dict(\n",
    "            color='black',\n",
    "            size=20\n",
    "        ),\n",
    "        showticklabels=True,\n",
    "        tickangle=0,\n",
    "        tickfont=dict(\n",
    "            color='black',\n",
    "            size=16\n",
    "        ),\n",
    "        exponentformat='e',\n",
    "        showexponent='all'\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        row=1,\n",
    "        col=feat_id+1,\n",
    "        automargin=True,\n",
    "        title_text=feats[feat_id],\n",
    "        autorange=False,\n",
    "        range=[y_min - 0.1 * y_ptp, y_max + 0.1 * y_ptp],\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        linecolor='black',\n",
    "        showline=True,\n",
    "        gridcolor='gainsboro',\n",
    "        gridwidth=0.05,\n",
    "        mirror=True,\n",
    "        ticks='outside',\n",
    "        titlefont=dict(\n",
    "            color='black',\n",
    "            size=20\n",
    "        ),\n",
    "        showticklabels=True,\n",
    "        tickangle=0,\n",
    "        tickfont=dict(\n",
    "            color='black',\n",
    "            size=16\n",
    "        ),\n",
    "        exponentformat='e',\n",
    "        showexponent='all'\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=f\"{components[comp]['name']}\",\n",
    "    # titlefont=dict(size=25),\n",
    "    template=\"none\",\n",
    "    width=1500,\n",
    "    height=700,\n",
    "    margin=go.layout.Margin(l=20, r=20, b=20, t=10),\n",
    "    font=dict(family='Montserrat'),\n",
    ")\n",
    "    \n",
    "\n",
    "fig.write_image(f\"{path}/ololo.png\", scale=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
