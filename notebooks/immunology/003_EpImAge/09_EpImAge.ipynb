{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import BaseCrossValidator, ParameterGrid, ParameterSampler\n",
    "import torch\n",
    "import pickle\n",
    "import shutil\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "import sklearn.metrics\n",
    "from scipy import stats\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "from src.utils.hash import dict_hash\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import optuna\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.cm\n",
    "import matplotlib as mpl\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import shap\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]\n",
    "\n",
    "def form_bar(base):\n",
    "    def formatter(x):\n",
    "        return f'{str(int(round(x * base)))}/{base}'\n",
    "    return formatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:45.850727Z",
     "start_time": "2024-07-01T14:29:22.801727Z"
    }
   },
   "outputs": [],
   "source": [
    "epi_data_type = 'no_harm'\n",
    "imm_data_type = 'imp_source(imm)_method(knn)_params(5)' # 'origin' 'imp_source(imm)_method(knn)_params(5)' 'imp_source(imm)_method(miceforest)_params(2)'\n",
    "\n",
    "selection_method = 'mrmr' # 'f_regression' 'mrmr'\n",
    "n_feats = 100\n",
    "\n",
    "tst_n_splits = 5\n",
    "tst_n_repeats = 5\n",
    "tst_random_state = 1337\n",
    "tst_split_id = 20\n",
    "\n",
    "val_n_splits = 4\n",
    "val_n_repeats = 4\n",
    "val_random_state = 1337\n",
    "val_fold_id = 5\n",
    "\n",
    "path = f\"E:/YandexDisk/Work/bbd/immunology/003_EpImAge/{imm_data_type}/{epi_data_type}/{selection_method}_{n_feats}/EpImAge\"\n",
    "path_epi = f\"E:/YandexDisk/Work/bbd/immunology/003_EpImAge/epi\"\n",
    "path_configs = \"E:/Git/bbs/notebooks/immunology/003_EpImAge/age_regression_configs\"\n",
    "\n",
    "data_full = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "\n",
    "# Filtering data\n",
    "status_count = data_full['Status'].value_counts()\n",
    "statuses_passed = status_count[status_count >= 10].index.values.tolist()\n",
    "data_full = data_full[data_full['Status'].isin(statuses_passed)]\n",
    "data_full.drop(data_full.index[data_full['Status'] == 'ICU'], inplace=True)\n",
    "# data_full.to_excel(f\"{path}/data_filtered.xlsx\", index_label='ID')\n",
    "\n",
    "status_count = data_full['Status'].value_counts()\n",
    "\n",
    "feats = pd.read_excel(f\"{path}/feats.xlsx\", index_col=0).index.values.tolist()\n",
    "feats = [f\"{f}_log\" for f in feats]\n",
    "\n",
    "gse_preproc = pd.read_excel(f\"{path_epi}/preproc.xlsx\", index_col=0)\n",
    "\n",
    "df_groups = pd.read_excel(f\"{path_epi}/groups.xlsx\", index_col=0)\n",
    "icd_chpts = np.sort(df_groups['ICD-11 chapter'].unique())\n",
    "icd_codes = np.sort(df_groups['ICD-11 code'].unique())\n",
    "colors = distinctipy.get_colors(len(icd_chpts), [mcolors.hex2color(mcolors.CSS4_COLORS['black']), mcolors.hex2color(mcolors.CSS4_COLORS['white'])], rng=1337, pastel_factor=0.5)\n",
    "colors_icd_chpts = {icd_chpt: colors[icd_chpt_id] for icd_chpt_id, icd_chpt in enumerate(icd_chpts)}\n",
    "colormaps_icd_chpts = {\n",
    "    icd_chpt: LinearSegmentedColormap.from_list(\n",
    "        name=f\"ICD-11 Chapter {icd_chpt} cmap\",\n",
    "        colors=[make_rgb_transparent(colors_icd_chpts[icd_chpt], (1, 1, 1), 0.2), colors_icd_chpts[icd_chpt]], N=256\n",
    "    )\n",
    "    for icd_chpt in icd_chpts\n",
    "}\n",
    "colormap_total = LinearSegmentedColormap.from_list(\n",
    "    name=f\"ICD-11 Total cmap\",\n",
    "    colors=[\n",
    "        mcolors.hex2color(mcolors.CSS4_COLORS['lavender']),\n",
    "        mcolors.hex2color(mcolors.CSS4_COLORS['dimgray'])],\n",
    "    N=256,\n",
    ")\n",
    "\n",
    "clocks_tests = pd.read_excel(f\"{path_epi}/clocks_tests.xlsx\", index_col=\"Clock Name\")\n",
    "clocks_tests['Year'] = clocks_tests['Year'].astype(str)\n",
    "clocks_tests.drop(index=['Knight', 'LeeControl', 'LeeRefinedRobust', 'LeeRobust', 'PedBE', 'RepliTali', 'ENCen100'], inplace=True)\n",
    "clocks_tests_raw = pd.read_excel(f\"{path_epi}/clocks_tests_raw_after_correction.xlsx\", index_col=\"Clock Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:46.387990Z",
     "start_time": "2024-07-01T14:29:45.850727Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"{path}/samples_tst({tst_random_state}_{tst_n_splits}_{tst_n_repeats})_val({val_random_state}_{val_n_splits}_{val_n_repeats}).pickle\", 'rb') as handle:\n",
    "    samples = pickle.load(handle)\n",
    "    \n",
    "for split_id in range(tst_n_splits * tst_n_repeats):\n",
    "    for fold_id in range(val_n_splits * val_n_repeats):\n",
    "        test_samples = samples[split_id]['test']\n",
    "        train_samples = samples[split_id]['trains'][fold_id]\n",
    "        validation_samples = samples[split_id]['validations'][fold_id]\n",
    "\n",
    "        intxns = {\n",
    "            'train_validation': set.intersection(set(train_samples), set(validation_samples)),\n",
    "            'validation_test': set.intersection(set(validation_samples), set(test_samples)),\n",
    "            'train_test': set.intersection(set(train_samples), set(test_samples))\n",
    "        }\n",
    "        \n",
    "        for intxn_name, intxn_samples in intxns.items():\n",
    "            if len(intxn_samples) > 0:\n",
    "                print(f\"Non-zero {intxn_name} intersection ({len(intxn_samples)}) for {split_id} Split and {fold_id} Fold!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = samples[tst_split_id]\n",
    "\n",
    "test = data_full.loc[split_dict['test'], feats + [\"Age\"]]\n",
    "train = data_full.loc[split_dict['trains'][val_fold_id], feats + [\"Age\"]]\n",
    "validation = data_full.loc[split_dict['validations'][val_fold_id], feats + [\"Age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_target = 1337  # 1337 42 451 1984 1899 1408\n",
    "\n",
    "models_runs = {\n",
    "    'GANDALF': {\n",
    "        'config': GANDALFConfig,\n",
    "        'n_trials': 1024,\n",
    "        'seed': seed_target,\n",
    "        'n_startup_trials': 256,\n",
    "        'n_ei_candidates': 16\n",
    "    },\n",
    "    # 'FTTransformer': {\n",
    "    #     'config': FTTransformerConfig,\n",
    "    #     'n_trials': 512,\n",
    "    #     'seed': 1337,\n",
    "    #     'n_startup_trials': 256,\n",
    "    #     'n_ei_candidates': 16\n",
    "    # },\n",
    "    # 'DANet': {\n",
    "    #     'config': DANetConfig,\n",
    "    #     'n_trials': 256,\n",
    "    #     'seed': 1337,\n",
    "    #     'n_startup_trials': 64,\n",
    "    #     'n_ei_candidates': 16\n",
    "    # },\n",
    "    # 'CategoryEmbeddingModel': {\n",
    "    #     'config': CategoryEmbeddingModelConfig,\n",
    "    #     'n_trials': 256,\n",
    "    #     'seed': 1337,\n",
    "    #     'n_startup_trials': 64,\n",
    "    #     'n_ei_candidates': 16\n",
    "    # },\n",
    "    # 'TabNetModel': {\n",
    "    #     'config': TabNetModelConfig,\n",
    "    #     'n_trials': 256,\n",
    "    #     'seed': 1337,\n",
    "    #     'n_startup_trials': 64,\n",
    "    #     'n_ei_candidates': 16\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_models = []\n",
    "\n",
    "for model_name, model_run in models_runs.items():\n",
    "\n",
    "    model_config_name = model_run['config']\n",
    "    n_trials = model_run['n_trials']\n",
    "    seed = model_run['seed']\n",
    "    n_startup_trials = model_run['n_startup_trials']\n",
    "    n_ei_candidates = model_run['n_ei_candidates']\n",
    "\n",
    "    data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "    data_config['target'] = ['Age']\n",
    "    data_config['continuous_cols'] = feats\n",
    "    trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "    trainer_config['checkpoints_path'] = f\"{path}/pytorch_tabular\"\n",
    "    optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "\n",
    "    lr_find_min_lr = 1e-8\n",
    "    lr_find_max_lr = 10\n",
    "    lr_find_num_training = 256\n",
    "    lr_find_mode = \"exponential\"\n",
    "    lr_find_early_stop_threshold = 8.0\n",
    "\n",
    "    trainer_config['seed'] = seed\n",
    "    trainer_config['checkpoints'] = 'valid_loss'\n",
    "    trainer_config['load_best'] = True\n",
    "    trainer_config['auto_lr_find'] = False\n",
    "\n",
    "    model_config_default = read_parse_config(f\"{path_configs}/models/{model_name}Config.yaml\", model_config_name)\n",
    "    tabular_model_default = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config_default,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        verbose=False,\n",
    "    )\n",
    "    datamodule = tabular_model_default.prepare_dataloader(train=train, validation=validation, seed=seed)\n",
    "\n",
    "    opt_parts = ['test', 'validation']\n",
    "    opt_metrics = [('mean_absolute_error', 'minimize')]\n",
    "    # opt_metrics = [('mean_absolute_error', 'minimize'), ('pearson_corrcoef', 'maximize')]\n",
    "    # opt_metrics = [('pearson_corrcoef', 'maximize')]\n",
    "    opt_directions = []\n",
    "    for part in opt_parts:\n",
    "        for metric_pair in opt_metrics:\n",
    "            opt_directions.append(f\"{metric_pair[1]}\")\n",
    "\n",
    "    trials_results = []\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=model_name,\n",
    "        sampler=optuna.samplers.TPESampler(\n",
    "            n_startup_trials=n_startup_trials,\n",
    "            n_ei_candidates=n_ei_candidates,\n",
    "            seed=seed,\n",
    "        ),\n",
    "        directions=opt_directions\n",
    "    )\n",
    "    study.optimize(\n",
    "        func=lambda trial: train_hyper_opt(\n",
    "            trial=trial,\n",
    "            trials_results=trials_results,\n",
    "            opt_metrics=opt_metrics,\n",
    "            opt_parts=opt_parts,\n",
    "            model_config_default=model_config_default,\n",
    "            data_config_default=data_config,\n",
    "            optimizer_config_default=optimizer_config,\n",
    "            trainer_config_default=trainer_config,\n",
    "            experiment_config_default=None,\n",
    "            train=train,\n",
    "            validation=validation,\n",
    "            test=test,\n",
    "            datamodule=datamodule,\n",
    "            min_lr=lr_find_min_lr,\n",
    "            max_lr=lr_find_max_lr,\n",
    "            num_training=lr_find_num_training,\n",
    "            mode=lr_find_mode,\n",
    "            early_stop_threshold=lr_find_early_stop_threshold\n",
    "        ),\n",
    "        n_trials=n_trials,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    fn_trials = (\n",
    "        f\"model({model_name})_\"\n",
    "        f\"trials({n_trials}_{seed}_{n_startup_trials}_{n_ei_candidates})_\"\n",
    "        f\"tst({tst_split_id})_\"\n",
    "        f\"val({val_fold_id})\"\n",
    "    )\n",
    "\n",
    "    df_trials = pd.DataFrame(trials_results)\n",
    "    df_trials['split_id'] = tst_split_id\n",
    "    df_trials['fold_id'] = val_fold_id\n",
    "    df_trials[\"train_more\"] = False\n",
    "    df_trials.loc[(df_trials[\"train_loss\"] > df_trials[\"test_loss\"]) | (\n",
    "            df_trials[\"train_loss\"] > df_trials[\"validation_loss\"]), \"train_more\"] = True\n",
    "    df_trials[\"validation_test_mean_loss\"] = (df_trials[\"validation_loss\"] + df_trials[\"test_loss\"]) / 2.0\n",
    "    df_trials[\"train_validation_test_mean_loss\"] = (df_trials[\"train_loss\"] + df_trials[\"validation_loss\"] + df_trials[\"test_loss\"]) / 3.0\n",
    "    df_trials.style.background_gradient(\n",
    "        subset=[\n",
    "            \"train_loss\",\n",
    "            \"validation_loss\",\n",
    "            \"validation_test_mean_loss\",\n",
    "            \"train_validation_test_mean_loss\",\n",
    "            \"test_loss\",\n",
    "            \"time_taken\",\n",
    "            \"time_taken_per_epoch\"\n",
    "        ], cmap=\"RdYlGn_r\"\n",
    "    ).to_excel(f\"{trainer_config['checkpoints_path']}/{fn_trials}.xlsx\")\n",
    "\n",
    "    dfs_models.append(df_trials)\n",
    "\n",
    "df_models = pd.concat(dfs_models, ignore_index=True)\n",
    "df_models.insert(0, 'Selected', 0)\n",
    "fn = (\n",
    "    f\"models_\"\n",
    "    f\"tst({tst_split_id})_\"\n",
    "    f\"val({val_fold_id})\"\n",
    ")\n",
    "df_models.style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"validation_test_mean_loss\",\n",
    "        \"train_validation_test_mean_loss\",\n",
    "        \"test_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{path}/pytorch_tabular/{fn}.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform tests on models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "path_sweep = f\"{path}/pytorch_tabular\"\n",
    "\n",
    "fn_sweep = (\n",
    "    f\"models_\"\n",
    "    f\"tst({tst_split_id})_\"\n",
    "    f\"val({val_fold_id})\"\n",
    ")\n",
    "\n",
    "df_sweeps = pd.read_excel(f\"{path_sweep}/{fn_sweep}.xlsx\", index_col=0)\n",
    "\n",
    "df_sweeps.insert(15, 'Passed\\nICD-11\\nTotal', None)\n",
    "ins_pos = 16\n",
    "for icd_chpt in icd_chpts:\n",
    "    df_sweeps.insert(ins_pos, f'Passed\\nICD-11\\nChapter {icd_chpt}', None)\n",
    "    ins_pos += 1\n",
    "\n",
    "models_tests_raw = pd.DataFrame(index=df_sweeps.index)\n",
    "for model_id, model_row in (pbar := tqdm(df_sweeps.iterrows())):\n",
    "    pbar.set_description(f\"Processing {model_id}\")\n",
    "\n",
    "    model_dir = str(pathlib.Path(df_sweeps.at[model_id, 'checkpoint']).parent).replace('\\\\', '/') + '/' + pathlib.Path(df_sweeps.at[model_id, 'checkpoint']).stem\n",
    "    \n",
    "    model = TabularModel.load_model(model_dir)\n",
    "\n",
    "    data_full['Prediction'] = model.predict(data_full)\n",
    "    data_full['Error'] = data_full['Prediction'] - data_full['Age']\n",
    "    \n",
    "    for section_id, section_row in df_groups.iterrows():\n",
    "        section_statuses = ast.literal_eval(section_row['Statuses'])\n",
    "        section_groups = ast.literal_eval(section_row['Groups'])\n",
    "        section_directions = ast.literal_eval(section_row['Directions'])\n",
    "        df_section = data_full.loc[(data_full['GSE'] == section_row['GSE']) & (data_full['Status'].isin(section_statuses)), ['Status', 'Error']]\n",
    "        \n",
    "        for section_group_id, section_group in enumerate(section_groups):\n",
    "            \n",
    "            _, pval = mannwhitneyu(\n",
    "                df_section.loc[df_section[\"Status\"] == section_group[0], \"Error\"].values,\n",
    "                df_section.loc[df_section[\"Status\"] == section_group[1], \"Error\"].values,\n",
    "                alternative=\"two-sided\",\n",
    "            )\n",
    "            bias_0 = np.mean(df_section.loc[df_section['Status'] == section_group[0], 'Error'])\n",
    "            bias_1 = np.mean(df_section.loc[df_section['Status'] == section_group[1], 'Error'])\n",
    "            \n",
    "            models_tests_raw.at[model_id, f\"pval\\n{section_id}\\n{section_group}\"] = pval\n",
    "            models_tests_raw.at[model_id, f\"bias_0\\n{section_id}\\n{section_group}\"] = bias_0\n",
    "            models_tests_raw.at[model_id, f\"bias_1\\n{section_id}\\n{section_group}\"] = bias_1\n",
    "models_tests_raw.to_excel(f\"{path_sweep}/models_tests_raw_before_correction.xlsx\", index_label='Model ID')\n",
    "\n",
    "# Here we can modify test results (p-values)\n",
    "pvals_cols = [col for col in models_tests_raw.columns if 'pval' in col]\n",
    "for model_id, model_row in (pbar := tqdm(df_sweeps.iterrows())):\n",
    "    _, models_tests_raw.loc[model_id, pvals_cols], _, _ = multipletests(models_tests_raw.loc[model_id, pvals_cols], 0.05, method='fdr_bh')\n",
    "models_tests_raw.to_excel(f\"{path_sweep}/models_tests_raw_after_correction.xlsx\", index_label='Model ID')\n",
    "    \n",
    "for model_id, model_row in (pbar := tqdm(df_sweeps.iterrows())):\n",
    "    pbar.set_description(f\"Processing {model_id}\")\n",
    "    passed_icd = {icd_chpt: 0 for icd_chpt in icd_chpts}\n",
    "    for icd_chpt in icd_chpts:\n",
    "        df_ckpt = df_groups[df_groups['ICD-11 chapter'] == icd_chpt]\n",
    "        for section_id, section_row in df_ckpt.iterrows():\n",
    "            section_statuses = ast.literal_eval(section_row['Statuses'])\n",
    "            section_groups = ast.literal_eval(section_row['Groups'])\n",
    "            section_directions = ast.literal_eval(section_row['Directions'])\n",
    "            \n",
    "            for section_group_id, section_group in enumerate(section_groups):\n",
    "                \n",
    "                pval = models_tests_raw.at[model_id, f\"pval\\n{section_id}\\n{section_group}\"]\n",
    "                bias_0 = models_tests_raw.at[model_id, f\"bias_0\\n{section_id}\\n{section_group}\"]\n",
    "                bias_1 = models_tests_raw.at[model_id, f\"bias_1\\n{section_id}\\n{section_group}\"]\n",
    "                \n",
    "                group_direction = section_directions[section_group_id]\n",
    "                \n",
    "                if pval < 0.05:\n",
    "                    if group_direction == 'Increasing' and bias_1 > bias_0:\n",
    "                        passed_icd[icd_chpt] += 1\n",
    "                    elif group_direction == 'Decreasing' and bias_1 < bias_0:\n",
    "                        passed_icd[icd_chpt] += 1\n",
    "        \n",
    "        df_sweeps.at[model_id, f'Passed\\nICD-11\\nChapter {icd_chpt}'] = passed_icd[icd_chpt]              \n",
    "        \n",
    "    df_sweeps.at[model_id, f'Passed\\nICD-11\\nTotal'] = sum(passed_icd.values())\n",
    "    \n",
    "df_sweeps.to_excel(f\"{path_sweep}/models.xlsx\", index_label='Model ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best models processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gse_controls_count = data_full.loc[data_full['Status'] == 'Control', 'GSE'].value_counts()\n",
    "gses_controls = gse_controls_count.index.values\n",
    "gse_controls_ids = {gse: data_full.index[(data_full['Status'] == 'Control') & (data_full['GSE'] == gse)].values for gse in gses_controls}\n",
    "colors = distinctipy.get_colors(len(gses_controls), [mcolors.hex2color(mcolors.CSS4_COLORS['white']), mcolors.hex2color(mcolors.CSS4_COLORS['black'])], rng=1337)\n",
    "colors_gse = {gses_controls[gse_id]: colors[gse_id] for gse_id in range(len(gses_controls))}\n",
    "\n",
    "statuses_rename = {x: x.replace(' ', '\\n').replace('-', '\\n') for x in data_full['Status'].value_counts().index.values}\n",
    "data_full['Status Origin'] = data_full['Status']\n",
    "data_full['Status'] = data_full['Status'].replace(statuses_rename) \n",
    "status_count = data_full['Status'].value_counts()\n",
    "statuses = status_count.index.values\n",
    "colors = distinctipy.get_colors(len(statuses) - 1, [mcolors.hex2color(mcolors.CSS4_COLORS['dodgerblue']), mcolors.hex2color(mcolors.CSS4_COLORS['white']), mcolors.hex2color(mcolors.CSS4_COLORS['black'])], rng=1337)\n",
    "colors_status = {'Control': mcolors.hex2color(mcolors.CSS4_COLORS['dodgerblue'])}\n",
    "for status_id, status in enumerate(statuses):\n",
    "    if status != 'Control':\n",
    "        colors_status[status] = colors[status_id - 1]\n",
    "\n",
    "mosaic_violins = []\n",
    "mosaic_rows = np.sort(df_groups['Row on violin plot'].unique())\n",
    "for mosaic_row in mosaic_rows:\n",
    "    df_mosaic_row = df_groups[df_groups['Row on violin plot'] == mosaic_row].sort_values(by=['ICD-11 chapter', 'ICD-11 code', 'GSE'], ascending=[True, True, True])\n",
    "    mosaic_row_labels = []\n",
    "    for plot_id, plot_row in df_mosaic_row.iterrows():\n",
    "        n_violins = len(ast.literal_eval(plot_row['Statuses']))\n",
    "        mosaic_row_labels += [plot_id]*n_violins\n",
    "    mosaic_violins.append(mosaic_row_labels)\n",
    "\n",
    "max_mosaic_row = max([len(x) for x in mosaic_violins])\n",
    "violons_empty_panels = set()\n",
    "for row_id, row in enumerate(mosaic_violins):\n",
    "    for added_spaces in range(len(row), max_mosaic_row):\n",
    "        violons_empty_panels.add(f'Empty row {row_id}')\n",
    "        mosaic_violins[row_id].append(f'Empty row {row_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_cols = []\n",
    "icd_code_chpt = {}\n",
    "icd_codes_for_chpts = {}\n",
    "for icd_chpt in icd_chpts:\n",
    "    icd_cols.append(f'Passed\\nICD-11\\nChapter {icd_chpt}')\n",
    "    icd_codes_for_chpts[icd_chpt] = np.sort(df_groups.loc[df_groups['ICD-11 chapter'] == icd_chpt, 'ICD-11 code'].unique())\n",
    "    for icd_code in [f\"Passed\\nICD-11\\nCode {x}\" for x in icd_codes_for_chpts[icd_chpt]]:\n",
    "        icd_code_chpt[icd_code] = f'Passed\\nICD-11\\nChapter {icd_chpt}'\n",
    "    icd_cols += [f\"Passed\\nICD-11\\nCode {x}\" for x in icd_codes_for_chpts[icd_chpt]]\n",
    "icd_cols_max = [f\"Max\\n{x}\" for x in icd_cols]\n",
    "\n",
    "col_names_common = [\"Year\", \"Total Rho\", \"Total MAE\", f\"Passed\\nICD-11\\nTotal\"]\n",
    "col_defs_common = [\n",
    "    ColumnDefinition(\n",
    "        name=\"Clock Name\",\n",
    "        title=\"Clocks\",\n",
    "        textprops={\"ha\": \"right\", \"weight\": \"bold\"},\n",
    "        width=2.25,\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=\"Year\",\n",
    "        title=\"Year\",\n",
    "        textprops={\"ha\": \"center\"},\n",
    "        width=1.0,\n",
    "        border=\"left\"\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=\"Total Rho\",\n",
    "        title=\"Total\\n\" + r\"Pearson $\\rho$\",\n",
    "        textprops={\"ha\": \"center\"},\n",
    "        formatter=\"{:.3f}\",\n",
    "        cmap=normed_cmap(clocks_tests[\"Total Rho\"].dropna(), cmap=matplotlib.cm.Greens, num_stds=2.5),\n",
    "        width=1.0,\n",
    "        border=\"left\"\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=\"Total MAE\",\n",
    "        title=\"Total\\nMAE\",\n",
    "        textprops={\"ha\": \"center\"},\n",
    "        formatter=\"{:.3f}\",\n",
    "        cmap=normed_cmap(clocks_tests[\"Total MAE\"].dropna(), cmap=matplotlib.cm.Reds, num_stds=2.5),\n",
    "        width=1.0,\n",
    "    ),\n",
    "    ColumnDefinition(\n",
    "        name=f\"Passed\\nICD-11\\nTotal\",\n",
    "        title=\"Passed\\nICD-11\",\n",
    "        width=1.5,\n",
    "        border=\"left\",\n",
    "        textprops={\"ha\": \"center\"},\n",
    "        plot_fn=bar,\n",
    "        plot_kw={\n",
    "            \"cmap\": colormap_total,\n",
    "            \"plot_bg_bar\": True,\n",
    "            \"annotate\": True,\n",
    "            \"height\": 0.95,\n",
    "            \"linewidth\": 0.5,\n",
    "            \"formatter\": form_bar(clocks_tests.at['Hannum', f'Max\\nPassed\\nICD-11\\nTotal']),\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "icd_chpt_col_defs = copy.deepcopy(col_defs_common)\n",
    "icd_chpt_col_names = copy.deepcopy(col_names_common)\n",
    "for icd_chpt in icd_chpts:\n",
    "    if icd_chpt == 1:\n",
    "        border = 'left'\n",
    "    else:\n",
    "        border = None\n",
    "    max_passed = clocks_tests.at['Hannum', f'Max\\nPassed\\nICD-11\\nChapter {icd_chpt}']\n",
    "    icd_chpt_col_names.append(f'Passed\\nICD-11\\nChapter {icd_chpt}')\n",
    "    col_def = ColumnDefinition(\n",
    "        name=f'Passed\\nICD-11\\nChapter {icd_chpt}',\n",
    "        title=f'Chapter {icd_chpt}',\n",
    "        width=1.0,\n",
    "        plot_fn=bar,\n",
    "        border=border,\n",
    "        textprops={\"ha\": \"center\"},\n",
    "        plot_kw={\n",
    "            \"cmap\": colormaps_icd_chpts[icd_chpt],\n",
    "            \"plot_bg_bar\": True,\n",
    "            \"annotate\": True,\n",
    "            \"height\": 0.95,\n",
    "            \"lw\": 0.5,\n",
    "            \"formatter\": form_bar(max_passed),\n",
    "        },\n",
    "    )\n",
    "    icd_chpt_col_defs.append(col_def)\n",
    "    \n",
    "icd_code_col_defs = copy.deepcopy(col_defs_common)\n",
    "icd_code_col_names = copy.deepcopy(col_names_common)\n",
    "for icd_chpt in icd_chpts:\n",
    "    if icd_chpt in [11, 12]:\n",
    "        group=fr\"$\\mathbf{{{icd_chpt}}}$\"\n",
    "    else:\n",
    "        group=fr\"$\\mathbf{{Chapter\\,{icd_chpt}}}$\"\n",
    "        \n",
    "    for code_in_chpt in icd_codes_for_chpts[icd_chpt]:\n",
    "        max_passed = clocks_tests.at['Hannum', f'Max\\nPassed\\nICD-11\\nCode {code_in_chpt}']\n",
    "        icd_code_col_names.append(f'Passed\\nICD-11\\nCode {code_in_chpt}')\n",
    "        col_def = ColumnDefinition(\n",
    "            name=f'Passed\\nICD-11\\nCode {code_in_chpt}',\n",
    "            title=f'{code_in_chpt}',\n",
    "            width=1.0,\n",
    "            plot_fn=bar,\n",
    "            border=None,\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            plot_kw={\n",
    "                \"cmap\": colormaps_icd_chpts[icd_chpt],\n",
    "                \"plot_bg_bar\": True,\n",
    "                \"annotate\": True,\n",
    "                \"height\": 0.95,\n",
    "                \"lw\": 0.5,\n",
    "                \"formatter\": form_bar(max_passed),\n",
    "            },\n",
    "            group=group,\n",
    "        )\n",
    "        icd_code_col_defs.append(col_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_method = \"GradientShap\"\n",
    "explain_baselines = \"b|100000\"\n",
    "\n",
    "models_type = 'DANet' # 'FTTransformer' 'GANDALF' 'DANet'\n",
    "models_ids = [\n",
    "    # 39,\n",
    "    # 43,\n",
    "    # 25,\n",
    "    # 0,\n",
    "    \n",
    "    #231,\n",
    "    194,\n",
    "    #22,\n",
    "]\n",
    "models_ids = sorted(list(set(models_ids)))\n",
    "\n",
    "df_sweeps = pd.read_excel(f\"{path}/pytorch_tabular/{models_type}/models.xlsx\", index_col=0)\n",
    "path_models = f\"{path}/pytorch_tabular/{models_type}/candidates\"\n",
    "pathlib.Path(path_models).mkdir(parents=True, exist_ok=True)\n",
    "df_sweeps.loc[models_ids, :].style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"test_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{path_models}/selected.xlsx\")\n",
    "\n",
    "df_models_metrics = pd.DataFrame(index=models_ids)\n",
    "df_models_check = pd.DataFrame(index=models_ids)\n",
    "df_gses_models_metrics = {}\n",
    "for md in [f\"{x[0]} {x[1]}\" for x in itertools.product(['MAE', 'Rho', 'Bias'], ['Train', 'Validation', 'Test', 'Total'])]:\n",
    "    df_gses_models_metrics[md] = pd.DataFrame(index=gses_controls, columns=['Count'] + list(models_ids))\n",
    "    df_gses_models_metrics[md].loc[gses_controls, 'Count'] = gse_controls_count[gses_controls]\n",
    "\n",
    "for model_id in models_ids:\n",
    "    print(model_id)\n",
    "\n",
    "    split_id = df_sweeps.at[model_id, 'split_id']\n",
    "    fold_id = df_sweeps.at[model_id, 'fold_id']\n",
    "    split_dict = samples[split_id]\n",
    "    ids_test = split_dict['test']\n",
    "    ids_train = split_dict['trains'][fold_id]\n",
    "    ids_validation = split_dict['validations'][fold_id]\n",
    "    ids_total = np.concatenate([ids_train, ids_validation, ids_test])\n",
    "    ids_dict = {\n",
    "        'Test': ids_test,\n",
    "        'Train': ids_train,\n",
    "        'Validation': ids_validation,\n",
    "        'Total': ids_total\n",
    "    }\n",
    "\n",
    "    model_dir = str(pathlib.Path(df_sweeps.at[model_id, 'checkpoint']).parent).replace('D:\\\\', 'E:\\\\').replace('\\\\', '/') + f'/{models_type}/' + pathlib.Path(df_sweeps.at[model_id, 'checkpoint']).stem\n",
    "    model = TabularModel.load_model(model_dir)\n",
    "    pathlib.Path(f\"{path_models}/{model_id}\").mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copytree(model_dir, f\"{path_models}/{model_id}\", dirs_exist_ok=True)\n",
    "    \n",
    "    def predict_func(X):\n",
    "        X_df = pd.DataFrame(data=X, columns=feats)\n",
    "        y = model.predict(X_df)['Age_prediction'].values\n",
    "        return y\n",
    "\n",
    "    data_full['Group'] = ''\n",
    "    data_full.loc[ids_train, 'Group'] = 'Train'\n",
    "    data_full.loc[ids_validation, 'Group'] = 'Validation'\n",
    "    data_full.loc[ids_test, 'Group'] = 'Test'\n",
    "    data_full['Prediction'] = model.predict(data_full)\n",
    "    data_full['Error'] = data_full['Prediction'] - data_full['Age']\n",
    "    data_full[['GPL', 'GSE', 'Age', 'Sex', 'Status', 'Group', 'Prediction', 'Error']].to_excel(f\"{path_models}/{model_id}/data.xlsx\")\n",
    "\n",
    "    df_metrics = pd.DataFrame(\n",
    "        index=list(ids_dict.keys()),\n",
    "        columns=['MAE', 'Rho', 'Bias']\n",
    "    )\n",
    "\n",
    "    for part, ids_part in ids_dict.items():\n",
    "\n",
    "        pred = torch.from_numpy(data_full.loc[ids_part, 'Prediction'].values)\n",
    "        real = torch.from_numpy(data_full.loc[ids_part, 'Age'].values)\n",
    "\n",
    "        df_metrics.at[part, 'MAE'] = mean_absolute_error(pred, real).numpy()\n",
    "        df_metrics.at[part, 'Rho'] = pearson_corrcoef(pred, real).numpy()\n",
    "        df_metrics.at[part, 'Bias'] = np.mean(data_full.loc[ids_part, 'Error'].values)\n",
    "\n",
    "        df_models_metrics.at[model_id, f'MAE\\n{part}'] = df_metrics.at[part, 'MAE']\n",
    "        df_models_metrics.at[model_id, f'Rho\\n{part}'] = df_metrics.at[part, 'Rho']\n",
    "        df_models_metrics.at[model_id, f'Bias\\n{part}'] = df_metrics.at[part, 'Bias']\n",
    "\n",
    "        if part != 'Total':\n",
    "            df_models_check.at[model_id, f'{part} MAE Before'] = df_sweeps.at[model_id, f'{part.lower()}_mean_absolute_error']\n",
    "            df_models_check.at[model_id, f'{part} Rho Before'] = df_sweeps.at[model_id, f'{part.lower()}_pearson_corrcoef']\n",
    "            df_models_check.at[model_id, f'{part} MAE After'] = df_metrics.at[part, 'MAE']\n",
    "            df_models_check.at[model_id, f'{part} Rho After'] = df_metrics.at[part, 'Rho']\n",
    "\n",
    "    df_metrics.to_excel(f\"{path_models}/{model_id}/metrics.xlsx\", index_label=\"Metrics\")\n",
    "\n",
    "    for gse, ids_gse in gse_controls_ids.items():\n",
    "        for part, ids_part in ids_dict.items():\n",
    "            ids_intxn = list(set.intersection(set(ids_gse), set(ids_part)))\n",
    "            if len(ids_intxn) > 0:\n",
    "                pred = torch.from_numpy(data_full.loc[ids_intxn, 'Prediction'].values)\n",
    "                real = torch.from_numpy(data_full.loc[ids_intxn, 'Age'].values)\n",
    "                df_gses_models_metrics[f'MAE {part}'].at[gse, model_id] = mean_absolute_error(pred, real).numpy()\n",
    "                df_gses_models_metrics[f'Rho {part}'].at[gse, model_id] = pearson_corrcoef(pred, real).numpy()\n",
    "                df_gses_models_metrics[f'Bias {part}'].at[gse, model_id] = np.mean(data_full.loc[ids_intxn, 'Error'].values)\n",
    "                \n",
    "    # # SHAP age acceleration table\n",
    "\n",
    "    # df_imm_shap_raw = pd.DataFrame(index=feats)\n",
    "    # for section_id, section_row in df_groups.iterrows():\n",
    "    #     section_statuses = ast.literal_eval(section_row['Statuses'])\n",
    "    #     section_groups = ast.literal_eval(section_row['Groups'])\n",
    "    #     section_directions = ast.literal_eval(section_row['Directions'])\n",
    "    #     df_section = data_full.loc[(data_full['GSE'] == section_row['GSE']) & (data_full['Status Origin'].isin(section_statuses)), :]\n",
    "\n",
    "    #     for section_group_id, section_group in enumerate(section_groups):\n",
    "    #         group_direction = section_directions[section_group_id]\n",
    "\n",
    "    #         df_section_group_0 = df_section.loc[df_section[\"Status Origin\"] == section_group[0], :]\n",
    "    #         explainer_0 = shap.SamplingExplainer(predict_func, df_section_group_0.loc[:, feats].values)\n",
    "    #         shap_values_0 = explainer_0.shap_values(df_section_group_0.loc[:, feats].values)\n",
    "    #         section_group_expl_0 = pd.DataFrame(data=shap_values_0, index=df_section_group_0.index, columns=feats)\n",
    "    #         shap_values_mean_0 = section_group_expl_0.mean()\n",
    "\n",
    "    #         df_section_group_1 = df_section.loc[df_section[\"Status Origin\"] == section_group[1], :]\n",
    "    #         explainer_1 = shap.SamplingExplainer(predict_func, df_section_group_1.loc[:, feats].values)\n",
    "    #         shap_values_1 = explainer_1.shap_values(df_section_group_1.loc[:, feats].values)\n",
    "    #         section_group_expl_1 = pd.DataFrame(data=shap_values_1, index=df_section_group_1.index, columns=feats)\n",
    "    #         shap_values_mean_1 = section_group_expl_1.mean()\n",
    "\n",
    "    #         if group_direction == 'Increasing':\n",
    "    #             df_imm_shap_raw.loc[feats, f\"shap_mean_diff\\n{section_id}\\n{section_group}\"] = shap_values_mean_1[feats] - shap_values_mean_0[feats]\n",
    "    #         else:\n",
    "    #             df_imm_shap_raw.loc[feats, f\"shap_mean_diff\\n{section_id}\\n{section_group}\"] = shap_values_mean_0[feats] - shap_values_mean_1[feats]\n",
    "    # df_imm_shap_raw.to_excel(f\"{path_models}/{model_id}/shap_mean_diff_raw.xlsx\", index_label='Immunomarker')  \n",
    "\n",
    "    # df_imm_shap = pd.DataFrame(index=feats)\n",
    "    # for icd_chpt in icd_chpts:\n",
    "    #     df_imm_shap.loc[feats, f'Chapter {icd_chpt}'] = 0.0\n",
    "    #     df_chpt = df_groups[df_groups['ICD-11 chapter'] == icd_chpt]\n",
    "    #     for section_id, section_row in df_chpt.iterrows():\n",
    "    #         section_groups = ast.literal_eval(section_row['Groups'])\n",
    "    #         for section_group_id, section_group in enumerate(section_groups):\n",
    "    #             df_imm_shap.loc[feats, f'Chapter {icd_chpt}'] += df_imm_shap_raw.loc[feats, f\"shap_mean_diff\\n{section_id}\\n{section_group}\"]   \n",
    "    # for icd_code in icd_codes:\n",
    "    #     df_imm_shap.loc[feats, f'Code {icd_code}'] = 0.0\n",
    "    #     df_code = df_groups[df_groups['ICD-11 code'] == icd_code]\n",
    "    #     for section_id, section_row in df_code.iterrows():\n",
    "    #         section_groups = ast.literal_eval(section_row['Groups'])\n",
    "    #         for section_group_id, section_group in enumerate(section_groups):\n",
    "    #             df_imm_shap.loc[feats, f'Code {icd_code}'] += df_imm_shap_raw.loc[feats, f\"shap_mean_diff\\n{section_id}\\n{section_group}\"]\n",
    "    # df_imm_shap.to_excel(f\"{path_models}/{model_id}/shap_mean_diff.xlsx\", index_label='Immunomarker')  \n",
    "\n",
    "    # df_imm_shap_table = pd.read_excel(f\"{path_models}/{model_id}/shap_mean_diff.xlsx\", index_col=0)\n",
    "    # df_imm_shap_table = df_imm_shap_table[[f'Chapter {icd_chpt}' for icd_chpt in icd_chpts]]\n",
    "    # df_imm_shap_table.index = df_imm_shap_table.index.str.replace('_log', '')\n",
    "    \n",
    "    # df_fig = df_imm_shap_table.astype(float)\n",
    "    # x_ticks_colors = {f'Chapter {icd_chpt}': colors_icd_chpts[icd_chpt] for icd_chpt in icd_chpts}\n",
    "    # sns.set_theme(style='ticks')\n",
    "    # clustermap = sns.clustermap(\n",
    "    #     df_fig,\n",
    "    #     annot=True,\n",
    "    #     col_cluster=False,\n",
    "    #     row_cluster=True,\n",
    "    #     fmt=\".2f\",\n",
    "    #     center=0.0,\n",
    "    #     cmap='seismic',\n",
    "    #     linewidth=0.1,\n",
    "    #     linecolor='black',\n",
    "    #     tree_kws=dict(linewidths=1.5),\n",
    "    #     figsize=(16, 12),\n",
    "    #     cbar_kws={'orientation': 'horizontal'}\n",
    "    # )\n",
    "    # clustermap.ax_heatmap.set_xlabel('')\n",
    "    # clustermap.ax_heatmap.set_ylabel('')\n",
    "    # for spine in clustermap.ax_cbar.spines.values():\n",
    "    #     spine.set(visible=True, lw=0.25, edgecolor=\"black\")\n",
    "    # clustermap.ax_heatmap.set_xticklabels(clustermap.ax_heatmap.get_xmajorticklabels(), rotation=0, path_effects=[pe.withStroke(linewidth=0.5, foreground=\"black\")])\n",
    "    # for tick_label in clustermap.ax_heatmap.get_xticklabels():\n",
    "    #     tick_label.set_color(x_ticks_colors[tick_label.get_text()])\n",
    "    # clustermap_pos = clustermap.ax_heatmap.get_position()\n",
    "    # clustermap.ax_cbar.set_position([clustermap_pos.x0, clustermap_pos.y1 + 0.05, clustermap_pos.width, 0.03])\n",
    "    # clustermap.ax_cbar.set_title(\"XAI age acceleration difference\", fontsize='large')\n",
    "    # clustermap.ax_cbar.tick_params(labelsize='large')\n",
    "    # for spine in clustermap.ax_cbar.spines:\n",
    "    #     clustermap.ax_cbar.spines[spine].set_linewidth(1)\n",
    "    # plt.savefig(f\"{path_models}/{model_id}/shap_mean_diff.png\", bbox_inches='tight', dpi=200)\n",
    "    # plt.savefig(f\"{path_models}/{model_id}/shap_mean_diff.pdf\", bbox_inches='tight')\n",
    "    # plt.close(clustermap.figure)\n",
    "\n",
    "    # # SHAP age acceleration table\n",
    "\n",
    "    # df_imm_shap_raw = pd.DataFrame(index=feats)\n",
    "    # for section_id, section_row in df_groups.iterrows():\n",
    "    #     section_statuses = ast.literal_eval(section_row['Statuses'])\n",
    "    #     section_groups = ast.literal_eval(section_row['Groups'])\n",
    "    #     section_directions = ast.literal_eval(section_row['Directions'])\n",
    "    #     df_section = data_full.loc[(data_full['GSE'] == section_row['GSE']) & (data_full['Status Origin'].isin(section_statuses)), :]\n",
    "\n",
    "    #     for section_group_id, section_group in enumerate(section_groups):\n",
    "    #         group_direction = section_directions[section_group_id]\n",
    "\n",
    "    #         df_section_group_0 = df_section.loc[df_section[\"Status Origin\"] == section_group[0], :]\n",
    "    #         section_group_expl_0 = model.explain(df_section_group_0, method=explain_method, baselines=explain_baselines)\n",
    "    #         shap_values_mean_0 = section_group_expl_0.mean()\n",
    "\n",
    "    #         df_section_group_1 = df_section.loc[df_section[\"Status Origin\"] == section_group[1], :]\n",
    "    #         section_group_expl_1 = model.explain(df_section_group_1, method=explain_method, baselines=explain_baselines)\n",
    "    #         shap_values_mean_1 = section_group_expl_1.mean()\n",
    "\n",
    "    #         if group_direction == 'Increasing':\n",
    "    #             df_imm_shap_raw.loc[feats, f\"shap_mean_diff\\n{section_id}\\n{section_group}\"] = shap_values_mean_1[feats] - shap_values_mean_0[feats]\n",
    "    #         else:\n",
    "    #             df_imm_shap_raw.loc[feats, f\"shap_mean_diff\\n{section_id}\\n{section_group}\"] = shap_values_mean_0[feats] - shap_values_mean_1[feats]\n",
    "    # df_imm_shap_raw.to_excel(f\"{path_models}/{model_id}/shap_mean_diff_raw.xlsx\", index_label='Immunomarker')  \n",
    "\n",
    "    # df_imm_shap = pd.DataFrame(index=feats)\n",
    "    # for icd_chpt in icd_chpts:\n",
    "    #     df_imm_shap.loc[feats, f'Chapter {icd_chpt}'] = 0.0\n",
    "    #     df_chpt = df_groups[df_groups['ICD-11 chapter'] == icd_chpt]\n",
    "    #     for section_id, section_row in df_chpt.iterrows():\n",
    "    #         section_groups = ast.literal_eval(section_row['Groups'])\n",
    "    #         for section_group_id, section_group in enumerate(section_groups):\n",
    "    #             df_imm_shap.loc[feats, f'Chapter {icd_chpt}'] += df_imm_shap_raw.loc[feats, f\"shap_mean_diff\\n{section_id}\\n{section_group}\"]   \n",
    "    # for icd_code in icd_codes:\n",
    "    #     df_imm_shap.loc[feats, f'Code {icd_code}'] = 0.0\n",
    "    #     df_code = df_groups[df_groups['ICD-11 code'] == icd_code]\n",
    "    #     for section_id, section_row in df_code.iterrows():\n",
    "    #         section_groups = ast.literal_eval(section_row['Groups'])\n",
    "    #         for section_group_id, section_group in enumerate(section_groups):\n",
    "    #             df_imm_shap.loc[feats, f'Code {icd_code}'] += df_imm_shap_raw.loc[feats, f\"shap_mean_diff\\n{section_id}\\n{section_group}\"]\n",
    "    # df_imm_shap.to_excel(f\"{path_models}/{model_id}/shap_mean_diff.xlsx\", index_label='Immunomarker')  \n",
    "\n",
    "    # df_imm_shap_table = pd.read_excel(f\"{path_models}/{model_id}/shap_mean_diff.xlsx\", index_col=0)\n",
    "    # df_imm_shap_table = df_imm_shap_table[[f'Chapter {icd_chpt}' for icd_chpt in icd_chpts]]\n",
    "    # df_imm_shap_table.index = df_imm_shap_table.index.str.replace('_log', '')\n",
    "    \n",
    "    # df_fig = df_imm_shap_table.astype(float)\n",
    "    # x_ticks_colors = {f'Chapter {icd_chpt}': colors_icd_chpts[icd_chpt] for icd_chpt in icd_chpts}\n",
    "    # sns.set_theme(style='ticks')\n",
    "    # clustermap = sns.clustermap(\n",
    "    #     df_fig,\n",
    "    #     annot=True,\n",
    "    #     col_cluster=False,\n",
    "    #     row_cluster=True,\n",
    "    #     fmt=\".2f\",\n",
    "    #     center=0.0,\n",
    "    #     cmap='seismic',\n",
    "    #     linewidth=0.1,\n",
    "    #     linecolor='black',\n",
    "    #     tree_kws=dict(linewidths=1.5),\n",
    "    #     figsize=(16, 12),\n",
    "    #     cbar_kws={'orientation': 'horizontal'}\n",
    "    # )\n",
    "    # clustermap.ax_heatmap.set_xlabel('')\n",
    "    # clustermap.ax_heatmap.set_ylabel('')\n",
    "    # for spine in clustermap.ax_cbar.spines.values():\n",
    "    #     spine.set(visible=True, lw=0.25, edgecolor=\"black\")\n",
    "    # clustermap.ax_heatmap.set_xticklabels(clustermap.ax_heatmap.get_xmajorticklabels(), rotation=0, path_effects=[pe.withStroke(linewidth=0.5, foreground=\"black\")])\n",
    "    # for tick_label in clustermap.ax_heatmap.get_xticklabels():\n",
    "    #     tick_label.set_color(x_ticks_colors[tick_label.get_text()])\n",
    "    # clustermap_pos = clustermap.ax_heatmap.get_position()\n",
    "    # clustermap.ax_cbar.set_position([clustermap_pos.x0, clustermap_pos.y1 + 0.05, clustermap_pos.width, 0.03])\n",
    "    # clustermap.ax_cbar.set_title(\"XAI age acceleration difference\", fontsize='large')\n",
    "    # clustermap.ax_cbar.tick_params(labelsize='large')\n",
    "    # for spine in clustermap.ax_cbar.spines:\n",
    "    #     clustermap.ax_cbar.spines[spine].set_linewidth(1)\n",
    "    # plt.savefig(f\"{path_models}/{model_id}/shap_mean_diff.png\", bbox_inches='tight', dpi=200)\n",
    "    # plt.savefig(f\"{path_models}/{model_id}/shap_mean_diff.pdf\", bbox_inches='tight')\n",
    "    # plt.close(clustermap.figure)\n",
    "\n",
    "    # Table with all clocks\n",
    "\n",
    "    clocks_tests.at['This work', 'Total Rho'] = df_metrics.at['Total', 'Rho']\n",
    "    clocks_tests.at['This work', 'Total MAE'] = df_metrics.at['Total', 'MAE']\n",
    "    clocks_tests.at['This work', 'Year'] = ''\n",
    "\n",
    "    for section_id, section_row in df_groups.iterrows():\n",
    "        section_statuses = ast.literal_eval(section_row['Statuses'])\n",
    "        section_groups = ast.literal_eval(section_row['Groups'])\n",
    "        section_directions = ast.literal_eval(section_row['Directions'])\n",
    "        df_section = data_full.loc[(data_full['GSE'] == section_row['GSE']) & (data_full['Status Origin'].isin(section_statuses)), ['Status Origin', 'Error']]\n",
    "\n",
    "        for section_group_id, section_group in enumerate(section_groups):\n",
    "\n",
    "            _, pval = mannwhitneyu(\n",
    "                df_section.loc[df_section[\"Status Origin\"] == section_group[0], \"Error\"].values,\n",
    "                df_section.loc[df_section[\"Status Origin\"] == section_group[1], \"Error\"].values,\n",
    "                alternative=\"two-sided\",\n",
    "            )\n",
    "            bias_0 = np.mean(df_section.loc[df_section['Status Origin'] == section_group[0], 'Error'])\n",
    "            bias_1 = np.mean(df_section.loc[df_section['Status Origin'] == section_group[1], 'Error'])\n",
    "\n",
    "            clocks_tests_raw.at['This work', f\"pval\\n{section_id}\\n{section_group}\"] = pval\n",
    "            clocks_tests_raw.at['This work', f\"bias_0\\n{section_id}\\n{section_group}\"] = bias_0\n",
    "            clocks_tests_raw.at['This work', f\"bias_1\\n{section_id}\\n{section_group}\"] = bias_1\n",
    "\n",
    "    # Here we can modify clocks' test results (p-values)\n",
    "    pvals_cols = [col for col in clocks_tests_raw.columns if 'pval' in col]\n",
    "    _, clocks_tests_raw.loc['This work', pvals_cols], _, _ = multipletests(clocks_tests_raw.loc['This work', pvals_cols], 0.05, method='fdr_bh')\n",
    "\n",
    "    passed_icd_chpt = {icd_chpt: 0 for icd_chpt in icd_chpts}\n",
    "    passed_icd_chpt_max = {icd_chpt: 0 for icd_chpt in icd_chpts}\n",
    "    for icd_chpt in icd_chpts:\n",
    "        df_chpt = df_groups[df_groups['ICD-11 chapter'] == icd_chpt]\n",
    "        for section_id, section_row in df_chpt.iterrows():\n",
    "            section_statuses = ast.literal_eval(section_row['Statuses'])\n",
    "            section_groups = ast.literal_eval(section_row['Groups'])\n",
    "            section_directions = ast.literal_eval(section_row['Directions'])\n",
    "\n",
    "            for section_group_id, section_group in enumerate(section_groups):\n",
    "                passed_icd_chpt_max[icd_chpt] += 1\n",
    "\n",
    "                pval = clocks_tests_raw.at['This work', f\"pval\\n{section_id}\\n{section_group}\"]\n",
    "                bias_0 = clocks_tests_raw.at['This work', f\"bias_0\\n{section_id}\\n{section_group}\"]\n",
    "                bias_1 = clocks_tests_raw.at['This work', f\"bias_1\\n{section_id}\\n{section_group}\"]\n",
    "\n",
    "                group_direction = section_directions[section_group_id]\n",
    "\n",
    "                if pval < 0.05:\n",
    "                    if group_direction == 'Increasing' and bias_1 > bias_0:\n",
    "                        passed_icd_chpt[icd_chpt] += 1\n",
    "                    elif group_direction == 'Decreasing' and bias_1 < bias_0:\n",
    "                        passed_icd_chpt[icd_chpt] += 1\n",
    "        clocks_tests.at['This work', f'Passed\\nICD-11\\nChapter {icd_chpt}'] = passed_icd_chpt[icd_chpt]\n",
    "        clocks_tests.at['This work', f'Max\\nPassed\\nICD-11\\nChapter {icd_chpt}'] = passed_icd_chpt_max[icd_chpt]\n",
    "    clocks_tests.at['This work', f'Passed\\nICD-11\\nTotal'] = sum(passed_icd_chpt.values())\n",
    "    clocks_tests.at['This work', f'Max\\nPassed\\nICD-11\\nTotal'] = sum(passed_icd_chpt_max.values())\n",
    "\n",
    "    passed_icd_code = {icd_code: 0 for icd_code in icd_codes}\n",
    "    passed_icd_code_max = {icd_code: 0 for icd_code in icd_codes}\n",
    "    for icd_code in icd_codes:\n",
    "        df_code = df_groups[df_groups['ICD-11 code'] == icd_code]\n",
    "        for section_id, section_row in df_code.iterrows():\n",
    "            section_statuses = ast.literal_eval(section_row['Statuses'])\n",
    "            section_groups = ast.literal_eval(section_row['Groups'])\n",
    "            section_directions = ast.literal_eval(section_row['Directions'])\n",
    "\n",
    "            for section_group_id, section_group in enumerate(section_groups):\n",
    "                passed_icd_code_max[icd_code] += 1\n",
    "\n",
    "                pval = clocks_tests_raw.at['This work', f\"pval\\n{section_id}\\n{section_group}\"]\n",
    "                bias_0 = clocks_tests_raw.at['This work', f\"bias_0\\n{section_id}\\n{section_group}\"]\n",
    "                bias_1 = clocks_tests_raw.at['This work', f\"bias_1\\n{section_id}\\n{section_group}\"]\n",
    "\n",
    "                group_direction = section_directions[section_group_id]\n",
    "\n",
    "                if pval < 0.05:\n",
    "                    if group_direction == 'Increasing' and bias_1 > bias_0:\n",
    "                        passed_icd_code[icd_code] += 1\n",
    "                    elif group_direction == 'Decreasing' and bias_1 < bias_0:\n",
    "                        passed_icd_code[icd_code] += 1\n",
    "        clocks_tests.at['This work', f'Passed\\nICD-11\\nCode {icd_code}'] = passed_icd_code[icd_code]\n",
    "        clocks_tests.at['This work', f'Max\\nPassed\\nICD-11\\nCode {icd_code}'] = passed_icd_code_max[icd_code]\n",
    "\n",
    "    clocks_tests.to_excel(f\"{path_models}/{model_id}/clocks_test.xlsx\", index_label='Model ID')\n",
    "    clocks_tests_raw.to_excel(f\"{path_models}/{model_id}/clocks_tests_raw.xlsx\", index_label='Model ID')\n",
    "    df_clocks = clocks_tests.copy()\n",
    "    df_clocks[f\"Passed\\nICD-11\\nTotal\"] /= clocks_tests.at['Hannum', f'Max\\nPassed\\nICD-11\\nTotal']\n",
    "    for col in icd_cols:\n",
    "        df_clocks[col] /= clocks_tests.at['Hannum', f'Max\\n{col}']\n",
    "    df_clocks = df_clocks.iloc[np.arange(-1, len(df_clocks)-1)] # Move the last row to the first position\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(25, 17))\n",
    "    table = Table(\n",
    "        df_clocks[icd_chpt_col_names],\n",
    "        column_definitions=icd_chpt_col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        odd_row_color=\"#ffffff\",\n",
    "        even_row_color=\"#f0f0f0\",\n",
    "        ax=ax,\n",
    "        # textprops={\"fontsize\": 10},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=icd_chpt_col_names)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/clocks_chpts.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/clocks_chpts.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(45, 22))\n",
    "    table = Table(\n",
    "        df_clocks[icd_code_col_names],\n",
    "        column_definitions=icd_code_col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        odd_row_color=\"#ffffff\",\n",
    "        even_row_color=\"#f0f0f0\",\n",
    "        ax=ax,\n",
    "        # textprops={\"fontsize\": 10},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=icd_code_col_names)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/clocks_codes.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/clocks_codes.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Results on all controls\n",
    "\n",
    "    sns.set_theme(style='ticks')\n",
    "    fig = plt.figure(layout='constrained', figsize=(15, 10))\n",
    "    subfigs = fig.subfigures(1, 2, width_ratios=[4, 9], wspace=0.05)\n",
    "    \n",
    "    axs = subfigs[0].subplots(4, 1, height_ratios=[0.2, 0.2, 0.8, 0.58], gridspec_kw={'wspace':0.25, 'hspace': 0.05}, sharey=False, sharex=False)\n",
    "\n",
    "    data_ctrl = data_full.loc[data_full['Status'] == 'Control', ['Age', 'Status', 'Group', 'Prediction', 'Error']]\n",
    "    row_id_table = 0\n",
    "    row_id_hist = 1\n",
    "    row_id_scatter = 2\n",
    "    row_id_violin = 3\n",
    "\n",
    "    df_table = pd.DataFrame(index=['MAE', fr\"Pearson $\\mathbf{{\\rho}}$\", \"Bias\"], columns=['Train', 'Validation', 'Test', 'Total'])\n",
    "    for part in ['Train', 'Validation', 'Test', 'Total']:\n",
    "        df_table.at['MAE', part] = f\"{df_metrics.at[part, 'MAE']:0.3f}\"\n",
    "        df_table.at[fr\"Pearson $\\mathbf{{\\rho}}$\", part] = f\"{df_metrics.at[part, 'Rho']:0.3f}\"\n",
    "        df_table.at[\"Bias\", part] = f\"{df_metrics.at[part, 'Bias']:0.3f}\"\n",
    "\n",
    "    col_defs = [\n",
    "        ColumnDefinition(\n",
    "            name=\"index\",\n",
    "            title='',\n",
    "            textprops={\"ha\": \"center\", \"weight\": \"bold\"},\n",
    "            width=2.5,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Train\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "            border=\"left\"\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Validation\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=2.2,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Test\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Total\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    axs[row_id_table].text(-2, -1, 'A', fontsize=30, fontfamily='arial')\n",
    "\n",
    "    table = Table(\n",
    "        df_table,\n",
    "        column_definitions=col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        ax=axs[row_id_table],\n",
    "        textprops={\"fontsize\": 8},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=['Train', 'Validation', 'Test', 'Total'])\n",
    "\n",
    "    hist_bins = np.linspace(0, 120, 25)\n",
    "    histplot = sns.histplot(\n",
    "        data=data_ctrl,\n",
    "        bins=hist_bins,\n",
    "        edgecolor='k',\n",
    "        linewidth=1,\n",
    "        x=\"Age\",\n",
    "        color='lightslategray',\n",
    "        ax=axs[row_id_hist]\n",
    "    )\n",
    "    axs[row_id_hist].set_xticks([])\n",
    "    axs[row_id_hist].set_xlim(0, 105)\n",
    "    axs[row_id_hist].set_ylabel(\"Count\")\n",
    "    axs[row_id_hist].set_xlabel(\"\")\n",
    "\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=data_ctrl.loc[data_ctrl['Group'].isin(['Train', 'Validation']), :],\n",
    "        x='Age',\n",
    "        y='Prediction',\n",
    "        fill=True,\n",
    "        cbar=False,\n",
    "        thresh=0.005,\n",
    "        color=make_rgb_transparent(mcolors.hex2color(mcolors.CSS4_COLORS['lightslategray']), (1, 1, 1), 0.25),\n",
    "        cut=0,\n",
    "        legend=False,\n",
    "        ax=axs[row_id_scatter]\n",
    "    )\n",
    "    scatter = sns.scatterplot(\n",
    "        data=data_ctrl.loc[data_ctrl['Group'] == 'Test', :],\n",
    "        x='Age',\n",
    "        y=\"Prediction\",\n",
    "        linewidth=0.01,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"k\",\n",
    "        s=2,\n",
    "        color='lightslategray',\n",
    "        ax=axs[row_id_scatter],\n",
    "    )\n",
    "    axs[row_id_scatter].axline((0, 0), slope=1, color=\"black\", linestyle=\":\")\n",
    "    axs[row_id_scatter].set_xlim(0, 105)\n",
    "    axs[row_id_scatter].set_ylim(0, 105)\n",
    "    axs[row_id_scatter].set_ylabel(\"Prediction\")\n",
    "    axs[row_id_scatter].set_xlabel(\"Age\")\n",
    "    \n",
    "    violin = sns.violinplot(\n",
    "        data=data_ctrl,\n",
    "        x='Group',\n",
    "        y='Error',\n",
    "        palette={'Train': 'lightgray', 'Validation': 'lightslategray', 'Test': 'dimgrey'},\n",
    "        scale='width',\n",
    "        order=['Train', 'Validation', 'Test'],\n",
    "        saturation=0.75,\n",
    "        legend=False,\n",
    "        ax=axs[row_id_violin]\n",
    "    )\n",
    "    axs[row_id_violin].set_xlabel('')\n",
    "    axs[row_id_violin].set_ylabel('Age Acceleration')\n",
    "    \n",
    "    ids_shap = ids_test\n",
    "            \n",
    "    # explanation = model.explain(data_full.loc[ids_shap, :], method=explain_method, baselines=explain_baselines)\n",
    "    # explanation.index = data_full.loc[ids_shap, :].index\n",
    "    # explanation.rename(columns=lambda s: s.replace(\"_log\", \"\"), inplace=True)\n",
    "    # explanation.to_excel(f\"{path_models}/{model_id}/explanation.xlsx\")\n",
    "    explanation = pd.read_excel(f\"{path_models}/{model_id}/shap_global/explanation.xlsx\", index_col=0)\n",
    "    \n",
    "    path_imm = f\"E:/YandexDisk/Work/bbd/immunology/003_EpImAge/{imm_data_type}/{epi_data_type}/{selection_method}_{n_feats}\"\n",
    "    df_imm_models = pd.read_excel(f\"{path_imm}/best_models_v5.xlsx\", index_col=0)\n",
    "    df_imm_models.sort_values(['test_pearson_corrcoef'], ascending=[False], inplace=True)\n",
    "    imm_colors = distinctipy.get_colors(n_colors=df_imm_models.shape[0], exclude_colors=[mcolors.hex2color(mcolors.CSS4_COLORS['gray'])], rng=42)\n",
    "    imm_colors_dict = {}\n",
    "    for imm_id, imm in enumerate(df_imm_models.index.values):\n",
    "        imm_color = imm_colors[imm_id]\n",
    "        imm_colors_dict[imm] = imm_color\n",
    "    \n",
    "    ds_fi = pd.DataFrame(index=explanation.columns.values, columns=['mean(|SHAP|)'])\n",
    "    for f in explanation.columns.values:\n",
    "        ds_fi.at[f, 'mean(|SHAP|)'] = explanation[f].abs().mean()\n",
    "    ds_fi.sort_values(['mean(|SHAP|)'], ascending=[False], inplace=True)\n",
    "    ds_fi['Features'] = ds_fi.index.values\n",
    "    \n",
    "\n",
    "    axs = subfigs[1].subplots(1, 2, width_ratios=[2, 7], gridspec_kw={'wspace':0.01, 'hspace': 0.05}, sharey=True, sharex=False)\n",
    "    \n",
    "    axs[0].text(-2, -1, 'B', fontsize=30, fontfamily='arial')\n",
    "    \n",
    "    barplot = sns.barplot(\n",
    "        data=ds_fi,\n",
    "        x='mean(|SHAP|)',\n",
    "        y='Features',\n",
    "        # color=ds_color,\n",
    "        hue='Features',\n",
    "        palette=imm_colors_dict,\n",
    "        edgecolor='black',\n",
    "        dodge=False,\n",
    "        ax=axs[0]\n",
    "    )\n",
    "    for container in barplot.containers:\n",
    "        barplot.bar_label(container, label_type='edge', color='gray', fmt='%0.2f', fontsize=12, padding=3.0)\n",
    "    axs[0].set_ylabel('')\n",
    "    axs[0].set(yticklabels=ds_fi.index.to_list())\n",
    "    # axs[0].get_legend().remove()\n",
    "    \n",
    "    is_colorbar = False\n",
    "    f_legends = []\n",
    "    for f in ds_fi.index:\n",
    "        \n",
    "        f_shap_ll = explanation[f].quantile(0.01)\n",
    "        f_shap_hl = explanation[f].quantile(0.99)\n",
    "        f_shap_index = explanation.index[(explanation[f] >= f_shap_ll) & (explanation[f] <= f_shap_hl)].values\n",
    "        \n",
    "        df_f_vals = data_full.loc[f_shap_index, :]\n",
    "        f_vals_ll = df_f_vals[f\"{f}_log\"].quantile(0.01)\n",
    "        f_vals_hl = df_f_vals[f\"{f}_log\"].quantile(0.99)\n",
    "        f_shap_index = df_f_vals.index[(df_f_vals[f\"{f}_log\"] >= f_vals_ll) & (df_f_vals[f\"{f}_log\"] <= f_vals_hl)].values\n",
    "        \n",
    "        f_shap = explanation.loc[f_shap_index, f].values\n",
    "        f_vals = data_full.loc[f_shap_index, f\"{f}_log\"].values\n",
    "        \n",
    "        f_cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "        f_norm = mcolors.Normalize(vmin=min(f_vals), vmax=max(f_vals)) \n",
    "        f_colors = {}\n",
    "        for cval in f_vals:\n",
    "            f_colors.update({cval: f_cmap(f_norm(cval))})\n",
    "\n",
    "        strip = sns.stripplot(\n",
    "            x=f_shap,\n",
    "            y=[f]*len(f_shap),\n",
    "            hue=f_vals,\n",
    "            palette=f_colors,\n",
    "            jitter=0.35,\n",
    "            alpha=0.5,\n",
    "            edgecolor='gray',\n",
    "            linewidth=0.00,\n",
    "            size=2,\n",
    "            legend=False,\n",
    "            ax=axs[1],\n",
    "        )\n",
    "        \n",
    "        if not is_colorbar:\n",
    "            sm = plt.cm.ScalarMappable(cmap=f_cmap, norm=f_norm)\n",
    "            sm.set_array([])\n",
    "            cbar = strip.figure.colorbar(sm)\n",
    "            cbar.set_label('Inflammatory markers', labelpad=-4, fontsize='large')\n",
    "            cbar.set_ticks([min(f_vals), max(f_vals)])\n",
    "            cbar.set_ticklabels([\"Min\", \"Max\"])\n",
    "            is_colorbar = True\n",
    "        \n",
    "    axs[1].set_xlabel('SHAP')\n",
    "\n",
    "    fig.savefig(f\"{path_models}/{model_id}/controls.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/controls.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Results on GSEs\n",
    "\n",
    "    n_rows = 6 * 4\n",
    "    n_cols = 12\n",
    "    fig_height = 32\n",
    "    fig_width = 46\n",
    "    sns.set_theme(style='ticks')\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), height_ratios=[0.2, 0.2, 0.8, 0.15] * 6, gridspec_kw={'wspace':0.25, 'hspace': 0.05}, sharey=False, sharex=False)\n",
    "\n",
    "    for gse_id, (gse, gse_samples) in tqdm(enumerate(gse_controls_ids.items())):\n",
    "        color_gse = colors_gse[gse]\n",
    "        data_gse = data_full.loc[gse_samples, ['GSE', 'Age', 'Status', 'Group', 'Prediction', 'Error']]\n",
    "        row_id, col_id = divmod(gse_id, n_cols)\n",
    "        row_id_table = row_id * 4\n",
    "        row_id_hist = row_id * 4 + 1\n",
    "        row_id_scatter = row_id * 4 + 2\n",
    "        row_id_empty = row_id * 4 + 3\n",
    "\n",
    "        df_table = pd.DataFrame(index=['MAE', fr\"Pearson $\\mathbf{{\\rho}}$\", \"Bias\"], columns=['Train', 'Validation', 'Test', 'Total'])\n",
    "        for part in ['Train', 'Validation', 'Test', 'Total']:\n",
    "            df_table.at['MAE', part] = f\"{df_gses_models_metrics[f'MAE {part}'].at[gse, model_id]:0.3f}\"\n",
    "            df_table.at[fr\"Pearson $\\mathbf{{\\rho}}$\", part] = f\"{df_gses_models_metrics[f'Rho {part}'].at[gse, model_id]:0.3f}\"\n",
    "            df_table.at[\"Bias\", part] = f\"{df_gses_models_metrics[f'Bias {part}'].at[gse, model_id]:0.3f}\"\n",
    "\n",
    "        col_defs = [\n",
    "            ColumnDefinition(\n",
    "                name=\"index\",\n",
    "                title=gse if gse != 'GSEUNN' else 'This work',\n",
    "                textprops={\"ha\": \"center\", \"weight\": \"bold\"},\n",
    "                width=2.5,\n",
    "            ),\n",
    "            ColumnDefinition(\n",
    "                name=\"Train\",\n",
    "                textprops={\"ha\": \"left\"},\n",
    "                width=1.5,\n",
    "                border=\"left\"\n",
    "            ),\n",
    "            ColumnDefinition(\n",
    "                name=\"Validation\",\n",
    "                textprops={\"ha\": \"left\"},\n",
    "                width=2.2,\n",
    "            ),\n",
    "            ColumnDefinition(\n",
    "                name=\"Test\",\n",
    "                textprops={\"ha\": \"left\"},\n",
    "                width=1.5,\n",
    "            ),\n",
    "            ColumnDefinition(\n",
    "                name=\"Total\",\n",
    "                textprops={\"ha\": \"left\"},\n",
    "                width=1.5,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        table = Table(\n",
    "            df_table,\n",
    "            column_definitions=col_defs,\n",
    "            row_dividers=True,\n",
    "            footer_divider=False,\n",
    "            ax=axs[row_id_table, col_id],\n",
    "            textprops={\"fontsize\": 8},\n",
    "            row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "            col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "            column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        ).autoset_fontcolors(colnames=['Train', 'Validation', 'Test', 'Total'])\n",
    "\n",
    "        hist_bins = np.linspace(0, 120, 13)\n",
    "        histplot = sns.histplot(\n",
    "            data=data_gse,\n",
    "            bins=hist_bins,\n",
    "            edgecolor='k',\n",
    "            linewidth=1,\n",
    "            x=\"Age\",\n",
    "            color=color_gse,\n",
    "            ax=axs[row_id_hist, col_id]\n",
    "        )\n",
    "        axs[row_id_hist, col_id].set_xticks([])\n",
    "        axs[row_id_hist, col_id].set_xlim(0, 115)\n",
    "        if col_id == 0:\n",
    "            axs[row_id_hist, col_id].set_ylabel(\"Count\")\n",
    "        else:\n",
    "            axs[row_id_hist, col_id].set_ylabel(\"\")\n",
    "\n",
    "        kdeplot = sns.kdeplot(\n",
    "            data=data_gse.loc[data_gse['Group'].isin(['Train', 'Validation']), :],\n",
    "            x='Age',\n",
    "            y='Prediction',\n",
    "            fill=True,\n",
    "            cbar=False,\n",
    "            color=make_rgb_transparent(color_gse, (1, 1, 1), 0.25),\n",
    "            cut=0,\n",
    "            legend=False,\n",
    "            ax=axs[row_id_scatter, col_id]\n",
    "        )\n",
    "        scatter = sns.scatterplot(\n",
    "            data=data_gse.loc[data_gse['Group'] == 'Test', :],\n",
    "            x='Age',\n",
    "            y=\"Prediction\",\n",
    "            linewidth=0.5,\n",
    "            alpha=0.8,\n",
    "            edgecolor=\"k\",\n",
    "            s=35,\n",
    "            color=color_gse,\n",
    "            ax=axs[row_id_scatter, col_id],\n",
    "        )\n",
    "        axs[row_id_scatter, col_id].axline((0, 0), slope=1, color=\"black\", linestyle=\":\")\n",
    "        axs[row_id_scatter, col_id].set_xlim(0, 115)\n",
    "        axs[row_id_scatter, col_id].set_ylim(0, 115)\n",
    "        if col_id == 0:\n",
    "            axs[row_id_scatter, col_id].set_ylabel(\"Prediction\")\n",
    "        else:\n",
    "            axs[row_id_scatter, col_id].set_ylabel(\"\")\n",
    "        if row_id_empty == n_rows - 1:\n",
    "            axs[row_id_scatter, col_id].set_xlabel(\"Age\")\n",
    "        else:\n",
    "            axs[row_id_scatter, col_id].set_xlabel(\"\")\n",
    "        axs[row_id_empty, col_id].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{path_models}/{model_id}/gses.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/gses.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Mosaic violins plot\n",
    "\n",
    "    sns.set_theme(style='ticks')\n",
    "    fig_height = 5 * len(mosaic_violins)\n",
    "    fig_width = 1.4 * max_mosaic_row\n",
    "    fig, axs = plt.subplot_mosaic(mosaic=mosaic_violins, figsize=(fig_width, fig_height), gridspec_kw={}, sharey=False, sharex=False)\n",
    "\n",
    "    for plot_id, plot_row in df_groups.iterrows():\n",
    "\n",
    "        plot_statuses = [statuses_rename[x] for x in ast.literal_eval(plot_row['Statuses'])]\n",
    "        plot_groups_raw = ast.literal_eval(plot_row['Groups'])\n",
    "        plot_groups = [(statuses_rename[x[0]], statuses_rename[x[1]]) for x in ast.literal_eval(plot_row['Groups'])]\n",
    "\n",
    "        df_plot = data_full.loc[(data_full['GSE'] == plot_row['GSE']) & (data_full['Status'].isin(plot_statuses)), ['Status', 'Error']]\n",
    "        plot_status_count = df_plot['Status'].value_counts()\n",
    "        plot_statuses_rename = {}\n",
    "        for x in plot_statuses:\n",
    "            plot_statuses_rename[x] = x + f\"\\nCount: {plot_status_count[x]}\\nBias: {np.mean(df_plot.loc[df_plot['Status'] == x, 'Error']):0.1f}\"\n",
    "        plot_statuses = [plot_statuses_rename[x] for x in plot_statuses]\n",
    "        plot_groups = [(plot_statuses_rename[x[0]], plot_statuses_rename[x[1]]) for x in plot_groups]\n",
    "        df_plot['Status'] = df_plot['Status'].replace(plot_statuses_rename)\n",
    "        colors_plot_status = {plot_statuses_rename[x]: colors_status[x] for x in plot_statuses_rename}\n",
    "\n",
    "        pval_formatted = []\n",
    "        for plot_group_id, plot_group in enumerate(plot_groups):\n",
    "            pval = clocks_tests_raw.at['This work', f\"pval\\n{plot_id}\\n{plot_groups_raw[plot_group_id]}\"]\n",
    "            pval_formatted.append(f\"{pval:.1e}\")\n",
    "\n",
    "        violinplot = sns.violinplot(\n",
    "            data=df_plot,\n",
    "            x='Status',\n",
    "            y='Error',\n",
    "            palette=colors_plot_status,\n",
    "            scale='width',\n",
    "            order=plot_statuses,\n",
    "            saturation=0.75,\n",
    "            legend=False,\n",
    "            ax=axs[plot_id]\n",
    "        )\n",
    "        annotator = Annotator(\n",
    "            ax=axs[plot_id],\n",
    "            pairs=plot_groups,\n",
    "            data=df_plot,\n",
    "            x=\"Status\",\n",
    "            y=\"Error\",\n",
    "            order=plot_statuses,\n",
    "        )\n",
    "        annotator.set_custom_annotations(pval_formatted)\n",
    "        annotator.configure(loc='inside', verbose=0)\n",
    "        annotator.annotate()\n",
    "\n",
    "        axs[plot_id].set_xlabel('')\n",
    "        axs[plot_id].set_ylabel('Age acceleration')\n",
    "        if plot_row['GSE'] == 'GSEUNN':\n",
    "            axs[plot_id].set_title(f\"This work ({df_plot.shape[0]})\")\n",
    "        else:\n",
    "            axs[plot_id].set_title(f\"{plot_row['GSE']} ({df_plot.shape[0]})\")\n",
    "        # axs[plot_id].set_facecolor(make_rgb_transparent(colors_icd_chpts[plot_row['ICD-11 chapter']], (1, 1, 1), 0.33))\n",
    "\n",
    "    for empty_panel in violons_empty_panels:\n",
    "        axs[empty_panel].axis('off')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{path_models}/{model_id}/violins_Status.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/violins_Status.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Ridgeline (column of violins) for controls' error\n",
    "\n",
    "    # for part, ids_part in ids_dict.items():\n",
    "    #     # Errors in GSEs\n",
    "    #     df_fig = data_full.loc[ids_part, ['Error', 'GSE']].copy()\n",
    "    #     df_fig['GSE'] = pd.Categorical(df_fig.GSE, categories=gses_controls, ordered=True)\n",
    "    #     df_fig = df_fig.sort_values('GSE')\n",
    "    #     gses_rename = {\n",
    "    #         gse: f\"{gse} ({gse_controls_count[gse]})\" + \"\\n\" +\n",
    "    #                fr\"MAE: {df_gses_models_metrics[f'MAE {part}'].at[gse, model_id]:0.2f}\" + \"\\n\"\n",
    "    #                fr\"Pearson $\\rho$: {df_gses_models_metrics[f'Rho {part}'].at[gse, model_id]:0.2f}\" + \"\\n\" +\n",
    "    #                fr\"Bias: {df_gses_models_metrics[f'Bias {part}'].at[gse, model_id]:0.2f}\"  + \"\\n\" +\n",
    "    #                f\"{gse_preproc.at[gse, 'Preproc']}\"\n",
    "    #         for gse in colors_gse\n",
    "    #     }\n",
    "    #     gse_colors_grid = {gses_rename[gse]: colors_gse[gse] for gse in colors_gse}\n",
    "    #     df_fig['GSE'].replace(gses_rename, inplace=True)\n",
    "    #     sns.set_theme(style=\"whitegrid\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "    #     g = sns.FacetGrid(df_fig, row=\"GSE\", hue=\"GSE\", aspect=8, height=0.5, palette=gse_colors_grid)\n",
    "    #     g.map(\n",
    "    #         sns.kdeplot,\n",
    "    #         'Error',\n",
    "    #         fill=True,\n",
    "    #         alpha=1.0,\n",
    "    #         linewidth=0.5\n",
    "    #     )\n",
    "    #     g.map(\n",
    "    #         sns.kdeplot,\n",
    "    #         'Error',\n",
    "    #         color=\"black\",\n",
    "    #         linewidth=1.0,\n",
    "    #     )\n",
    "    #     # g.refline(y=0, linewidth=2.0, linestyle=\"-\", color=None, clip_on=False)\n",
    "    #     def label(x, color, label):\n",
    "    #         ax = plt.gca()\n",
    "    #         ax.text(-0.15, 0.2, label, size=4, fontweight=\"light\", color=color, ha=\"left\", va=\"center\", transform=ax.transAxes, path_effects=[pe.withStroke(linewidth=0.5, foreground=\"black\")])\n",
    "    #     g.map(label, 'Error')\n",
    "    #     # Set the subplots to overlap\n",
    "    #     g.figure.subplots_adjust(hspace=0.0)\n",
    "    #     # Remove axes details that don't play well with overlap\n",
    "    #     g.set_titles(\"\")\n",
    "    #     g.set(yticks=[], ylabel=\"\")\n",
    "    #     g.despine(bottom=True, left=True)\n",
    "    #     # Save\n",
    "    #     g.savefig(f\"{path_models}/{model_id}/ridgeline_GSEs_error_{part}.png\", bbox_inches='tight', dpi=200)\n",
    "    #     g.savefig(f\"{path_models}/{model_id}/ridgeline_GSEs_error_{part}.pdf\", bbox_inches='tight')\n",
    "    #     plt.close(g.fig)\n",
    "\n",
    "df_models_metrics.to_excel(f\"{path_models}/models_metrics.xlsx\", index_label='Model ID')\n",
    "\n",
    "for group in ['Train', 'Validation', 'Test']:\n",
    "    df_models_check[f'{group} MAE Diff'] = df_models_check[f'{group} MAE After'] - df_models_check[f'{group} MAE Before']\n",
    "    df_models_check[f'{group} Rho Diff'] = df_models_check[f'{group} Rho After'] - df_models_check[f'{group} Rho Before']\n",
    "df_models_check.to_excel(f\"{path_models}/models_check.xlsx\", index_label='Model ID')\n",
    "\n",
    "with pd.ExcelWriter(f\"{path_models}/gses_models_metrics.xlsx\", engine='xlsxwriter') as writer:\n",
    "    for md in [f\"{x[0]} {x[1]}\" for x in itertools.product(['MAE', 'Rho', 'Bias'], ['Train', 'Validation', 'Test', 'Total'])]:\n",
    "        df_gses_models_metrics[md].insert(1, 'Preproc', gse_preproc.loc[df_gses_models_metrics[md].index, 'Preproc'])\n",
    "        df_gses_models_metrics[md].to_excel(writer, sheet_name=md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemenatary table with all predicted data for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'DANet' # 'FTTransformer' 'GANDALF' 'DANet'\n",
    "model_id = 194\n",
    "\n",
    "df_model = pd.read_excel(f\"{path}/pytorch_tabular/{model_type}/candidates/{model_id}/data.xlsx\", index_col=0)\n",
    "df_data = pd.read_excel(f\"{path}/data_filtered.xlsx\", index_col=0)\n",
    "\n",
    "df_model.loc[df_model.index, 'Status'] = df_data.loc[df_model.index, 'Status']\n",
    "df_model.loc[df_model.index, 'ICD-11 chapter'] = df_data.loc[df_model.index, 'ICD-11 chapter']\n",
    "df_model.loc[df_model.index, 'ICD-11 chapter and description'] = df_data.loc[df_model.index, 'ICD-11 chapter and description']\n",
    "df_model.loc[df_model.index, 'ICD-11 code'] = df_data.loc[df_model.index, 'ICD-11 code']\n",
    "df_model.loc[df_model.index, 'ICD-11 code and description'] = df_data.loc[df_model.index, 'ICD-11 code and description']\n",
    "\n",
    "for clock in clocks_tests.index:\n",
    "    df_model.loc[df_model.index, clock] = df_data.loc[df_model.index, clocks_tests.at[clock, 'Model ID']]\n",
    "    \n",
    "for f in feats:\n",
    "    df_model.loc[df_model.index, f.replace('_log', '')] = df_data.loc[df_model.index, f]\n",
    "\n",
    "df_model.to_excel(f\"{path}/EpImAge.xlsx\", index_label=\"Sample ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDE plot for all clocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/EpImAge.xlsx\", index_col=\"Sample ID\")\n",
    "df_ctrl = df.loc[df['Status'] == 'Control', :]\n",
    "epiages = clocks_tests.index[clocks_tests['Type'] == 'Age'].to_list()\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig = plt.figure(\n",
    "    figsize=(13, 25),\n",
    "    layout=\"constrained\"\n",
    ")\n",
    "subfigs = fig.subfigures(\n",
    "    nrows=7,\n",
    "    ncols=4,\n",
    "    # wspace=0.001,\n",
    "    # hspace=0.001,\n",
    ")\n",
    "for epiage_id, epiage in tqdm(enumerate(epiages)):\n",
    "    row_id, col_id = divmod(epiage_id, 4)\n",
    "\n",
    "    axs = subfigs[row_id, col_id].subplot_mosaic(\n",
    "        [\n",
    "            ['1'],\n",
    "            ['2'],\n",
    "        ],\n",
    "        height_ratios=[1, 4],\n",
    "        gridspec_kw={\n",
    "            \"bottom\": 0.14,\n",
    "            \"top\": 0.95,\n",
    "            # \"left\": 0.1,\n",
    "            # \"right\": 0.5,\n",
    "            \"wspace\": 0.33,\n",
    "            \"hspace\": 0.01,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    ds_table = pd.DataFrame(index=['MAE', fr\"Pearson $\\rho$\", \"Bias\"], columns=[epiage])\n",
    "    mae = sklearn.metrics.mean_absolute_error(df_ctrl['Age'].values, df_ctrl[epiage].values)\n",
    "    rho, _ = stats.pearsonr(df_ctrl['Age'].values, df_ctrl[epiage].values)\n",
    "    bias = np.mean(df_ctrl[epiage] - df_ctrl['Age'])\n",
    "    ds_table.at['MAE', epiage] = f\"{mae:0.3f}\"\n",
    "    ds_table.at[fr\"Pearson $\\rho$\", epiage] = f\"{rho:0.3f}\"\n",
    "    ds_table.at[\"Bias\", epiage] = f\"{bias:0.3f}\"\n",
    "    table_title = f\"{epiage}\\:({clocks_tests.at[epiage, 'Year']})\"\n",
    "    col_defs = [\n",
    "        ColumnDefinition(\n",
    "            name=\"index\",\n",
    "            title=fr\"$\\mathbf{{{table_title}}}$\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=4.5,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=epiage,\n",
    "            title='',\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            width=2.0,\n",
    "        ),\n",
    "    ]\n",
    "    table = Table(\n",
    "        ds_table,\n",
    "        column_definitions=col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        ax=axs['1'],\n",
    "        textprops={\"fontsize\": 7},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=[epiage])\n",
    "    \n",
    "    xy_min = df_ctrl[['Age', epiage]].min().min()\n",
    "    xy_max = df_ctrl[['Age', epiage]].max().max()\n",
    "    xy_ptp = xy_max - xy_min\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        y=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        zorder=0,\n",
    "        ax=axs['2']\n",
    "    )\n",
    "    regplot = sns.regplot(\n",
    "        data=df_ctrl,\n",
    "        x='Age',\n",
    "        y=epiage,\n",
    "        color='crimson',\n",
    "        scatter=False,\n",
    "        truncate=False,\n",
    "        ax=axs['2'],\n",
    "    )\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=df_ctrl,\n",
    "        x='Age',\n",
    "        y=epiage,\n",
    "        fill=True,\n",
    "        cbar=False,\n",
    "        color='gray',\n",
    "        thresh=0.002,\n",
    "        cut=0,\n",
    "        legend=False,\n",
    "        zorder=0,\n",
    "        ax=axs['2']\n",
    "    )\n",
    "    axs['2'].set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    axs['2'].set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    \n",
    "fig.savefig(f\"{path}/epi_ages_distribution.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path}/epi_ages_distribution.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of all epigenetic clocks for controls and cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/EpImAge.xlsx\", index_col=\"Sample ID\")\n",
    "df_ctrls = df.loc[df['Status'] == 'Control', :]\n",
    "df_cases = df.loc[df['Status'] != 'Control', :]\n",
    "epiages = ['EpImAge'] + clocks_tests.index[clocks_tests['Type'] == 'Age'].to_list()\n",
    "\n",
    "df_corr = pd.DataFrame(index=epiages, columns=epiages, data=np.zeros(shape=(len(epiages), len(epiages))),)\n",
    "for f_id_1 in range(len(epiages)):\n",
    "    for f_id_2 in range(f_id_1, len(epiages)):\n",
    "        f_1 = epiages[f_id_1]\n",
    "        f_2 = epiages[f_id_2]\n",
    "        vals_ctrls_1 = df_ctrls.loc[:, f_1].values\n",
    "        vals_ctrls_2 = df_ctrls.loc[:, f_2].values\n",
    "        vals_cases_1 = df_cases.loc[:, f_1].values\n",
    "        vals_cases_2 = df_cases.loc[:, f_2].values\n",
    "        if f_id_1 != f_id_2:\n",
    "            corr_ctrls, _ = stats.pearsonr(vals_ctrls_1, vals_ctrls_2)\n",
    "            corr_cases, _ = stats.pearsonr(vals_cases_1, vals_cases_2)\n",
    "            df_corr.at[f_2, f_1] = corr_ctrls\n",
    "            df_corr.at[f_1, f_2] = corr_cases\n",
    "            if f_1 == 'EpImAge' and f_2 == 'Horvath':\n",
    "                print(f\"{f_1} vs {f_2} controls: {corr_ctrls}\")\n",
    "                print(f\"{f_1} vs {f_2} cases: {corr_cases}\")\n",
    "        else:\n",
    "            df_corr.at[f_2, f_1] = np.nan\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig, ax = plt.subplots(figsize=(4.5 + 0.2 * len(epiages), 2.5 + 0.2 * len(epiages)), layout='constrained')\n",
    "cmap_triu = plt.get_cmap(\"seismic\").copy()\n",
    "heatmap = sns.heatmap(\n",
    "    df_corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    center=0.0,\n",
    "    cmap=cmap_triu,\n",
    "    linewidth=0.1,\n",
    "    linecolor='black',\n",
    "    annot_kws={\"fontsize\": 32 / np.sqrt(len(df_corr.values) + 10)},\n",
    "    ax=ax\n",
    ")\n",
    "ax.figure.axes[-1].set_ylabel(r\"Pearson $\\rho$\", fontsize='x-large')\n",
    "for spine in ax.figure.axes[-1].spines.values():\n",
    "    spine.set(visible=True, lw=0.25, edgecolor=\"black\")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_title('')\n",
    "fig.savefig(f\"{path}/epi_ages_correlation.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path}/epi_ages_correlation.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of all epigenetic clocks acceleration for controls and cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/EpImAge.xlsx\", index_col=\"Sample ID\")\n",
    "df_ctrls = df.loc[df['Status'] == 'Control', :]\n",
    "df_cases = df.loc[df['Status'] != 'Control', :]\n",
    "epiages = ['EpImAge'] + clocks_tests.index[clocks_tests['Type'] == 'Age'].to_list()\n",
    "\n",
    "df_corr = pd.DataFrame(index=epiages, columns=epiages, data=np.zeros(shape=(len(epiages), len(epiages))),)\n",
    "for f_id_1 in range(len(epiages)):\n",
    "    for f_id_2 in range(f_id_1, len(epiages)):\n",
    "        f_1 = epiages[f_id_1]\n",
    "        f_2 = epiages[f_id_2]\n",
    "        vals_ctrls_1 = df_ctrls.loc[:, f_1].values - df_ctrls.loc[:, 'Age'].values\n",
    "        vals_ctrls_2 = df_ctrls.loc[:, f_2].values - df_ctrls.loc[:, 'Age'].values\n",
    "        vals_cases_1 = df_cases.loc[:, f_1].values - df_cases.loc[:, 'Age'].values\n",
    "        vals_cases_2 = df_cases.loc[:, f_2].values - df_cases.loc[:, 'Age'].values\n",
    "        if f_id_1 != f_id_2:\n",
    "            corr_ctrls, _ = stats.pearsonr(vals_ctrls_1, vals_ctrls_2)\n",
    "            corr_cases, _ = stats.pearsonr(vals_cases_1, vals_cases_2)\n",
    "            df_corr.at[f_2, f_1] = corr_ctrls\n",
    "            df_corr.at[f_1, f_2] = corr_cases\n",
    "            if f_1 == 'EpImAge' and f_2 == 'Horvath':\n",
    "                print(f\"{f_1} vs {f_2} controls: {corr_ctrls}\")\n",
    "                print(f\"{f_1} vs {f_2} cases: {corr_cases}\")\n",
    "        else:\n",
    "            df_corr.at[f_2, f_1] = np.nan\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig, ax = plt.subplots(figsize=(4.5 + 0.2 * len(epiages), 2.5 + 0.2 * len(epiages)), layout='constrained')\n",
    "cmap_triu = plt.get_cmap(\"seismic\").copy()\n",
    "heatmap = sns.heatmap(\n",
    "    df_corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    center=0.0,\n",
    "    cmap=cmap_triu,\n",
    "    linewidth=0.1,\n",
    "    linecolor='black',\n",
    "    annot_kws={\"fontsize\": 32 / np.sqrt(len(df_corr.values) + 10)},\n",
    "    ax=ax\n",
    ")\n",
    "ax.figure.axes[-1].set_ylabel(r\"Age acceleration Pearson $\\rho$\", fontsize='x-large')\n",
    "for spine in ax.figure.axes[-1].spines.values():\n",
    "    spine.set(visible=True, lw=0.25, edgecolor=\"black\")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_title('')\n",
    "fig.savefig(f\"{path}/epi_ages_acceleration_correlation.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path}/epi_ages_acceleration_correlation.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'DANet' # 'FTTransformer' 'GANDALF' 'DANet'\n",
    "model_id = 194\n",
    "\n",
    "df_sweeps = pd.read_excel(f\"{path}/pytorch_tabular/{model_type}/models.xlsx\", index_col=0)\n",
    "model = TabularModel.load_model(f\"{path}/pytorch_tabular/{model_type}/candidates/{model_id}\")\n",
    "\n",
    "data_full['Group'] = ''\n",
    "data_full['EpImAge'] = model.predict(data_full)\n",
    "data_full['Age Acceleration'] = data_full['EpImAge'] - data_full['Age']\n",
    "\n",
    "data_gradio = data_full.loc[data_full['Status'] == 'Control', ['Age', 'EpImAge', 'Age Acceleration'] + list(feats)]\n",
    "data_gradio.to_pickle(f\"{path}/Background.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'DANet' # 'FTTransformer' 'GANDALF' 'DANet'\n",
    "model_id = 194\n",
    "\n",
    "df_sweeps = pd.read_excel(f\"{path}/pytorch_tabular/{model_type}/models.xlsx\", index_col=0)\n",
    "model = TabularModel.load_model(f\"{path}/pytorch_tabular/{model_type}/candidates/{model_id}\")\n",
    "\n",
    "split_id = df_sweeps.at[model_id, 'split_id']\n",
    "fold_id = df_sweeps.at[model_id, 'fold_id']\n",
    "split_dict = samples[split_id]\n",
    "ids_test = split_dict['test']\n",
    "ids_train = split_dict['trains'][fold_id]\n",
    "ids_validation = split_dict['validations'][fold_id]\n",
    "ids_total = np.concatenate([ids_train, ids_validation, ids_test])\n",
    "ids_dict = {\n",
    "    'Test': ids_test,\n",
    "    'Train': ids_train,\n",
    "    'Validation': ids_validation,\n",
    "    'Total': ids_total\n",
    "}\n",
    "\n",
    "data_full['Group'] = ''\n",
    "data_full.loc[ids_train, 'Group'] = 'Train'\n",
    "data_full.loc[ids_validation, 'Group'] = 'Validation'\n",
    "data_full.loc[ids_test, 'Group'] = 'Test'\n",
    "data_full['Prediction'] = model.predict(data_full)\n",
    "data_full['Error'] = data_full['Prediction'] - data_full['Age']\n",
    "\n",
    "data_ctrl = data_full.loc[data_full['Status'] == 'Control', :]\n",
    "\n",
    "def predict_func(X):\n",
    "    X_df = pd.DataFrame(data=X, columns=feats)\n",
    "    y = model.predict(X_df)['Age_prediction'].values\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgt_id = 'I1' # 'I1' 'I8' 'I1 (1)' 'I1 (2)'\n",
    "trgt_age = data_full.at[trgt_id, 'Age']\n",
    "trgt_pred = data_full.at[trgt_id, 'Prediction']\n",
    "trgt_aa = trgt_pred-trgt_age\n",
    "print(trgt_age)\n",
    "print(trgt_pred)\n",
    "\n",
    "n_closest = 200\n",
    "data_closest = data_ctrl.iloc[(data_ctrl['Prediction'] - trgt_age).abs().argsort()[:n_closest]]\n",
    "\n",
    "explainer = shap.SamplingExplainer(predict_func, data_closest.loc[:, feats])\n",
    "print(explainer.expected_value)\n",
    "shap_values = explainer.shap_values(data_full.loc[[trgt_id], feats].values)[0]\n",
    "shap_values = shap_values * (trgt_pred - trgt_age) / (trgt_pred - explainer.expected_value)\n",
    "\n",
    "shap.plots.waterfall(\n",
    "    shap.Explanation(\n",
    "        values=shap_values,\n",
    "        base_values=trgt_age,\n",
    "        data=data_full.loc[trgt_id, feats].values,\n",
    "        feature_names=[f.replace('_log', '') for f in feats]\n",
    "    ),\n",
    "    max_display=len(feats),\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='ticks')\n",
    "n_rows = 4\n",
    "n_cols = 6\n",
    "fig_height = 10\n",
    "fig_width = 20\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), gridspec_kw={}, sharey=False, sharex=False)\n",
    "for feat_id, feat in tqdm(enumerate(feats)):\n",
    "    row_id, col_id = divmod(feat_id, n_cols)\n",
    "\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=data_closest,\n",
    "        x=feat,\n",
    "        color='gray',\n",
    "        linewidth=1,\n",
    "        cut=0,\n",
    "        ax=axs[row_id, col_id]\n",
    "    )\n",
    "    kdeline = axs[row_id, col_id].lines[0]\n",
    "    xs = kdeline.get_xdata()\n",
    "    ys = kdeline.get_ydata()\n",
    "    trgt_val = data_full.at[trgt_id, feat]\n",
    "    trgt_prctl = scipy.stats.percentileofscore(data_closest.loc[:, feat], trgt_val)\n",
    "    axs[row_id, col_id].fill_between(xs, 0, ys, where=(xs <= trgt_val), interpolate=True, facecolor='dodgerblue', alpha=0.7)\n",
    "    axs[row_id, col_id].fill_between(xs, 0, ys, where=(xs >= trgt_val), interpolate=True, facecolor='crimson', alpha=0.7)\n",
    "    axs[row_id, col_id].vlines(trgt_val, 0, np.interp(trgt_val, xs, ys), color='black', linewidth=1.5)\n",
    "    axs[row_id, col_id].text(np.mean([min(xs), trgt_val]), 0.1 * max(ys), f\"{trgt_prctl:0.1f}%\", fontstyle=\"oblique\",\n",
    "            color=\"black\", ha=\"center\", va=\"center\")\n",
    "    axs[row_id, col_id].text(np.mean([max(xs), trgt_val]), 0.1 * max(ys), f\"{100 - trgt_prctl:0.1f}%\", fontstyle=\"oblique\",\n",
    "            color=\"black\", ha=\"center\", va=\"center\")\n",
    "    axs[row_id, col_id].ticklabel_format(style='scientific', scilimits=(-1, 1), axis='y', useOffset=True)\n",
    "fig.tight_layout()    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_less_more = pd.DataFrame(index=[f.replace('_log', '') for f in feats], columns=['Less', 'More'])\n",
    "for f in df_less_more.index:\n",
    "    df_less_more.at[f, 'Less'] = round(scipy.stats.percentileofscore(data_closest.loc[:, f\"{f}_log\"].values, data_full.at[trgt_id, f\"{f}_log\"]))\n",
    "    df_less_more.at[f, 'More'] = 100.0 - df_less_more.at[f, 'Less']\n",
    "\n",
    "df_shap = pd.DataFrame(index=[f.replace('_log', '') for f in feats], data=shap_values, columns=[trgt_id])\n",
    "df_shap.sort_values(by=trgt_id, key=abs, inplace=True)\n",
    "df_shap['cumsum'] = df_shap[trgt_id].cumsum()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, shared_yaxes=True, shared_xaxes=True, column_widths=[2, 1])\n",
    "fig.add_trace(\n",
    "    go.Waterfall(\n",
    "        hovertext=[\"Chrono Age\", \"EpImAge\"],\n",
    "        orientation=\"h\",\n",
    "        measure=['absolute', 'relative'],\n",
    "        y=[-1.5, df_shap.shape[0] + 0.5],\n",
    "        x=[trgt_age, trgt_aa],\n",
    "        base=0,\n",
    "        text=[f\"{trgt_age:0.2f}\", f\"+{trgt_aa:0.2f}\" if trgt_aa > 0 else f\"{trgt_aa:0.2f}\"],\n",
    "        textposition = \"auto\",\n",
    "        decreasing = {\"marker\":{\"color\": \"deepskyblue\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        increasing = {\"marker\":{\"color\": \"crimson\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        totals= {\"marker\":{\"color\": \"dimgray\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        connector={\n",
    "            \"mode\": \"between\",\n",
    "            \"line\": {\"width\": 1, \"color\": \"black\", \"dash\": \"dot\"},\n",
    "        },\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Waterfall(\n",
    "        hovertext=df_shap.index.values,\n",
    "        orientation=\"h\",\n",
    "        measure=[\"relative\"] * len(feats),\n",
    "        y=list(range(df_shap.shape[0])),\n",
    "        x=df_shap[trgt_id].values,\n",
    "        base=trgt_age,\n",
    "        text=[f\"+{x:0.2f}\" if x > 0 else f\"{x:0.2f}\" for x in df_shap[trgt_id].values],\n",
    "        textposition = \"auto\",\n",
    "        decreasing = {\"marker\":{\"color\": \"lightblue\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        increasing = {\"marker\":{\"color\": \"lightcoral\", \"line\": {\"color\": \"black\", \"width\": 1}}},\n",
    "        connector={\n",
    "            \"mode\": \"between\",\n",
    "            \"line\": {\"width\": 1, \"color\": \"black\", \"dash\": \"solid\"},\n",
    "        },\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.update_traces(row=1, col=1, showlegend=False)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        hovertext=df_shap.index.values,\n",
    "        orientation=\"h\",\n",
    "        name='Less',\n",
    "        x=df_less_more.loc[df_shap.index.values, 'Less'],\n",
    "        y=list(range(df_shap.shape[0])),\n",
    "        marker=dict(color='steelblue', line=dict(color=\"black\", width=1)),\n",
    "        text=df_less_more.loc[df_shap.index.values, 'Less'],\n",
    "        textposition='auto'\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        hovertext=df_shap.index.values,\n",
    "        orientation=\"h\",\n",
    "        name='More',\n",
    "        x=df_less_more.loc[df_shap.index.values, 'More'],\n",
    "        y=list(range(df_shap.shape[0])),\n",
    "        marker=dict(color='violet', line=dict(color=\"black\", width=1)),\n",
    "        text=df_less_more.loc[df_shap.index.values, 'More'],\n",
    "        textposition='auto',\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2\n",
    ")\n",
    "fig.update_layout(barmode=\"relative\")\n",
    "fig.update_layout(legend=dict(\n",
    "    title=dict(text=\"Immunomarkers' disribution<br>in samples with same age\", side=\"top center\"),\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=0.95,\n",
    "    xanchor=\"center\",\n",
    "    x=0.84\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"{trgt_id} XAI age acceleration\",\n",
    "    titlefont=dict(size=25),\n",
    "    template=\"none\",  # 'simple_white'\n",
    "    width=800,\n",
    "    height=1000,\n",
    "    margin=go.layout.Margin(l=120, r=20, b=50, t=50, pad=0),\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    tickmode=\"array\",\n",
    "    tickvals=[-1.5] + list(range(df_shap.shape[0])) + [df_shap.shape[0] + 0.5],\n",
    "    ticktext=[\"Chrono Age\"] + df_shap.index.to_list() + [\"EpImAge\"],\n",
    "    tickfont=dict(size=18),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    title='Age',\n",
    "    titlefont=dict(size=25),\n",
    "    range=[\n",
    "        trgt_age - df_shap['cumsum'].abs().max() * 1.25,\n",
    "        trgt_age + df_shap['cumsum'].abs().max() * 1.25\n",
    "    ],\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    showgrid=False,\n",
    "    showline=False,\n",
    "    zeroline=False,\n",
    "    showticklabels=False,\n",
    "    row=1,\n",
    "    col=2\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=False,\n",
    "    showline=False,\n",
    "    zeroline=False,\n",
    "    showticklabels=False,\n",
    "    row=1,\n",
    "    col=2\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
