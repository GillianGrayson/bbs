{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Debugging autoreload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import BaseCrossValidator, ParameterGrid, ParameterSampler\n",
    "import torch\n",
    "import shutil\n",
    "import pickle\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "import optuna\n",
    "import pathlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*exists and is not empty.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*is smaller than the logging interval Trainer.*\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epi_data_type = 'no_harm'\n",
    "imm_data_type = 'imp_source(imm)_method(knn)_params(5)' # 'origin' 'imp_source(imm)_method(knn)_params(5)' 'imp_source(imm)_method(miceforest)_params(2)'\n",
    "\n",
    "selection_method = 'mrmr' # 'f_regression' 'spearman' 'mrmr'\n",
    "n_feats = 100\n",
    "\n",
    "imm = 'CX3CL1'\n",
    "\n",
    "tst_n_splits = 5\n",
    "tst_n_repeats = 5\n",
    "tst_random_state = 1337\n",
    "tst_split_id = 5\n",
    "\n",
    "val_n_splits = 4\n",
    "val_n_repeats = 2\n",
    "val_random_state = 1337\n",
    "val_fold_id = 5\n",
    "\n",
    "fn_samples = f\"samples_tst({tst_random_state}_{tst_n_splits}_{tst_n_repeats})_val({val_random_state}_{val_n_splits}_{val_n_repeats})\"\n",
    "with open(f\"D:/YandexDisk/Work/bbd/immunology/003_EpImAge/{fn_samples}.pickle\", 'rb') as handle:\n",
    "    samples = pickle.load(handle)\n",
    "    \n",
    "for split_id in range(tst_n_splits * tst_n_repeats):\n",
    "    for fold_id in range(val_n_splits * val_n_repeats):\n",
    "        test_samples = samples[split_id]['test']\n",
    "        train_samples = samples[split_id]['trains'][fold_id]\n",
    "        validation_samples = samples[split_id]['validations'][fold_id]\n",
    "\n",
    "        intxns = {\n",
    "            'train_validation': set.intersection(set(train_samples), set(validation_samples)),\n",
    "            'validation_test': set.intersection(set(validation_samples), set(test_samples)),\n",
    "            'train_test': set.intersection(set(train_samples), set(test_samples))\n",
    "        }\n",
    "        \n",
    "        for intxn_name, intxn_samples in intxns.items():\n",
    "            if len(intxn_samples) > 0:\n",
    "                print(f\"Non-zero {intxn_name} intersection ({len(intxn_samples)}) for {split_id} Split and {fold_id} Fold!\")\n",
    "\n",
    "path_data = f\"D:/YandexDisk/Work/bbd/immunology/003_EpImAge/{imm_data_type}/{epi_data_type}/{selection_method}_{n_feats}/{imm}\"\n",
    "pathlib.Path(f\"{path_data}/pytorch_tabular\").mkdir(parents=True, exist_ok=True)\n",
    "path_configs = \"D:/Work/bbs/notebooks/immunology/003_EpImAge/immuno_regression_configs\"\n",
    "data = pd.read_excel(f\"{path_data}/data.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path_data}/feats_con.xlsx\", index_col=0).index.values.tolist()\n",
    "\n",
    "split_dict = samples[tst_split_id]\n",
    "\n",
    "test = data.loc[split_dict['test'], feats + [f\"{imm}_log\"]]\n",
    "train = data.loc[split_dict['trains'][val_fold_id], feats + [f\"{imm}_log\"]]\n",
    "validation = data.loc[split_dict['validations'][val_fold_id], feats + [f\"{imm}_log\"]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load non-model configs"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "data_config['target'] = [f\"{imm}_log\"]\n",
    "data_config['continuous_cols'] = feats\n",
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "trainer_config['checkpoints_path'] = f\"{path_data}/pytorch_tabular\"\n",
    "optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "\n",
    "lr_find_min_lr = 1e-8\n",
    "lr_find_max_lr = 10\n",
    "lr_find_num_training = 512\n",
    "lr_find_mode = \"exponential\"\n",
    "lr_find_early_stop_threshold = 8.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optuna Hyperparameter Optimization"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Init default model config, datamodule"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "seed = 1337\n",
    "model_name = 'DANet'\n",
    "\n",
    "n_trials = 64\n",
    "opt_seed = 40\n",
    "n_startup_trials = 32\n",
    "n_ei_candidates = 16\n",
    "\n",
    "trainer_config['seed'] = seed\n",
    "trainer_config['checkpoints'] = 'valid_loss'\n",
    "trainer_config['load_best'] = True\n",
    "trainer_config['auto_lr_find'] = False\n",
    "\n",
    "model_config_default = read_parse_config(f\"{path_configs}/models/{model_name}Config.yaml\", GANDALFConfig)\n",
    "tabular_model_default = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config_default,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=False,\n",
    ")\n",
    "datamodule = tabular_model_default.prepare_dataloader(train=train, validation=validation, seed=seed)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Init optimization metrics with directions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "opt_parts = ['test', 'validation']\n",
    "opt_metrics = [('mean_absolute_error', 'minimize'), ('pearson_corrcoef', 'maximize')]\n",
    "opt_directions = []\n",
    "for part in opt_parts:\n",
    "    for metric_pair in opt_metrics:\n",
    "        opt_directions.append(f\"{metric_pair[1]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Tuner, No Cross-Validation (Train, Validation, Test)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "trials_results = []\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=model_name,\n",
    "    sampler=optuna.samplers.TPESampler(\n",
    "        n_startup_trials=n_startup_trials,\n",
    "        n_ei_candidates=n_ei_candidates,\n",
    "        seed=opt_seed,\n",
    "    ),\n",
    "    directions=opt_directions\n",
    ")\n",
    "study.optimize(\n",
    "    func=lambda trial: train_hyper_opt(\n",
    "        trial=trial,\n",
    "        trials_results=trials_results,\n",
    "        opt_metrics=opt_metrics,\n",
    "        opt_parts=opt_parts,\n",
    "        model_config_default=model_config_default,\n",
    "        data_config=data_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        experiment_config=None,\n",
    "        train=train,\n",
    "        validation=validation,\n",
    "        test=test,\n",
    "        datamodule=datamodule,\n",
    "        min_lr=lr_find_min_lr,\n",
    "        max_lr=lr_find_max_lr,\n",
    "        num_training=lr_find_num_training,\n",
    "        mode=lr_find_mode,\n",
    "        early_stop_threshold=lr_find_early_stop_threshold\n",
    "    ), \n",
    "    n_trials=n_trials, \n",
    "    show_progress_bar=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fn_trials = (f\"model({model_name})_trials({n_trials}_{opt_seed}_{n_startup_trials}_{n_ei_candidates})_\"\n",
    "             f\"tst({tst_split_id})_val({val_fold_id})_\"\n",
    "             f\"{optimizer_config['lr_scheduler']}_{data_config['continuous_feature_transform']}\")\n",
    "\n",
    "df_trials = pd.DataFrame(trials_results)\n",
    "df_trials['split_id'] = tst_split_id\n",
    "df_trials['fold_id'] = val_fold_id\n",
    "df_trials[\"train_more\"] = False\n",
    "df_trials.loc[(df_trials[\"train_loss\"] > df_trials[\"test_loss\"]) | (\n",
    "            df_trials[\"train_loss\"] > df_trials[\"validation_loss\"]), \"train_more\"] = True\n",
    "df_trials[\"validation_test_mean_loss\"] = (df_trials[\"validation_loss\"] + df_trials[\"test_loss\"]) / 2.0\n",
    "df_trials[\"train_validation_test_mean_loss\"] = (df_trials[\"train_loss\"] + df_trials[\"validation_loss\"] + df_trials[\"test_loss\"]) / 3.0\n",
    "\n",
    "df_trials.sort_values(by=['test_loss'], ascending=[True], inplace=True)\n",
    "df_trials.style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"validation_test_mean_loss\",\n",
    "        \"train_validation_test_mean_loss\",\n",
    "        \"test_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{trainer_config['checkpoints_path']}/{fn_trials}.xlsx\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Sweep Training"
  },
  {
   "cell_type": "markdown",
   "source": "## Models Search Spaces",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GANDALF Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__gflu_stages\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    \"model_config__gflu_dropout\": [0.0, 0.1],\n",
    "    \"model_config__gflu_feature_init_sparsity\": [0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.1],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [1337],\n",
    "}\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\",\n",
    "    activation='ReLU',\n",
    "    dropout=0.1,\n",
    "    use_batch_norm=False,\n",
    "    initialization=\"kaiming\",\n",
    ").__dict__\n",
    "\n",
    "model_list = []\n",
    "for i, params in enumerate(ParameterGrid(search_space)):\n",
    "    head_config_tmp = copy.deepcopy(head_config)\n",
    "    head_config_tmp['dropout'] = params['model_config.head_config__dropout']\n",
    "    model_config = read_parse_config(f\"{path_configs}/models/GANDALFConfig.yaml\", GANDALFConfig)\n",
    "    model_config['gflu_stages'] = params['model_config__gflu_stages']\n",
    "    model_config['gflu_feature_init_sparsity'] = params['model_config__gflu_feature_init_sparsity']\n",
    "    model_config['gflu_dropout'] = params['model_config__gflu_dropout']\n",
    "    model_config['learning_rate'] = params['model_config__learning_rate']\n",
    "    model_config['seed'] = params['model_config__seed']\n",
    "    model_config['head_config'] = head_config_tmp\n",
    "    model_list.append(GANDALFConfig(**model_config))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DANet Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__n_layers\": [4, 6, 8, 10, 12, 14, 16],\n",
    "    \"model_config__abstlay_dim_1\": [8, 16, 32],\n",
    "    \"model_config__k\": [3, 4, 5, 6],\n",
    "    \"model_config__dropout_rate\": [0.0, 0.1],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.1],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [1337],\n",
    "}\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\",\n",
    "    activation='ReLU',\n",
    "    dropout=0.1,\n",
    "    use_batch_norm=False,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__\n",
    "\n",
    "model_list = []\n",
    "for i, params in enumerate(ParameterGrid(search_space)):\n",
    "    head_config_tmp = copy.deepcopy(head_config)\n",
    "    head_config_tmp['dropout'] = params['model_config.head_config__dropout']\n",
    "    model_config = read_parse_config(f\"{path_configs}/models/DANetConfig.yaml\", DANetConfig)\n",
    "    model_config['n_layers'] = params['model_config__n_layers']\n",
    "    model_config['abstlay_dim_1'] = params['model_config__abstlay_dim_1']\n",
    "    model_config['k'] = params['model_config__k']\n",
    "    model_config['dropout_rate'] = params['model_config__dropout_rate']\n",
    "    model_config['learning_rate'] = params['model_config__learning_rate']\n",
    "    model_config['seed'] = params['model_config__seed']\n",
    "    model_config['head_config'] = head_config_tmp\n",
    "    model_list.append(DANetConfig(**model_config))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform model sweep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "common_params = {\n",
    "    \"task\": \"regression\",\n",
    "}\n",
    "\n",
    "seeds = [1337]  # [1337, 55763, 40279, 87571, 234461]\n",
    "\n",
    "dfs_result = []\n",
    "for seed in seeds:\n",
    "\n",
    "    trainer_config['seed'] = seed\n",
    "    trainer_config['checkpoints'] = 'valid_loss'\n",
    "    trainer_config['load_best'] = True\n",
    "    trainer_config['auto_lr_find'] = True\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        sweep_df, best_model = model_sweep_custom(\n",
    "            task=\"regression\",\n",
    "            train=train,\n",
    "            validation=validation,\n",
    "            test=test,\n",
    "            data_config=data_config,\n",
    "            optimizer_config=optimizer_config,\n",
    "            trainer_config=trainer_config,\n",
    "            model_list=model_list,\n",
    "            common_model_args=common_params,\n",
    "            metrics=[\"mean_absolute_error\", \"pearson_corrcoef\"],\n",
    "            metrics_params=[{}, {}],\n",
    "            metrics_prob_input=[False, False],\n",
    "            rank_metric=(\"mean_absolute_error\", \"lower_is_better\"),\n",
    "            return_best_model=True,\n",
    "            seed=seed,\n",
    "            progress_bar=False,\n",
    "            verbose=False,\n",
    "            suppress_lightning_logger=True,\n",
    "            min_lr=lr_find_min_lr,\n",
    "            max_lr=lr_find_max_lr,\n",
    "            num_training=lr_find_num_training,\n",
    "            mode=lr_find_mode,\n",
    "            early_stop_threshold=lr_find_early_stop_threshold,\n",
    "        )\n",
    "    sweep_df['seed'] = seed\n",
    "    sweep_df['split_id'] = tst_split_id\n",
    "    sweep_df['fold_id'] = val_fold_id\n",
    "    sweep_df[\"train_more\"] = False\n",
    "    sweep_df.loc[(sweep_df[\"train_loss\"] > sweep_df[\"test_loss\"]) | (\n",
    "                sweep_df[\"train_loss\"] > sweep_df[\"validation_loss\"]), \"train_more\"] = True\n",
    "    sweep_df[\"validation_test_mean_loss\"] = (sweep_df[\"validation_loss\"] + sweep_df[\"test_loss\"]) / 2.0\n",
    "    sweep_df[\"train_validation_test_mean_loss\"] = (sweep_df[\"train_loss\"] + sweep_df[\"validation_loss\"] + sweep_df[\"test_loss\"]) / 3.0\n",
    "\n",
    "    dfs_result.append(sweep_df)\n",
    "\n",
    "    fn_suffix = (f\"models({len(model_list)})_\"\n",
    "                 f\"tst({tst_split_id})_val({val_fold_id})_\"\n",
    "                 f\"{best_model.config['lr_scheduler']}_{best_model.config['continuous_feature_transform']}\")\n",
    "    try:\n",
    "        df_result = pd.concat(dfs_result, ignore_index=True)\n",
    "        df_result.sort_values(by=['test_loss'], ascending=[True], inplace=True)\n",
    "        df_result.style.background_gradient(\n",
    "            subset=[\n",
    "                \"train_loss\",\n",
    "                \"validation_loss\",\n",
    "                \"validation_test_mean_loss\",\n",
    "                \"train_validation_test_mean_loss\",\n",
    "                \"test_loss\",\n",
    "                \"time_taken\",\n",
    "                \"time_taken_per_epoch\"\n",
    "            ], cmap=\"RdYlGn_r\"\n",
    "        ).to_excel(f\"{trainer_config['checkpoints_path']}/{fn_suffix}.xlsx\")\n",
    "    except PermissionError:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Save best models (legacy)",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "fn_trials = (f\"model({model_name})_trials({n_trials}_{opt_seed}_{n_startup_trials}_{n_ei_candidates})_\"\n",
    "             f\"tst({tst_split_id})_val({val_fold_id})_\"\n",
    "             f\"{optimizer_config['lr_scheduler']}\")\n",
    "\n",
    "df_sweeps = pd.read_excel(f\"{trainer_config['checkpoints_path']}/{fn_trials}.xlsx\", index_col=0)\n",
    "path_models = f\"{trainer_config['checkpoints_path']}/candidates/{fn_trials}\"\n",
    "pathlib.Path(path_models).mkdir(parents=True, exist_ok=True)\n",
    "df_sweeps.style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"test_loss\",\n",
    "        \"validation_test_mean_loss\",\n",
    "        \"train_validation_test_mean_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{path_models}/sweep.xlsx\")\n",
    "\n",
    "models_ids = [\n",
    "43,\n",
    "17,\n",
    "42,\n",
    "48,\n",
    "47,\n",
    "]\n",
    "models_ids = list(set(models_ids))\n",
    "\n",
    "df_sweeps.loc[models_ids, :].style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"test_loss\",\n",
    "        \"validation_test_mean_loss\",\n",
    "        \"train_validation_test_mean_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{path_models}/selected.xlsx\")\n",
    "\n",
    "explain_method = \"GradientShap\"\n",
    "explain_baselines = \"b|1000\"\n",
    "explain_n_feats_to_plot = 25\n",
    "\n",
    "for model_id in models_ids:\n",
    "\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=ast.literal_eval(df_sweeps.at[model_id, 'data_params']),\n",
    "        model_config=ast.literal_eval(df_sweeps.at[model_id, 'model_params']),\n",
    "        optimizer_config=ast.literal_eval(df_sweeps.at[model_id, 'optimizer_params']),\n",
    "        trainer_config=trainer_config,\n",
    "        verbose=True,\n",
    "        suppress_lightning_logger=True\n",
    "    )\n",
    "    datamodule = tabular_model.prepare_dataloader(\n",
    "        train=train,\n",
    "        validation=validation,\n",
    "        seed=trainer_config['seed'],\n",
    "    )\n",
    "    model = tabular_model.prepare_model(\n",
    "        datamodule\n",
    "    )\n",
    "    tabular_model._prepare_for_training(\n",
    "        model,\n",
    "        datamodule\n",
    "    )\n",
    "    tabular_model.load_weights(df_sweeps.at[model_id, 'checkpoint'])\n",
    "    tabular_model.evaluate(test, verbose=False)\n",
    "    tabular_model.save_model(f\"{path_models}/{model_id}\")\n",
    "    \n",
    "    loaded_model = TabularModel.load_model(f\"{path_models}/{model_id}\")\n",
    "    \n",
    "    df = data.loc[:, data_config['target']]\n",
    "    df.loc[train.index, 'Group'] = 'Train'\n",
    "    df.loc[validation.index, 'Group'] = 'Validation'\n",
    "    df.loc[test.index, 'Group'] = 'Test'\n",
    "    df['Prediction'] = loaded_model.predict(data)\n",
    "    df['Error'] = df['Prediction'] - df[data_config['target'][0]]\n",
    "    df.to_excel(f\"{path_models}/{model_id}/df.xlsx\")\n",
    "    \n",
    "    colors_groups = {\n",
    "        'Train': 'chartreuse',\n",
    "        'Validation': 'dodgerblue',\n",
    "        'Test': 'crimson',\n",
    "    }\n",
    "    \n",
    "    df_metrics = pd.DataFrame(\n",
    "        index=list(colors_groups.keys()),\n",
    "        columns=['mean_absolute_error', 'pearson_corrcoef', 'bias']\n",
    "    )\n",
    "    for group in colors_groups.keys():\n",
    "        pred = torch.from_numpy(df.loc[df['Group'] == group, 'Prediction'].values)\n",
    "        real = torch.from_numpy(df.loc[df['Group'] == group, data_config['target'][0]].values)\n",
    "        df_metrics.at[group, 'mean_absolute_error'] = mean_absolute_error(pred, real).numpy()\n",
    "        df_metrics.at[group, 'pearson_corrcoef'] = pearson_corrcoef(pred, real).numpy()\n",
    "        df_metrics.at[group, 'bias'] = np.mean(df.loc[df['Group'] == group, 'Error'].values)\n",
    "    df_metrics.to_excel(f\"{path_models}/{model_id}/metrics.xlsx\", index_label=\"Metrics\")\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    xy_min = df[[data_config['target'][0], 'Prediction']].min().min()\n",
    "    xy_max = df[[data_config['target'][0], 'Prediction']].max().max()\n",
    "    xy_ptp = xy_max - xy_min\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "    scatter = sns.scatterplot(\n",
    "        data=df,\n",
    "        x=data_config['target'][0],\n",
    "        y=\"Prediction\",\n",
    "        hue=\"Group\",\n",
    "        palette=colors_groups,\n",
    "        linewidth=0.2,\n",
    "        alpha=0.75,\n",
    "        edgecolor=\"k\",\n",
    "        s=20,\n",
    "        hue_order=list(colors_groups.keys()),\n",
    "        ax=ax\n",
    "    )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        y=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"{df_sweeps.at[model_id, 'model']} ({df_sweeps.at[model_id, '# Params']} params, {df_sweeps.at[model_id, 'epochs']} epochs)\")\n",
    "    ax.set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    ax.set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    fig.savefig(f\"{path_models}/{model_id}/scatter.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/scatter.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    df_fig = df.loc[:, ['Error', 'Group']]\n",
    "    groups_rename = {\n",
    "        group: f\"{group}\" + \"\\n\" +\n",
    "               fr\"MAE: {df_metrics.at[group, 'mean_absolute_error']:0.2f}\" + \"\\n\"\n",
    "               fr\"Pearson $\\rho$: {df_metrics.at[group, 'pearson_corrcoef']:0.2f}\" + \"\\n\" +\n",
    "               fr\"$\\langle$Error$\\rangle$: {df_metrics.at[group, 'bias']:0.2f}\" \n",
    "        for group in colors_groups\n",
    "    }\n",
    "    colors_groups_violin = {groups_rename[group]: colors_groups[group] for group in colors_groups}\n",
    "    df_fig['Group'].replace(groups_rename, inplace=True)\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    violin = sns.violinplot(\n",
    "        data=df_fig,\n",
    "        x='Group',\n",
    "        y='Error',\n",
    "        palette=colors_groups_violin,\n",
    "        scale='width',\n",
    "        order=list(colors_groups_violin.keys()),\n",
    "        saturation=0.75,\n",
    "        legend=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('')\n",
    "    fig.savefig(f\"{path_models}/{model_id}/violin.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_models}/{model_id}/violin.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    try:\n",
    "        explanation = loaded_model.explain(data, method=explain_method, baselines=explain_baselines)\n",
    "        explanation.index = data.index\n",
    "        explanation.to_excel(f\"{path_models}/{model_id}/explanation.xlsx\")\n",
    "        \n",
    "        sns.set_theme(style='whitegrid')\n",
    "        fig = shap.summary_plot(\n",
    "            shap_values=explanation.loc[:, feats].values,\n",
    "            features=data.loc[:, feats].values,\n",
    "            feature_names=feats,\n",
    "            max_display=explain_n_feats_to_plot,\n",
    "            plot_type=\"violin\",\n",
    "            show=False,\n",
    "        )\n",
    "        plt.savefig(f\"{path_models}/{model_id}/explain_beeswarm.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_models}/{model_id}/explain_beeswarm.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        sns.set_theme(style='whitegrid')\n",
    "        fig = shap.summary_plot(\n",
    "            shap_values=explanation.loc[:, feats].values,\n",
    "            features=data.loc[:, feats].values,\n",
    "            feature_names=feats,\n",
    "            max_display=explain_n_feats_to_plot,\n",
    "            plot_type=\"bar\",\n",
    "            show=False,\n",
    "        )\n",
    "        plt.savefig(f\"{path_models}/{model_id}/explain_bar.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_models}/{model_id}/explain_bar.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    except NotImplementedError:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save best models"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "models_names = [\n",
    "    'FTTransformerModel',\n",
    "    'DANetModel',\n",
    "    'GANDALFModel',\n",
    "    'CategoryEmbeddingModel',\n",
    "    'TabNetModel'\n",
    "]\n",
    "\n",
    "target = f\"{imm}_log\"\n",
    "\n",
    "path_ckpts = f'{path_data}/pytorch_tabular'\n",
    "\n",
    "fn_trials = (f\"models_\"\n",
    "             f\"tst({tst_split_id})_\"\n",
    "             f\"val({val_fold_id})\")\n",
    "df_trials = pd.read_excel(f\"{path_ckpts}/{fn_trials}.xlsx\", index_col=0)\n",
    "pathlib.Path(f\"{path_ckpts}/candidates\").mkdir(parents=True, exist_ok=True)\n",
    "df_trials.style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"validation_test_mean_loss\",\n",
    "        \"train_validation_test_mean_loss\",\n",
    "        \"test_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{path_ckpts}/candidates/{fn_trials}.xlsx\")\n",
    "\n",
    "for model_name in models_names:\n",
    "    print(model_name)\n",
    "    df_model_all = df_trials[df_trials['model'] == model_name]\n",
    "    path_model = f\"{path_ckpts}/candidates/{model_name}\"\n",
    "    pathlib.Path(path_model).mkdir(parents=True, exist_ok=True)\n",
    "    df_model_all.style.background_gradient(\n",
    "        subset=[\n",
    "            \"train_loss\",\n",
    "            \"validation_loss\",\n",
    "            \"test_loss\",\n",
    "            \"validation_test_mean_loss\",\n",
    "            \"train_validation_test_mean_loss\",\n",
    "            \"time_taken\",\n",
    "            \"time_taken_per_epoch\"\n",
    "        ], cmap=\"RdYlGn_r\"\n",
    "    ).to_excel(f\"{path_model}/all.xlsx\")\n",
    "    \n",
    "    df_model_selected = df_model_all[df_model_all['Selected'] == 1]\n",
    "    df_model_selected.style.background_gradient(\n",
    "        subset=[\n",
    "            \"train_loss\",\n",
    "            \"validation_loss\",\n",
    "            \"test_loss\",\n",
    "            \"validation_test_mean_loss\",\n",
    "            \"train_validation_test_mean_loss\",\n",
    "            \"time_taken\",\n",
    "            \"time_taken_per_epoch\"\n",
    "        ], cmap=\"RdYlGn_r\"\n",
    "    ).to_excel(f\"{path_model}/selected.xlsx\")\n",
    "    \n",
    "    explain_method = \"GradientShap\"\n",
    "    explain_baselines = \"b|1000\"\n",
    "    explain_n_feats_to_plot = 25\n",
    "    \n",
    "    for model_id, row in df_model_selected.iterrows():\n",
    "        \n",
    "        model_dir = (str(pathlib.Path(row['checkpoint']).parent).replace('\\\\', '/') \n",
    "                     + '/' + pathlib.Path(row['checkpoint']).stem)\n",
    "        \n",
    "        model = TabularModel.load_model(model_dir)\n",
    "        pathlib.Path(f\"{path_model}/{model_id}\").mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copytree(model_dir, f\"{path_model}/{model_id}\", dirs_exist_ok=True)\n",
    "        \n",
    "        df = data.loc[:, [target]]\n",
    "        df.loc[train.index, 'Group'] = 'Train'\n",
    "        df.loc[validation.index, 'Group'] = 'Validation'\n",
    "        df.loc[test.index, 'Group'] = 'Test'\n",
    "        df['Prediction'] = model.predict(data)\n",
    "        df['Error'] = df['Prediction'] - df[target]\n",
    "        df.to_excel(f\"{path_model}/{model_id}/df.xlsx\")\n",
    "        \n",
    "        colors_groups = {\n",
    "            'Train': 'chartreuse',\n",
    "            'Validation': 'dodgerblue',\n",
    "            'Test': 'crimson',\n",
    "        }\n",
    "        \n",
    "        df_metrics = pd.DataFrame(\n",
    "            index=list(colors_groups.keys()),\n",
    "            columns=['mean_absolute_error', 'pearson_corrcoef', 'bias']\n",
    "        )\n",
    "        for group in colors_groups.keys():\n",
    "            pred = torch.from_numpy(df.loc[df['Group'] == group, 'Prediction'].values)\n",
    "            real = torch.from_numpy(df.loc[df['Group'] == group, target].values)\n",
    "            df_metrics.at[group, 'mean_absolute_error'] = mean_absolute_error(pred, real).numpy()\n",
    "            df_metrics.at[group, 'pearson_corrcoef'] = pearson_corrcoef(pred, real).numpy()\n",
    "            df_metrics.at[group, 'bias'] = np.mean(df.loc[df['Group'] == group, 'Error'].values)\n",
    "        df_metrics.to_excel(f\"{path_model}/{model_id}/metrics.xlsx\", index_label=\"Metrics\")\n",
    "        \n",
    "        sns.set_theme(style='whitegrid')\n",
    "        xy_min = df[[target, 'Prediction']].min().min()\n",
    "        xy_max = df[[target, 'Prediction']].max().max()\n",
    "        xy_ptp = xy_max - xy_min\n",
    "        fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "        scatter = sns.scatterplot(\n",
    "            data=df,\n",
    "            x=target,\n",
    "            y=\"Prediction\",\n",
    "            hue=\"Group\",\n",
    "            palette=colors_groups,\n",
    "            linewidth=0.2,\n",
    "            alpha=0.75,\n",
    "            edgecolor=\"k\",\n",
    "            s=20,\n",
    "            hue_order=list(colors_groups.keys()),\n",
    "            ax=ax\n",
    "        )\n",
    "        bisect = sns.lineplot(\n",
    "            x=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "            y=[xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "            linestyle='--',\n",
    "            color='black',\n",
    "            linewidth=1.0,\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.set_title(f\"{row['model']} ({row['# Params']} params, {row['epochs']} epochs)\")\n",
    "        ax.set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "        ax.set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        fig.savefig(f\"{path_model}/{model_id}/scatter.png\", bbox_inches='tight', dpi=200)\n",
    "        fig.savefig(f\"{path_model}/{model_id}/scatter.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        df_fig = df.loc[:, ['Error', 'Group']]\n",
    "        groups_rename = {\n",
    "            group: f\"{group}\" + \"\\n\" +\n",
    "                   fr\"MAE: {df_metrics.at[group, 'mean_absolute_error']:0.2f}\" + \"\\n\"\n",
    "                   fr\"Pearson $\\rho$: {df_metrics.at[group, 'pearson_corrcoef']:0.2f}\" + \"\\n\" +\n",
    "                   fr\"$\\langle$Error$\\rangle$: {df_metrics.at[group, 'bias']:0.2f}\" \n",
    "            for group in colors_groups\n",
    "        }\n",
    "        colors_groups_violin = {groups_rename[group]: colors_groups[group] for group in colors_groups}\n",
    "        df_fig['Group'].replace(groups_rename, inplace=True)\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        fig, ax = plt.subplots(figsize=(7, 4))\n",
    "        violin = sns.violinplot(\n",
    "            data=df_fig,\n",
    "            x='Group',\n",
    "            y='Error',\n",
    "            palette=colors_groups_violin,\n",
    "            scale='width',\n",
    "            order=list(colors_groups_violin.keys()),\n",
    "            saturation=0.75,\n",
    "            legend=False,\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.set_xlabel('')\n",
    "        fig.savefig(f\"{path_model}/{model_id}/violin.png\", bbox_inches='tight', dpi=200)\n",
    "        fig.savefig(f\"{path_model}/{model_id}/violin.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        try:\n",
    "            explanation = model.explain(data, method=explain_method, baselines=explain_baselines)\n",
    "            explanation.index = data.index\n",
    "            explanation.to_excel(f\"{path_model}/{model_id}/explanation.xlsx\")\n",
    "            \n",
    "            sns.set_theme(style='whitegrid')\n",
    "            fig = shap.summary_plot(\n",
    "                shap_values=explanation.loc[:, feats].values,\n",
    "                features=data.loc[:, feats].values,\n",
    "                feature_names=feats,\n",
    "                max_display=explain_n_feats_to_plot,\n",
    "                plot_type=\"violin\",\n",
    "                show=False,\n",
    "            )\n",
    "            plt.savefig(f\"{path_model}/{model_id}/explain_beeswarm.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_model}/{model_id}/explain_beeswarm.pdf\", bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            \n",
    "            sns.set_theme(style='whitegrid')\n",
    "            fig = shap.summary_plot(\n",
    "                shap_values=explanation.loc[:, feats].values,\n",
    "                features=data.loc[:, feats].values,\n",
    "                feature_names=feats,\n",
    "                max_display=explain_n_feats_to_plot,\n",
    "                plot_type=\"bar\",\n",
    "                show=False,\n",
    "            )\n",
    "            plt.savefig(f\"{path_model}/{model_id}/explain_bar.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_model}/{model_id}/explain_bar.pdf\", bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "        \n",
    "        except NotImplementedError:\n",
    "            pass"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
