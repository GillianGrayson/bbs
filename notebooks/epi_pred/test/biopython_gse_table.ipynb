{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GEOparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "GPL = 'GPL21145'\n",
    "n_gsm_in_gse = 50\n",
    "\n",
    "path = \"E:/YandexDisk/DNAm draft/GEO\"\n",
    "\n",
    "if Path(f\"{path}/{GPL}_geo_datasets.pkl\").is_file():\n",
    "    gsm_df = pd.read_pickle(f\"{path}/{GPL}_geo_datasets.pkl\")\n",
    "else:\n",
    "    gsm_df = pd.read_excel(f\"{path}/{GPL}_geo_datasets.xlsx\", index_col='Accession')\n",
    "    gsm_df.to_pickle(f\"{path}/{GPL}_geo_datasets.pkl\")\n",
    "\n",
    "pathlib.Path(f\"{path}/{GPL}\").mkdir(parents=True, exist_ok=True)\n",
    "if Path(f\"{path}/{GPL}/gse_gms_dict.pkl\").is_file():\n",
    "    f = open(f\"{path}/{GPL}/gse_gms_dict.pkl\", 'rb')\n",
    "    gse_gsms_dict = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    gse_gsms_dict = {}\n",
    "    for gsm, row in gsm_df.iterrows():\n",
    "        gses_i = row['GSE'].split(';')\n",
    "        for gse in gses_i:\n",
    "            if gse not in gse_gsms_dict:\n",
    "                gse_gsms_dict[gse] = [gsm]\n",
    "            else:\n",
    "                gse_gsms_dict[gse].append(gsm)\n",
    "    f = open(f\"{path}/{GPL}/gse_gms_dict.pkl\", 'wb')\n",
    "    pickle.dump(gse_gsms_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "gses = sorted(gse_gsms_dict.keys(),  key=lambda s: len(gse_gsms_dict.get(s)),  reverse=True)\n",
    "gses_df = pd.DataFrame()\n",
    "gses_df.index.name = 'GSE'\n",
    "\n",
    "for gse_id, gse in enumerate(gses):\n",
    "    if len(gse_gsms_dict[gse]) < n_gsm_in_gse:\n",
    "        break\n",
    "    else:\n",
    "        if gse_id < 0:\n",
    "            continue\n",
    "        print(f\"{gse_id}: {gse} ({len(gse_gsms_dict[gse])})\")\n",
    "        pathlib.Path(f\"{path}/{GPL}/{gse_id}_{gse}\").mkdir(parents=True, exist_ok=True)\n",
    "        gsms_i = gse_gsms_dict[gse]\n",
    "        gse_df_1 = gsm_df.loc[gsm_df.index.isin(gsms_i), :]\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                gse_data = GEOparse.get_GEO(geo=gse, destdir=f\"{path}/{GPL}/{gse_id}_{gse}\", include_data=False, how=\"quick\", silent=True)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            except ConnectionError:\n",
    "                continue\n",
    "            except IOError:\n",
    "                continue\n",
    "            break\n",
    "        gse_df_2 = gse_data.phenotype_data\n",
    "        if gse_df_2.empty:\n",
    "            process_type = 'Entrez'\n",
    "        else:\n",
    "            gse_df_2.index.name = 'gsm'\n",
    "            gse_df_2.replace('NONE', pd.NA, inplace=True)\n",
    "            gse_df_2 = gse_df_2.loc[(gse_df_2['platform_id'] == GPL), :]\n",
    "            is_index_equal = set(gse_df_1.index) == set(gse_df_2.index)\n",
    "            if is_index_equal:\n",
    "                process_type = 'GEOparse'\n",
    "            else:\n",
    "                print(f\"Entrez: {gse_df_1.shape[0]}\")\n",
    "                print(f\"GEOparse: {gse_df_2.shape[0]}\")\n",
    "                if gse_df_2.shape[0] > gse_df_1.shape[0]:\n",
    "                    process_type = 'GEOparse'\n",
    "                else:\n",
    "                    continue\n",
    "        print(f\"process_type: {process_type}\")\n",
    "\n",
    "        gses_df.at[gse, 'Entrez'] = gse_df_1.shape[0]\n",
    "        gses_df.at[gse, 'GEOparse'] = gse_df_2.shape[0]\n",
    "\n",
    "        if process_type == 'GEOparse':\n",
    "            gse_df = gse_df_2.copy()\n",
    "            chars_df_1 = set()\n",
    "        elif process_type == 'Entrez':\n",
    "            gse_df = gse_df_1.copy()\n",
    "            chars_df_1 = set()\n",
    "\n",
    "        if process_type == 'GEOparse':\n",
    "            chars_cols = gse_df.columns.values[gse_df.columns.str.startswith('characteristics_ch1.')]\n",
    "            r = re.compile(r\"characteristics_ch1.\\d*.(.*)\")\n",
    "            chars_df_2 = set([r.findall(x)[0] for x in chars_cols])\n",
    "        else:\n",
    "            chars_df_2 = set()\n",
    "\n",
    "        chars_all = chars_df_1.union(chars_df_2)\n",
    "\n",
    "        gses_df.at[gse, 'n_characteristics_ch1_GEOparse'] = len(chars_df_2)\n",
    "        gses_df.at[gse, 'process_type'] = process_type\n",
    "        gses_df.at[gse, 'Count'] = gse_df.shape[0]\n",
    "        gses_df.at[gse, 'characteristics_ch1'] = str(chars_all)\n",
    "        gses_df.at[gse, 'source_name_ch1'] = gse_df['source_name_ch1'].unique()\n",
    "\n",
    "        if not gse_df['supplementary_file'].isnull().all():\n",
    "            gses_df.at[gse, 'raw_files_exist'] = True\n",
    "            if len(gse_df['supplementary_file'].unique()) == len(gse_df.index):\n",
    "                gses_df.at[gse, 'raw_files_for_all'] = True\n",
    "            else:\n",
    "                gses_df.at[gse, 'raw_files_for_all'] = False\n",
    "            supp_files_split = gse_df['supplementary_file'].str.split('[,;]\\s*', expand=True, regex=True)\n",
    "            if supp_files_split.shape[1] == 2:\n",
    "                gse_df[['supplementary_file_1', 'supplementary_file_2']] = supp_files_split\n",
    "                supp_details = gse_df['supplementary_file_1'].str.findall('(?:.*\\/)(.*)(?:_\\w*.\\..*\\..*)').explode().str.split('_', expand=True)\n",
    "                if supp_details.shape[1] == 3:\n",
    "                    gse_df[['Sample_Name', 'Sentrix_ID', 'Sentrix_Position']] = supp_details\n",
    "        else:\n",
    "            gses_df.at[gse, 'raw_files_exist'] = False\n",
    "\n",
    "        gse_df.to_excel(f\"{path}/{GPL}/{gse_id}_{gse}/{process_type}.xlsx\", index=True)\n",
    "\n",
    "gses_df.to_excel(f\"{path}/{GPL}/gses.xlsx\", index=True)\n",
    "\n",
    "path_filled_tables = \"E:/YandexDisk/pydnameth/draft/10_MetaEPIClock\"\n",
    "additional_columns = ['Origin or Subset', 'Age', 'Sex', 'Newborn', 'Longitudinal data', 'Twins',\n",
    "                      'Postmortem', 'Multi-tissue or single-tissue', 'Controls', 'Cases', 'Ethnicity', \n",
    "                      'Country', 'Good for Paper 1', 'Good for paper 2', 'Comment', 'Preprocessed', \n",
    "                      'Number of controls', 'Controls selection comment', 'Selection comments']\n",
    "if os.path.exists(f\"{path_filled_tables}/{GPL}.xlsx\"):\n",
    "    comm_df = pd.read_excel(f\"{path_filled_tables}/{GPL}.xlsx\", index_col='GSE')\n",
    "    gses_df = pd.concat([gses_df, comm_df[additional_columns]], axis=1)\n",
    "    gses_df[['Age', 'Sex', 'Newborn', 'Longitudinal data', 'Twins', 'Postmortem', 'Controls', 'Cases']] = gses_df[['Age', 'Sex', 'Newborn', 'Longitudinal data', 'Twins', 'Postmortem', 'Controls', 'Cases']].replace({0:False, 1:True})\n",
    "else:\n",
    "    gses_df = gses_df.reindex(columns=[*gses_df.columns.tolist(), *additional_columns])\n",
    "gses_df.to_excel(f\"{path}/{GPL}/{GPL}.xlsx\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
